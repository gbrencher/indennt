{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9bedd6-f6f5-4978-a247-db514ea50b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import torch\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import math\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "import random\n",
    "from scipy import stats\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04f4c1a-7b2b-4a4a-9859-5cc413fb583b",
   "metadata": {},
   "source": [
    "### Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f26a77-3e63-492f-8e31-2cd9a5fdc131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_dir = '/mnt/working/brencher/sw/repos/indennt'\n",
    "subset_types = ['signal', 'noise', 'dem', 'murp', 'era5']\n",
    "\n",
    "# exclude non tif files, e.g. metadata\n",
    "def list_tifs(my_fns):\n",
    "    my_list = []\n",
    "    for i in my_fns:\n",
    "        if i[-4:] == '.tif':\n",
    "            my_list.append(i)\n",
    "    return my_list\n",
    "\n",
    "def subset_lists(main_dir, ds_type, subset_types):\n",
    "    path_d = {}\n",
    "    fn_list = []\n",
    "    for type in subset_types:\n",
    "        path_d[type] = f'{main_dir}/{ds_type}_subsets/{type}/'\n",
    "        fn_list.append(list_tifs(os.listdir(path_d[type])))\n",
    "    return path_d, fn_list[0]\n",
    "\n",
    "test_d, test_list = subset_lists(main_dir, 'test', subset_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb6b81e-1896-4a40-a38b-17913bbc6c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define transforms\n",
    "my_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d30041-3e3e-4572-a02c-22ccd60a1de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define dataset \n",
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_list, path_d, norm_list = [-41, 41, 0, 4374.6372], transform=None, \n",
    "                 norm=True, blurnoise=False, random_blur=False, flip=False, invert=False, rotate=False):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.signal_dir = path_d['signal']\n",
    "        self.noise_dir = path_d['noise']\n",
    "        self.dem_dir = path_d['dem']\n",
    "        self.era5_dir = path_d['era5']\n",
    "        self.murp_dir = path_d['murp']\n",
    "        self.norm = norm\n",
    "        self.blurnoise = blurnoise\n",
    "        self.random_blur = random_blur\n",
    "        self.flip = flip\n",
    "        self.invert = invert\n",
    "        self.rotate = rotate\n",
    "        self.igram_min = norm_list[0]\n",
    "        self.igram_max = norm_list[1]\n",
    "        self.dem_min = norm_list[2]\n",
    "        self.dem_max = norm_list[3]\n",
    "        \n",
    "    #dataset length\n",
    "    def __len__(self):\n",
    "        self.filelength = len(self.file_list)\n",
    "        return self.filelength\n",
    "    \n",
    "    #load images\n",
    "    def __getitem__(self,idx):\n",
    "        signal_path = self.signal_dir+self.file_list[idx]\n",
    "        noise_path = self.noise_dir+self.file_list[idx]\n",
    "        dem_path = self.dem_dir+self.file_list[idx]\n",
    "        era5_path = self.era5_dir+self.file_list[idx]\n",
    "        murp_path = self.murp_dir+self.file_list[idx]\n",
    "        \n",
    "        signal = self.transform(Image.open(signal_path))\n",
    "        noise = self.transform(Image.open(noise_path))\n",
    "        dem = self.transform(Image.open(dem_path))\n",
    "        era5 = self.transform(Image.open(era5_path))\n",
    "        murp = self.transform(Image.open(murp_path))\n",
    "        \n",
    "        # Blur noise\n",
    "        if self.blurnoise == True: # blur noise to mitigate signal from non atmospheric sources\n",
    "            if self.random_blur == True:\n",
    "                blur_params = [[13, 3], [15, 3.5], [17, 4], [19, 4.5], [21, 5]]\n",
    "                while True:\n",
    "                    index = round(np.random.normal(2, 0.4))\n",
    "                    if -1 < index < 5:\n",
    "                        break\n",
    "                \n",
    "                blur_select = blur_params[index]\n",
    "                gblur = transforms.GaussianBlur(kernel_size=(blur_select[0], blur_select[0]), sigma=blur_select[1])\n",
    "                noise = gblur(noise)\n",
    "            else:\n",
    "                gblur = transforms.GaussianBlur(kernel_size=(17, 17), sigma=4)\n",
    "                noise = gblur(noise)\n",
    "        \n",
    "        # Generate scaled training images\n",
    "        scalar = np.round(np.random.lognormal(4, 0.5), 3) # FOR PLOTTING: 5, 0.2, for training 4, 0.5\n",
    "        signal = signal*scalar*-1 #multiply by -1 because mintpy has a reversed sign convention\n",
    "        igram = noise+signal\n",
    "        \n",
    "        # set local ref for era5\n",
    "        ref_index = signal.abs().argmin().item() # location of lowest signal in velocity map\n",
    "        corr_diff = (igram.flatten()[ref_index] - era5.flatten()[ref_index]).item()\n",
    "        era5 = era5+corr_diff\n",
    "        \n",
    "        # set local ref for murp\n",
    "        corr_diff = (igram.flatten()[ref_index] - murp.flatten()[ref_index]).item()\n",
    "        murp = murp+corr_diff\n",
    "        \n",
    "        era5_corr = igram-era5\n",
    "        murp_corr = igram-murp\n",
    "        \n",
    "        # correct hp\n",
    "        hp_filter = transforms.GaussianBlur(kernel_size=(17, 17), sigma=4)\n",
    "        igram_filtered = hp_filter(igram)\n",
    "        hp_corr = igram - igram_filtered\n",
    "        \n",
    "        if self.invert==True:\n",
    "            if random.random() < 0.5:\n",
    "                igram = igram*-1\n",
    "                signal = signal*-1\n",
    "                noise = noise*-1\n",
    "                era5_corr = era5_corr *-1\n",
    "                murp_corr = murp_corr *-1\n",
    "                hp_corr = hp_corr *-1\n",
    "            \n",
    "        if self.norm == True:\n",
    "            igram = 2*(((igram-self.igram_min)/(self.igram_max-self.igram_min)))-1\n",
    "            signal = 2*(((signal-self.igram_min)/(self.igram_max-self.igram_min)))-1\n",
    "            noise = 2*(((noise-self.igram_min)/(self.igram_max-self.igram_min)))-1\n",
    "            dem = 2*(((dem-self.dem_min)/(self.dem_max-self.dem_min)))-1\n",
    "        \n",
    "        if self.flip==True:\n",
    "            flip_dim = []\n",
    "            if random.random() < 0.25:\n",
    "                flip_dim = [0]\n",
    "            elif random.random() > 0.25 and random.random() < 0.5:\n",
    "                flip_dim = [1]\n",
    "            elif random.random() > 0.5 and random.random() < 0.75:\n",
    "                flip_dim = [0, 1]\n",
    "            \n",
    "            igram = torch.flip(igram, flip_dim)\n",
    "            signal = torch.flip(signal, flip_dim)\n",
    "            noise = torch.flip(noise, flip_dim)\n",
    "            era5_corr = torch.flip(era5_corr, flip_dim)\n",
    "            murp_corr = torch.flip(murp_corr, flip_dim)\n",
    "            hp_corr = torch.flip(hp_corr, flip_dim)\n",
    "            dem = torch.flip(dem, flip_dim)\n",
    "        \n",
    "        if self.rotate==True:\n",
    "            angle = random.randint(0, 180)\n",
    "            igram = transforms.functional.rotate(igram, angle)\n",
    "            signal = transforms.functional.rotate(signal, angle)\n",
    "            noise = transforms.functional.rotate(noise, angle)\n",
    "            era5_corr = transforms.functional.rotate(era5_corr, angle)\n",
    "            murp_corr = transforms.functional.rotate(murp_corr, angle)\n",
    "            hp_corr = transforms.functional.rotate(hp_corr, angle)\n",
    "            dem = transforms.functional.rotate(dem, angle)\n",
    "            \n",
    "         \n",
    "        return igram, signal, noise, dem, era5_corr, murp_corr, hp_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee59951-4408-4499-8253-f243595c64b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def undo_norm(array, min=-41, max=41):\n",
    "    array = ((array+1)*((max-min)/2))+min\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c10e99d-54fa-4b7c-b93b-4e413571d602",
   "metadata": {},
   "source": [
    "### Set up network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbccc342-447b-4593-b3ce-66aaabbf4eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride=1, padding=1, bias=True):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding, bias=bias)\n",
    "\n",
    "\n",
    "def conv1x1(in_channels, out_channels):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "\n",
    "\n",
    "def check_valid_activation(choice):\n",
    "    if choice not in ['relu', 'lrelu', 'prelu']:\n",
    "        raise ValueError(f\"'{choice}' is not a valid activation function. Choose among ['relu', 'lrelu', 'prelu'].\\n\")\n",
    "\n",
    "\n",
    "def upconv(in_channels, out_channels, mode='transpose'):\n",
    "    # stride=2 implies upsampling by a factor of 2\n",
    "    get_up_mode = nn.ModuleDict([\n",
    "        ['bilinear', nn.Sequential(nn.Upsample(mode='bilinear', scale_factor=2), conv1x1(in_channels, out_channels))],\n",
    "        ['transpose', nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)]\n",
    "    ])\n",
    "\n",
    "    return get_up_mode[mode]\n",
    "\n",
    "\n",
    "def get_activation(choice):\n",
    "    activation_functions = nn.ModuleDict([\n",
    "        ['relu', nn.ReLU(inplace=True)],\n",
    "        ['lrelu', nn.LeakyReLU(inplace=True)],\n",
    "        ['prelu', nn.PReLU()]\n",
    "        ])\n",
    "    return activation_functions[choice]\n",
    "\n",
    "\n",
    "def conv_block(in_channels, out_channels, activation='relu', do_BN=True, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Partial encoder block consisting of a 3×3 convolutional layer with stride 1, followed by batch normalization\n",
    "    (optional) and a non-linear activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    if do_BN:\n",
    "        return nn.Sequential(\n",
    "            conv3x3(in_channels, out_channels, bias=False, *args, **kwargs),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            get_activation(activation)\n",
    "        )\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            conv3x3(in_channels, out_channels, bias=True, *args, **kwargs),\n",
    "            get_activation(activation)\n",
    "        )\n",
    "\n",
    "\n",
    "def conv_up_block(in_channels, out_channels, activation='relu', do_BN=True, up_mode='transpose', *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Decoder block consisting of an up-convolutional layer, followed by a 3×3 convolutional layer with stride 1,\n",
    "    batch normalization (optional), and a non-linear activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    if do_BN:\n",
    "        return nn.Sequential(\n",
    "            upconv(in_channels, in_channels, up_mode),\n",
    "            nn.Sequential(\n",
    "                conv3x3(in_channels, out_channels, bias=False, *args, **kwargs),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                get_activation(activation))\n",
    "            )\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            upconv(in_channels, in_channels, up_mode),\n",
    "            nn.Sequential(\n",
    "                conv3x3(in_channels, out_channels, bias=True, *args, **kwargs),\n",
    "                get_activation(activation))\n",
    "            )\n",
    "\n",
    "\n",
    "def bottleneck(in_channels, out_channels, activation='relu', do_BN=True, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Bottleneck block.\n",
    "    \"\"\"\n",
    "\n",
    "    if do_BN:\n",
    "        return nn.Sequential(\n",
    "            conv3x3(in_channels, out_channels, bias=False, *args, **kwargs),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            get_activation(activation)\n",
    "        )\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            conv3x3(in_channels, out_channels, bias=True, *args, **kwargs),\n",
    "            get_activation(activation)\n",
    "        )\n",
    "\n",
    "\n",
    "class SkipConnection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SkipConnection, self).__init__()\n",
    "\n",
    "    def forward(self, x_skip, x_up):\n",
    "        return x_skip + x_up\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_input_channels=2, start_kernel=64, max_filter_depth=512, depth=5,\n",
    "                 act_fn_encoder='relu', act_fn_decoder='relu', act_fn_bottleneck='relu', up_mode='transpose',\n",
    "                 do_BN=False, bias_conv_layer=True, outer_skip=True, outer_skip_BN=False):\n",
    "        \"\"\"\n",
    "        UNet network architecture.\n",
    "        :param n_input_channels:    int, number of input channels\n",
    "        :param start_kernel:        int, number of filters of the first convolutional layer in the encoder\n",
    "        :param max_filter_depth:    int, maximum filter depth\n",
    "        :param depth:               int, number of downsampling and upsampling layers (i.e., number of blocks in the\n",
    "                                    encoder and decoder)\n",
    "        :param act_fn_encoder:      str, activation function used in the encoder\n",
    "        :param act_fn_decoder:      str, activation function used in the decoder\n",
    "        :param act_fn_bottleneck:   str, activation function used in the bottleneck\n",
    "        :param up_mode:             str, upsampling mode\n",
    "        :param do_BN:               boolean, True to perform batch normalization after every convolutional layer,\n",
    "                                    False otherwise\n",
    "        :param bias_conv_layer:     boolean, True to activate the learnable bias of the convolutional layers,\n",
    "                                    False otherwise\n",
    "        :param outer_skip:          boolean, True to activate the long residual skip connection that adds the\n",
    "                                    initial DSM to the output of the last decoder layer, False otherwise\n",
    "        :param outer_skip_BN:       boolean, True to add batch normalization to the long residual skip connection,\n",
    "                                    False otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        check_valid_activation(act_fn_encoder)\n",
    "        check_valid_activation(act_fn_decoder)\n",
    "        check_valid_activation(act_fn_bottleneck)\n",
    "\n",
    "        if up_mode not in ['transpose', 'bilinear']:\n",
    "            raise ValueError(f\"'{up_mode}' is not a valid mode for upsampling. Choose among ['transpose', 'bilinear'] \"\n",
    "                             \"to specify 'up_mode'.\\n\")\n",
    "\n",
    "        self.n_input_channels = n_input_channels\n",
    "        self.start_kernel = start_kernel\n",
    "        self.depth = depth\n",
    "        self.act_fn_encoder = act_fn_encoder\n",
    "        self.act_fn_decoder = act_fn_decoder\n",
    "        self.act_fn_bottleneck = act_fn_bottleneck\n",
    "        self.up_mode = up_mode\n",
    "        self.max_filter_depth = max_filter_depth\n",
    "        self.do_BN = do_BN\n",
    "        self.bias_conv_layer = bias_conv_layer\n",
    "        self.do_outer_skip = outer_skip\n",
    "        self.do_outer_skip_BN = outer_skip_BN\n",
    "        self.filter_depths = [self.start_kernel * (2 ** i) for i in range(self.depth)]\n",
    "\n",
    "        # Restrict the maximum filter depth to a predefined value\n",
    "        self.filter_depths = [self.max_filter_depth if i > self.max_filter_depth else i for i in self.filter_depths]\n",
    "\n",
    "        # Set up the encoder\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.encoder.append(nn.Sequential(\n",
    "            conv_block(self.n_input_channels, self.start_kernel, activation=self.act_fn_encoder, do_BN=self.do_BN),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            ))\n",
    "\n",
    "        for in_channel, out_channel in zip(self.filter_depths, self.filter_depths[1:]):\n",
    "            self.encoder.append(nn.Sequential(\n",
    "                conv_block(in_channel, out_channel, activation=self.act_fn_encoder, do_BN=self.do_BN),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            ))\n",
    "\n",
    "        # Set up the bottleneck\n",
    "        self.bottleneck = bottleneck(self.filter_depths[-1], self.filter_depths[-1], activation=self.act_fn_bottleneck,\n",
    "                                     do_BN=self.do_BN)\n",
    "\n",
    "        # Set up the decoder\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.filter_depths_up = list(reversed(self.filter_depths))\n",
    "\n",
    "        for in_channel, out_channel in zip(self.filter_depths_up[:-1], self.filter_depths_up[1:]):\n",
    "            self.decoder.append(conv_up_block(in_channel, out_channel, activation=self.act_fn_decoder,\n",
    "                                              up_mode=self.up_mode, do_BN=self.do_BN))\n",
    "        self.decoder.append(upconv(self.filter_depths_up[-1], self.filter_depths_up[-1], up_mode))\n",
    "\n",
    "        # Set up the final layer of the decoder\n",
    "        self.last_layer = conv3x3(self.start_kernel, 1, bias=self.bias_conv_layer)\n",
    "\n",
    "        # Skip connection\n",
    "        self.skipconnect = SkipConnection()\n",
    "\n",
    "        # Batch normalization added to the long residual skip connection\n",
    "        if self.do_outer_skip:\n",
    "            self.layer_outer_skip = nn.ModuleList()\n",
    "            if self.do_outer_skip_BN:\n",
    "                self.layer_outer_skip.append(nn.BatchNorm2d(1))\n",
    "            self.layer_outer_skip.append(SkipConnection())\n",
    "\n",
    "    def forward(self, x, dem):\n",
    "        skip_connections = []\n",
    "        x = torch.cat((x, dem), dim=1)\n",
    "        out = x\n",
    "\n",
    "        # Encoder (save intermediate outputs for skip connections)\n",
    "        for index, layer in enumerate(self.encoder):\n",
    "            layer_conv = layer[:-1]  # all layers before the pooling layer (at depth index)\n",
    "            layer_pool = layer[-1]   # pooling layer (at depth index)\n",
    "\n",
    "            out_before_pool = layer_conv(out)\n",
    "            skip_connections.append(out_before_pool)\n",
    "            out = layer_pool(out_before_pool)\n",
    "\n",
    "        # Bottleneck\n",
    "        out = self.bottleneck(out)\n",
    "\n",
    "        # Decoder + skip connections\n",
    "        index_max = len(self.decoder) - 1\n",
    "        for index, layer in enumerate(self.decoder):\n",
    "            if index <= index_max - 1:\n",
    "                layer_upconv = layer[0]  # upconv layer\n",
    "                layer_conv = layer[1::]  # all other layers (conv, batchnorm, activation)\n",
    "\n",
    "                out_temp = layer_upconv(out)\n",
    "                out = self.skipconnect(skip_connections[-1 - index], out_temp)\n",
    "                out = layer_conv(out)\n",
    "            else:\n",
    "                out_temp = layer(out)   # upconv of last layer\n",
    "                out = self.skipconnect(skip_connections[-1 - index], out_temp)\n",
    "\n",
    "        # Last layer of the decoder\n",
    "        out = self.last_layer(out)\n",
    "\n",
    "        # Add long residual skip connection\n",
    "        if self.do_outer_skip:\n",
    "            if self.layer_outer_skip.__len__() == 2:\n",
    "                # pipe input through a batch normalization layer before adding it to the output of the last\n",
    "                # decoder layer\n",
    "                bn = self.layer_outer_skip[0]\n",
    "                x_0 = x[:, 0, :, :]       # use channel 0 only\n",
    "                x_0 = x_0.unsqueeze(1)\n",
    "                x = bn(x_0)\n",
    "\n",
    "            # add (batchnorm) input to the output of the last decoder layer\n",
    "            add = self.layer_outer_skip[-1]\n",
    "            x_0 = x[:, 0, :, :]\n",
    "            x_0 = x_0.unsqueeze(1)\n",
    "\n",
    "            out = add(x_0, out)  # use channel 0 only\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48cb32d3-6940-44f5-86ce-1b44bd5c28e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (encoder): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (last_layer): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (skipconnect): SkipConnection()\n",
       "  (layer_outer_skip): ModuleList(\n",
       "    (0): SkipConnection()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load previous model\n",
    "model = UNet()\n",
    "model.load_state_dict(torch.load('../../models/noisemodel1.4_174epochs'))\n",
    "model.to('cuda')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2bf63-c7d0-481c-bd43-c7e89d514c4f",
   "metadata": {},
   "source": [
    "### functions for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6801820-3905-4cfa-8a12-eaf55fd9a15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ssim_lists(model, data_loader):\n",
    "    # initialize lists \n",
    "    ssim_list_uncorrected = []\n",
    "    ssim_list_model = []\n",
    "    ssim_list_era5 = []\n",
    "    ssim_list_murp = []\n",
    "    ssim_list_hp = []\n",
    "    \n",
    "    for i, (igram, signal_target, noise_target, dem, era5_corr, murp_corr, hp_corr) in enumerate(data_loader):\n",
    "        # model preds\n",
    "        noise = model(igram.to('cuda'), dem.to('cuda')) #Generate predictions using the model\n",
    "        signal = torch.clamp(igram.to('cpu') - noise.to('cpu'), -1, 1)\n",
    "        \n",
    "        # denormalize\n",
    "        igram = undo_norm(igram.squeeze().detach())\n",
    "        signal = undo_norm(signal.squeeze().detach())\n",
    "        signal_target = undo_norm(signal_target.squeeze().detach())\n",
    "        \n",
    "        # uncorrected SSIM\n",
    "        # calc ssim\n",
    "        ssim_value_uncorrected = ssim(signal_target.numpy(), igram.numpy(), gaussian_weights=True, data_range=(igram.max()-igram.min()).item())\n",
    "        ssim_list_uncorrected.append(ssim_value_uncorrected)\n",
    "        \n",
    "        \n",
    "        # calc ssim\n",
    "        ssim_value_model = ssim(signal_target.numpy(), signal.numpy(), gaussian_weights=True,  data_range=(signal.max()-signal.min()).item())\n",
    "        ssim_list_model.append(ssim_value_model)\n",
    "    \n",
    "        # era5 corrected SSIM\n",
    "        ssim_value_era5 = ssim(signal_target.numpy(), era5_corr.squeeze().numpy(), gaussian_weights=True, data_range=(era5_corr.max()-era5_corr.min()).item())\n",
    "        ssim_list_era5.append(ssim_value_era5)\n",
    "\n",
    "        # murp corrected SSIM\n",
    "        ssim_value_murp = ssim(signal_target.numpy(), murp_corr.squeeze().numpy(), gaussian_weights=True, data_range=(murp_corr.max()-murp_corr.min()).item())\n",
    "        ssim_list_murp.append(ssim_value_murp)\n",
    "    \n",
    "        # hp filter corrected SSIM\n",
    "        ssim_value_hp = ssim(signal_target.numpy(), hp_corr.squeeze().numpy(), gaussian_weights=True, data_range=(hp_corr.max()-hp_corr.min()).item())\n",
    "        ssim_list_hp.append(ssim_value_hp)\n",
    "    \n",
    "    print('mean ssim before correction:', np.mean(ssim_list_uncorrected),\n",
    "          '\\nmean ssim model correction:', np.mean(ssim_list_model), \n",
    "          '\\nmean ssim era5 correction:', np.mean(ssim_list_era5),\n",
    "          '\\nmean ssim murp correction:', np.mean(ssim_list_murp),\n",
    "          '\\nmean ssim high pass filter correction:', np.mean(ssim_list_hp))\n",
    "    \n",
    "    return ssim_list_uncorrected, ssim_list_model, ssim_list_era5, ssim_list_murp, ssim_list_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d818da5-233d-459d-af78-0d864717df92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mse_lists(model, data_loader):\n",
    "    # initialize lists \n",
    "    mse_list_uncorrected = []\n",
    "    mse_list_model = []\n",
    "    mse_list_era5 = []\n",
    "    mse_list_murp = []\n",
    "    mse_list_hp = []\n",
    "    \n",
    "    for i, (igram, signal_target, noise_target, dem, era5_corr, murp_corr, hp_corr) in enumerate(data_loader):\n",
    "        \n",
    "        # model preds\n",
    "        noise = model(igram.to('cuda'), dem.to('cuda')) #Generate predictions using the model\n",
    "        signal = torch.clamp(igram.to('cpu') - noise.to('cpu'), -1, 1).detach()\n",
    "        \n",
    "        # denormalize\n",
    "        igram = undo_norm(igram.squeeze().detach())\n",
    "        signal = undo_norm(signal.squeeze().detach())\n",
    "        signal_target = undo_norm(signal_target.squeeze())\n",
    "        \n",
    "        # uncorrected MSE\n",
    "        # calc ssim\n",
    "        mse_value_uncorrected = mse(signal_target.numpy(), igram.numpy())\n",
    "        mse_list_uncorrected.append(mse_value_uncorrected)\n",
    "    \n",
    "        # Model corrected MSE\n",
    "        # calc ssim\n",
    "        mse_value_model = mse(signal_target.numpy(), signal.numpy())\n",
    "        mse_list_model.append(mse_value_model)\n",
    "    \n",
    "        # era5 corrected MSE\n",
    "        mse_value_era5 = mse(signal_target.numpy(), era5_corr.squeeze().numpy())\n",
    "        mse_list_era5.append(mse_value_era5)\n",
    "\n",
    "        # murp corrected MSE\n",
    "        mse_value_murp = mse(signal_target.numpy(), murp_corr.squeeze().numpy())\n",
    "        mse_list_murp.append(mse_value_murp)\n",
    "    \n",
    "        # hp filter corrected MSE\n",
    "        mse_value_hp = mse(signal_target.numpy(), hp_corr.squeeze().numpy())\n",
    "        mse_list_hp.append(mse_value_hp)\n",
    "    \n",
    "    print('mean rmse before correction:', np.mean(mse_list_uncorrected),\n",
    "          '\\nmean rmse model correction:', np.mean(mse_list_model), \n",
    "          '\\nmean rmse era5 correction:', np.mean(mse_list_era5),\n",
    "          '\\nmean rmse murp correction:', np.mean(mse_list_murp),\n",
    "          '\\nmean rmse high pass filter correction:', np.mean(mse_list_hp))\n",
    "    \n",
    "    return mse_list_uncorrected, mse_list_model, mse_list_era5, mse_list_murp, mse_list_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef91b49-3233-4c8a-b020-b16e6e0020e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate SNR\n",
    "def rms(tensor):\n",
    "    rms = np.sqrt(np.mean(tensor.squeeze().numpy()**2))\n",
    "    return rms\n",
    "\n",
    "def snr(model, data_loader):\n",
    "    snr_list = []\n",
    "\n",
    "    for i, (igram, signal_target, noise_target, dem, era5_corr, murp_corr, hp_corr) in enumerate(data_loader):\n",
    "        igram = undo_norm(igram.squeeze().detach())\n",
    "        signal_target = undo_norm(signal_target.squeeze().detach())\n",
    "        snr_list.append(rms(signal_target)/rms(igram-signal_target))\n",
    "\n",
    "    print('mean snr of images:', np.mean(snr_list), 'stdev of SNR of images:', np.std(snr_list))\n",
    "    \n",
    "    return snr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a868de7d-dd9f-4129-a1a0-ab28742f5928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_for_plotting(snr_list, ssim_list_uncorrected, ssim_list_model, ssim_list_era5, ssim_list_murp, ssim_list_hp):\n",
    "\n",
    "    roll_count = 200\n",
    "    q_low = 25\n",
    "    q_high = 75\n",
    "\n",
    "    ssim_dict = {'snr': snr_list,\n",
    "                 'ssim_uncorrected':ssim_list_uncorrected,\n",
    "                 'ssim_model':ssim_list_model,\n",
    "                 'ssim_era5':ssim_list_era5,\n",
    "                 'ssim_murp':ssim_list_murp,\n",
    "                 'ssim_hp':ssim_list_hp}\n",
    "    ssim_df = pd.DataFrame(ssim_dict)\n",
    "\n",
    "    # uncorrected ssim\n",
    "    ssim_df['ssim_uncorrected_mean'] = ssim_df.sort_values(by=['snr']).ssim_uncorrected.rolling(roll_count, center=True).mean()\n",
    "    ssim_df[f'ssim_uncorrected_q{q_low}'] = ssim_df.sort_values(by=['snr']).ssim_uncorrected.rolling(roll_count, center=True).quantile(quantile=q_low/100)\n",
    "    ssim_df[f'ssim_uncorrected_q{q_high}'] = ssim_df.sort_values(by=['snr']).ssim_uncorrected.rolling(roll_count, center=True).quantile(quantile=q_high/100)\n",
    "\n",
    "    # model corrected ssim\n",
    "    ssim_df['ssim_model_mean'] = ssim_df.sort_values(by=['snr']).ssim_model.rolling(roll_count, center=True).mean()\n",
    "    ssim_df[f'ssim_model_q{q_low}'] = ssim_df.sort_values(by=['snr']).ssim_model.rolling(roll_count, center=True).quantile(quantile=q_low/100)\n",
    "    ssim_df[f'ssim_model_q{q_high}'] = ssim_df.sort_values(by=['snr']).ssim_model.rolling(roll_count, center=True).quantile(quantile=q_high/100)\n",
    "\n",
    "    # era5 corrected ssim\n",
    "    ssim_df['ssim_era5_mean'] = ssim_df.sort_values(by=['snr']).ssim_era5.rolling(roll_count, center=True).mean()\n",
    "    ssim_df[f'ssim_era5_q{q_low}'] = ssim_df.sort_values(by=['snr']).ssim_era5.rolling(roll_count, center=True).quantile(quantile=q_low/100)\n",
    "    ssim_df[f'ssim_era5_q{q_high}'] = ssim_df.sort_values(by=['snr']).ssim_era5.rolling(roll_count, center=True).quantile(quantile=q_high/100)\n",
    "\n",
    "    # murp corrected ssim\n",
    "    ssim_df['ssim_murp_mean'] = ssim_df.sort_values(by=['snr']).ssim_murp.rolling(roll_count, center=True).mean()\n",
    "    ssim_df[f'ssim_murp_q{q_low}'] = ssim_df.sort_values(by=['snr']).ssim_murp.rolling(roll_count, center=True).quantile(quantile=q_low/100)\n",
    "    ssim_df[f'ssim_murp_q{q_high}'] = ssim_df.sort_values(by=['snr']).ssim_murp.rolling(roll_count, center=True).quantile(quantile=q_high/100)\n",
    "\n",
    "    # era5 corrected ssim\n",
    "    ssim_df['ssim_hp_mean'] = ssim_df.sort_values(by=['snr']).ssim_hp.rolling(roll_count, center=True).mean()\n",
    "    ssim_df[f'ssim_hp_q{q_low}'] = ssim_df.sort_values(by=['snr']).ssim_hp.rolling(roll_count, center=True).quantile(quantile=q_low/100)\n",
    "    ssim_df[f'ssim_hp_q{q_high}'] = ssim_df.sort_values(by=['snr']).ssim_hp.rolling(roll_count, center=True).quantile(quantile=q_high/100)\n",
    "    \n",
    "    return ssim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99852bbd-0514-44e7-bb8a-170bf718ed2d",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed7e0678-5f10-4573-980c-ede01725a247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define dataloader for evaluation\n",
    "test_data = dataset(test_list, test_d, transform=my_transforms, blurnoise=True, random_blur=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d39ec6af-b1fc-4039-b45e-d1612b647f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('test data ssim')\n",
    "# test_ssim_list_uncorrected, test_ssim_list_model, test_ssim_list_era5, test_ssim_list_murp, test_ssim_list_hp = ssim_lists(model, test_loader)\n",
    "# print('test data mse')\n",
    "# test_mse_list_uncorrected, test_mse_list_model, test_mse_list_era5, test_mse_list_murp, test_mse_list_hp = mse_lists(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43d9a19c-bd2f-44e3-869f-b4658bf966c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_snr_list = snr(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b7db260-ff5c-4252-8d56-c9746cfd8ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_rmse(value_list, target_list, ylabel, binwidth=0.5, vmax=50000, axmin=-30, axmax=30):\n",
    "    sns.set_theme()\n",
    "    f, ax = plt.subplots(1, 1, figsize=(3,3))\n",
    "\n",
    "    # uncorrected \n",
    "    sns.histplot(ax=ax, x=target_list, y=value_list, \n",
    "                 cmap='Greens', cbar=False, alpha=1, binwidth=binwidth, vmax=vmax)\n",
    "    ax.set_xlabel('target signal')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_box_aspect(1)\n",
    "    ax.set_xlim(axmin, axmax)\n",
    "    ax.set_ylim(axmin, axmax)\n",
    "    f.tight_layout()\n",
    "    \n",
    "\n",
    "    plt.savefig(f'../../figs/{ylabel}_rmse.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "527b7bf5-4913-4b5e-85ee-0ca8df8e390c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def list_plot_uncorrected(data, data_loader):\n",
    "#     # init lists\n",
    "#     uncorrected_list = []\n",
    "#     target_list = []\n",
    "    \n",
    "#     for i, (igram, signal_target, noise_target, dem, era5_corr, murp_corr, hp_corr) in enumerate(data_loader):\n",
    "#         if (i+1)%500 == 0:\n",
    "#             print(f'loop {i+1}/{data.filelength}')\n",
    "            \n",
    "#         igram = undo_norm(igram.squeeze().detach())\n",
    "#         signal_target = undo_norm(signal_target.squeeze())\n",
    "        \n",
    "#         uncorrected_list.extend(igram.flatten())\n",
    "#         target_list.extend(signal_target.flatten())\n",
    "    \n",
    "#     uncorrected_array = np.array(uncorrected_list)\n",
    "#     target_array = np.array(target_list)\n",
    "    \n",
    "#     del uncorrected_list\n",
    "#     del target_list\n",
    "    \n",
    "#     plot_rmse(uncorrected_array, target_array, ylabel='uncorrected')\n",
    "    \n",
    "#     del uncorrected_array\n",
    "#     del target_array\n",
    "        \n",
    "# list_plot_uncorrected(test_data, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a3dfe52-9a79-4818-817c-e0776107a9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def list_plot_model(data, data_loader):\n",
    "#     # init lists\n",
    "#     model_list = []\n",
    "#     target_list = []\n",
    "    \n",
    "#     for i, (igram, signal_target, noise_target, dem, era5_corr, murp_corr, hp_corr) in enumerate(data_loader):\n",
    "#         if (i+1)%500 == 0:\n",
    "#             print(f'loop {i+1}/{data.filelength}')\n",
    "            \n",
    "#         noise_pred = model(igram.to('cuda'), dem.to('cuda')) #Generate predictions using the model\n",
    "#         signal_pred = torch.clamp(igram.to('cpu') - noise_pred.to('cpu'), -1, 1)\n",
    "        \n",
    "#         signal_target = undo_norm(signal_target.squeeze())\n",
    "#         signal_pred = undo_norm(signal_pred.squeeze().detach().to('cpu'))\n",
    "        \n",
    "#         model_list.extend(signal_pred.flatten())\n",
    "#         target_list.extend(signal_target.flatten())\n",
    "    \n",
    "#     model_array = np.array(model_list)\n",
    "#     target_array = np.array(target_list)\n",
    "    \n",
    "#     del model_list\n",
    "#     del target_list\n",
    "    \n",
    "#     plot_rmse(model_array, target_array, ylabel='CNN')\n",
    "    \n",
    "#     del model_array\n",
    "#     del target_array\n",
    "        \n",
    "# list_plot_model(test_data, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c300091e-4b11-41f8-bb9c-b37f5da6da83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def list_plot_era5(data, data_loader):\n",
    "#     # init lists\n",
    "#     era5_list = []\n",
    "#     target_list = []\n",
    "    \n",
    "#     for i, (igram, signal_target, noise_target, dem, era5_corr, murp_corr, hp_corr) in enumerate(data_loader):\n",
    "#         if (i+1)%500 == 0:\n",
    "#             print(f'loop {i+1}/{data.filelength}')\n",
    "        \n",
    "#         signal_target = undo_norm(signal_target.squeeze())\n",
    "        \n",
    "#         era5_list.extend(era5_corr.flatten())\n",
    "#         target_list.extend(signal_target.flatten())\n",
    "    \n",
    "#     era5_array = np.array(era5_list)\n",
    "#     target_array = np.array(target_list)\n",
    "    \n",
    "#     del era5_list\n",
    "#     del target_list\n",
    "    \n",
    "#     plot_rmse(era5_array, target_array, ylabel='ERA5')\n",
    "    \n",
    "#     del era5_array\n",
    "#     del target_array\n",
    "        \n",
    "# list_plot_era5(test_data, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a67067c-9c72-499d-8924-7d14653e840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def list_plot_murp(data, data_loader):\n",
    "#     # init lists\n",
    "#     murp_list = []\n",
    "#     target_list = []\n",
    "    \n",
    "#     for i, (igram, signal_target, noise_target, dem, murp_corr, murp_corr, hp_corr) in enumerate(data_loader):\n",
    "#         if (i+1)%500 == 0:\n",
    "#             print(f'loop {i+1}/{data.filelength}')\n",
    "        \n",
    "#         signal_target = undo_norm(signal_target.squeeze())\n",
    "        \n",
    "#         murp_list.extend(murp_corr.flatten())\n",
    "#         target_list.extend(signal_target.flatten())\n",
    "    \n",
    "#     murp_array = np.array(murp_list)\n",
    "#     target_array = np.array(target_list)\n",
    "    \n",
    "#     del murp_list\n",
    "#     del target_list\n",
    "    \n",
    "#     plot_rmse(murp_array, target_array, ylabel='murp')\n",
    "    \n",
    "#     del murp_array\n",
    "#     del target_array\n",
    "        \n",
    "# list_plot_murp(test_data, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63d87eab-d5e6-472e-89e5-8c8b2eaf18a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 500/2765\n",
      "loop 1000/2765\n",
      "loop 1500/2765\n",
      "loop 2000/2765\n",
      "loop 2500/2765\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def list_plot_hp(data, data_loader):\n",
    "    # init lists\n",
    "    hp_list = []\n",
    "    target_list = []\n",
    "    \n",
    "    for i, (igram, signal_target, noise_target, dem, hp_corr, hp_corr, hp_corr) in enumerate(data_loader):\n",
    "        if (i+1)%500 == 0:\n",
    "            print(f'loop {i+1}/{data.filelength}')\n",
    "        \n",
    "        signal_target = undo_norm(signal_target.squeeze())\n",
    "        \n",
    "        hp_list.extend(hp_corr.flatten())\n",
    "        target_list.extend(signal_target.flatten())\n",
    "    \n",
    "    hp_array = np.array(hp_list)\n",
    "    target_array = np.array(target_list)\n",
    "    \n",
    "    del hp_list\n",
    "    del target_list\n",
    "    \n",
    "    plot_rmse(hp_array, target_array, ylabel='hp')\n",
    "    \n",
    "    del hp_array\n",
    "    del target_array\n",
    "        \n",
    "list_plot_hp(test_data, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3191a779-7d17-457f-b6c1-7890e0792d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_ssim_df=df_for_plotting(test_snr_list, test_ssim_list_uncorrected, test_ssim_list_model, test_ssim_list_era5, test_ssim_list_murp, test_ssim_list_hp)\n",
    "# test_mse_df=df_for_plotting(test_snr_list, test_mse_list_uncorrected, test_mse_list_model, test_mse_list_era5, test_mse_list_murp, test_mse_list_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3e80b31-4e7e-4811-9dfe-42e498839ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # can't plot exactly 0 snr due to log scale\n",
    "# test_ssim_df_clean = test_ssim_df[test_ssim_df.snr != 0]\n",
    "# test_mse_df_clean = test_mse_df[test_mse_df.snr != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b2a0c72-e828-4676-82e8-07df24aa9e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.set_theme()\n",
    "\n",
    "# f, ax = plt.subplots(1, 5, figsize=(10,4), sharex=True, sharey=True)\n",
    "\n",
    "# # val uncorrected \n",
    "# sns.histplot(ax=ax[0], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_uncorrected, cmap='Oranges', cbar=False, alpha=0)\n",
    "# ax[0].set_xscale('log')\n",
    "\n",
    "# sns.histplot(ax=ax[0], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_uncorrected, cmap='Oranges', cbar=False,\n",
    "#              bins=30, vmax=50, alpha=0.8)\n",
    "# ax[0].set_xscale('log')\n",
    "# ax[0].set_ylabel('SSIM')\n",
    "# ax[0].set_xlabel('SNR')\n",
    "# ax[0].set_title('uncorrected')\n",
    "\n",
    "# sns.lineplot(ax=ax[0], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_uncorrected_mean, size=1, c='k', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[0], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_uncorrected_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[0], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_uncorrected_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# # val model corrected\n",
    "# sns.histplot(ax=ax[1], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_model, cmap='Oranges', cbar=False,\n",
    "#              bins=30, vmax=50, alpha=0.8)\n",
    "# ax[1].set_xscale('log')\n",
    "# ax[1].set_ylabel('SSIM')\n",
    "# ax[1].set_xlabel('SNR')\n",
    "# ax[1].set_title('CNN')\n",
    "\n",
    "# sns.lineplot(ax=ax[1], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_model_mean, size=1, c='k', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[1], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_model_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[1], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_model_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# # val era5 corrected\n",
    "# sns.histplot(ax=ax[2], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_era5, cmap='Oranges', cbar=False,\n",
    "#              bins=30, vmax=50, alpha=0.8)\n",
    "# ax[2].set_xscale('log')\n",
    "# ax[2].set_ylabel('SSIM')\n",
    "# ax[2].set_xlabel('SNR')\n",
    "# ax[2].set_title('ERA5')\n",
    "\n",
    "# sns.lineplot(ax=ax[2], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_era5_mean, size=1, c='k', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[2], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_era5_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[2], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_era5_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# # val murp corrected\n",
    "# sns.histplot(ax=ax[3], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_murp, cmap='Oranges', cbar=False,\n",
    "#              bins=30, vmax=50, alpha=0.8)\n",
    "# ax[3].set_xscale('log')\n",
    "# ax[3].set_ylabel('SSIM')\n",
    "# ax[3].set_xlabel('SNR')\n",
    "# ax[3].set_title('MuRP')\n",
    "\n",
    "# sns.lineplot(ax=ax[3], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_murp_mean, size=1, c='k', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[3], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_murp_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[3], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_murp_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "\n",
    "# # val hp corrected\n",
    "# sns.histplot(ax=ax[4], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_hp, cmap='Oranges', cbar=False,\n",
    "#              bins=30, vmax=50, alpha=0.8)\n",
    "# ax[4].set_xscale('log')\n",
    "# ax[4].set_xlabel('SNR')\n",
    "# ax[4].set_ylabel('SSIM')\n",
    "# ax[4].set_title('low-pass filter')\n",
    "\n",
    "# sns.lineplot(ax=ax[4], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_hp_mean, size=1, c='k', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[4], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_hp_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[4], x=test_ssim_df_clean.snr, y=test_ssim_df_clean.ssim_hp_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# #plt.savefig('SSIMv2.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae88f24d-eb96-4c6c-b6d5-b7d9d852f098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.set_theme()\n",
    "\n",
    "# f, ax = plt.subplots(1, 5, figsize=(10,5), sharex=True, sharey=True)\n",
    "\n",
    "# # val uncorrected \n",
    "# sns.histplot(ax=ax[0], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_uncorrected, cmap='Oranges', cbar=False, alpha=0)\n",
    "# ax[0].set_xscale('log')\n",
    "# ax[0].set_yscale('log')\n",
    "\n",
    "# sns.histplot(ax=ax[0], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_uncorrected, cmap='Oranges', cbar=False,\n",
    "#              bins=30, vmax=50, alpha=0.8)\n",
    "# ax[0].set_xscale('log')\n",
    "# ax[0].set_yscale('log')\n",
    "# ax[0].set_ylabel('MSE')\n",
    "# ax[0].set_title('uncorrected')\n",
    "\n",
    "# sns.lineplot(ax=ax[0], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_uncorrected_mean, size=1, c='k', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[0], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_uncorrected_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[0], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_uncorrected_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# # val model corrected\n",
    "# sns.histplot(ax=ax[1], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_model, cmap='Oranges', cbar=False,\n",
    "#              bins=30, vmax=50, alpha=0.8)\n",
    "# ax[1].set_xscale('log')\n",
    "# ax[1].set_yscale('log')\n",
    "# ax[1].set_ylabel('MSE')\n",
    "# ax[1].set_title('CNN')\n",
    "\n",
    "# sns.lineplot(ax=ax[1], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_model_mean, size=1, c='k', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[1], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_model_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[1], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_model_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# # val era5 corrected\n",
    "# sns.histplot(ax=ax[2], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_era5, cmap='Oranges', cbar=False,\n",
    "#              bins=30, vmax=50, alpha=0.8)\n",
    "# ax[2].set_xscale('log')\n",
    "# ax[2].set_yscale('log')\n",
    "# ax[2].set_ylabel('MSE')\n",
    "# ax[2].set_title('ERA5')\n",
    "\n",
    "# sns.lineplot(ax=ax[2], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_era5_mean, size=1, c='k', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[2], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_era5_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[2], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_era5_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# # val murp corrected\n",
    "# sns.histplot(ax=ax[3], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_murp, cmap='Oranges', cbar=False,\n",
    "#              bins=30, vmax=50, alpha=0.8)\n",
    "# ax[3].set_xscale('log')\n",
    "# ax[3].set_yscale('log')\n",
    "# ax[3].set_ylabel('MSE')\n",
    "# ax[3].set_title('MuRP')\n",
    "\n",
    "# sns.lineplot(ax=ax[3], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_murp_mean, size=1, c='k', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[3], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_murp_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[3], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_murp_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "\n",
    "# # val hp corrected\n",
    "# sns.histplot(ax=ax[4], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_hp, cmap='Oranges', cbar=False,\n",
    "#              bins=30, vmax=50, alpha=0.8)\n",
    "# ax[4].set_xscale('log')\n",
    "# ax[4].set_yscale('log')\n",
    "# ax[4].set_xlabel('SNR')\n",
    "# ax[4].set_ylabel('MSE')\n",
    "# ax[4].set_title('low-pass filter')\n",
    "\n",
    "# sns.lineplot(ax=ax[4], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_hp_mean, size=1, c='k', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[4], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_hp_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "# sns.lineplot(ax=ax[4], x=test_mse_df_clean.snr, y=test_mse_df_clean.ssim_hp_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# #plt.savefig('SSIMv2.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a386cf3e-ea35-490e-8600-4e804f6716b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # convert to long format for more plotting\n",
    "# ssim_labels = ['ssim_uncorrected',  'ssim_model', 'ssim_era5', 'ssim_murp', 'ssim_hp']\n",
    "# test_ssim_long = pd.melt(test_ssim_df[ssim_labels], value_vars=ssim_labels, var_name='corr_type', value_name='ssim')\n",
    "# test_ssim_long['dataset'] = 'test'\n",
    "\n",
    "# # convert to long format for more plotting\n",
    "# ssim_labels = ['ssim_uncorrected',  'ssim_model', 'ssim_era5', 'ssim_murp', 'ssim_hp']\n",
    "# test_mse_long = pd.melt(test_mse_df[ssim_labels], value_vars=ssim_labels, var_name='corr_type', value_name='mse')\n",
    "# test_mse_long['dataset'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4c0e094-e352-498b-b9be-6aa853454dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #histplots \n",
    "# sns.set_theme()\n",
    "# f, ax = plt.subplots(1, 1, figsize=(8,3))\n",
    "\n",
    "# sns.kdeplot(ax=ax, data=test_ssim_long, x='ssim', hue='corr_type', \n",
    "#             hue_order=['ssim_hp', 'ssim_era5', 'ssim_murp', 'ssim_model', 'ssim_uncorrected'], \n",
    "#             palette=['peru', 'orange', 'gold', 'blue', 'red'], fill=True, legend=False)\n",
    "\n",
    "# ax.set_xlim((-0.25, 0.8))\n",
    "# ax.set_xlabel('SSIM')\n",
    "# ax.set_ylabel('kernel density')\n",
    "# f.tight_layout()\n",
    "# #plt.savefig('ssim_kde.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07f582b7-40bd-4928-ae6f-1d58a8034180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #histplots \n",
    "# sns.set_theme()\n",
    "# f, ax = plt.subplots(1, 1, figsize=(8,3))\n",
    "\n",
    "# sns.kdeplot(ax=ax, data=test_mse_long, x='mse', hue='corr_type', \n",
    "#             hue_order=['ssim_hp', 'ssim_era5', 'ssim_murp', 'ssim_model', 'ssim_uncorrected'], \n",
    "#             palette=['peru', 'orange', 'gold', 'blue', 'red'], fill=True, legend=False)\n",
    "\n",
    "# ax.set_xlim((-0.25, 1))\n",
    "# ax.set_xlabel('MSE')\n",
    "# ax.set_ylabel('kernel density')\n",
    "# f.tight_layout()\n",
    "# #plt.savefig('ssim_kde.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
