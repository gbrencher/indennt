{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0a9712-533a-498e-b602-f445bfebc3e7",
   "metadata": {},
   "source": [
    "# Generate subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ace461-37cd-4125-9ce4-831bebedf876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "from glob import glob\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b84828-afd2-49ed-a78e-cf56cccd64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in single igram and other data \n",
    "def hyp3_to_xarray_single(path):\n",
    "    '''\n",
    "    Reads hyp3 outputs into xarray dataset from single hyp3 folder \n",
    "    '''\n",
    "    # globs for data to load\n",
    "    unw_phase_path = glob(f'{path}/*unw_phase.tif')[0]\n",
    "    era5_path = glob(f'{path}/*ERA5.tif')[0]\n",
    "    murp_path = glob(f'{path}/*MuRP.tif')[0]\n",
    "    dem_path = glob(f'{path}/*dem.tif')[0]\n",
    "    corr_path = glob(f'{path}/*corr.tif')[0]\n",
    "    meta_path = glob(f'{path}/S1*.txt')[0]\n",
    "\n",
    "    # list granules for coordinate\n",
    "    granule = os.path.split(unw_phase_path)[-1][0:-14]\n",
    "\n",
    "    d = {}\n",
    "    with open(meta_path) as f:\n",
    "        for line in f:\n",
    "            (key, val) = line.split(':')\n",
    "            d[key] = str.strip(val)\n",
    "\n",
    "    # read unw_phase into data array and assign coordinates\n",
    "    da = xr.open_dataset(unw_phase_path)\n",
    "    da = da.assign_coords({'granule':('granule', [granule])})\n",
    "    for item in d.keys():\n",
    "            da = da.assign_coords({item:('granule', [d[item]])})\n",
    "    \n",
    "    # concatenate into dataset and rename variable\n",
    "    ds = da.rename({'band_data': 'unw_phase'})\n",
    "\n",
    "    #open coherence and dem into datasets\n",
    "    era5_ds = xr.open_dataset(era5_path)\n",
    "    murp_ds = xr.open_dataset(murp_path)\n",
    "    dem_ds = xr.open_dataset(dem_path)\n",
    "    corr_ds = xr.open_dataset(corr_path)\n",
    "\n",
    "    # add coherence and dem to unw_phase dataset\n",
    "    ds['era5_phase'] = (('band', 'y', 'x'), era5_ds.band_data.values)\n",
    "    ds['murp_phase'] = (('band', 'y', 'x'), murp_ds.band_data.values)\n",
    "    ds['elevation'] = (('band', 'y', 'x'), dem_ds.band_data.values)\n",
    "    ds['coherence'] = (('band', 'y', 'x'), era5_ds.band_data.values)\n",
    "\n",
    "    # remove band coordinate\n",
    "    ds = ds.squeeze()\n",
    "\n",
    "    return ds\n",
    "\n",
    "def sample_ds(ds, subset_size=128):\n",
    "    minx = 0\n",
    "    miny = 0\n",
    "    maxx = len(ds.x)-subset_size\n",
    "    maxy = len(ds.y)-subset_size\n",
    "\n",
    "    sub_minx = random.randint(minx, maxx)\n",
    "    sub_miny = random.randint(miny, maxy)\n",
    "    subset = ds.isel(x=slice(sub_minx, sub_minx+subset_size), y=slice(sub_miny, sub_miny+subset_size))\n",
    "    \n",
    "    return subset\n",
    "\n",
    "# set local ref with coherence, not in use currently\n",
    "def subset_ref(subset_ds, corr_thresh=0.95):\n",
    "    atmo_noise = subset_ds.signal.values[np.where(subset_ds.coherence >= corr_thresh, [subset_ds.signal, np.nan])].median(dim=['x', 'y'])\n",
    "    subset_ds['signal'] = subset_ds['signal'] - atmo_noise\n",
    "    return subset_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3312b03-855a-48da-9ad7-7154f1950e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_refs(ds, corr_thresh, n_refs):\n",
    "    ref_list = []\n",
    "    ref_counter = 0\n",
    "    while ref_counter < n_refs:\n",
    "        x, y = np.random.randint(0, len(ds.x)), np.random.randint(0, len(ds.y))\n",
    "        if ds.signal_corr.isel(x=x, y=y) >= corr_thresh:\n",
    "            ref_list.append([x, y])\n",
    "            ref_counter +=1\n",
    "    return ref_list\n",
    "\n",
    "def sample_refs(ds, refs):\n",
    "    ref_phase = []\n",
    "    ref_elevation = []\n",
    "    for ref in refs:\n",
    "        ref_elevation.append(ds.elevation.isel(x=ref[0], y=ref[1]).item())\n",
    "        ref_phase.append(ds.signal.isel(x=ref[0], y=ref[1]).item())\n",
    "    return ref_phase, ref_elevation\n",
    "\n",
    "def linear_fits(ds, ref_phase, ref_elevation):\n",
    "    model = linear_model.LinearRegression() \n",
    "    inputs = np.array((ref_elevation, ref_phase)).transpose()\n",
    "    inputs = inputs[~np.isnan(inputs).any(axis=1)]\n",
    "    model.fit(inputs[:, 0].reshape(-1, 1), inputs[:, 1])\n",
    "    fits = [model.coef_.item(), model.intercept_]\n",
    "    return fits\n",
    "\n",
    "def correct_igrams(ds, fits):\n",
    "    slope, intercept = fits[0], fits[1]\n",
    "    ds['signal_MuRP'] = ds.signal - (ds.elevation.values*slope+intercept)\n",
    "    return ds\n",
    "\n",
    "# single function\n",
    "def MuRP(ds, corr_thresh=0.7, n_refs=100):\n",
    "    '''\n",
    "    Correct unwrapped phase with linear fit to multiple stable reference points\n",
    "    '''\n",
    "    #print('selecting reference points')\n",
    "    refs = select_refs(ds, corr_thresh=corr_thresh, n_refs=n_refs)\n",
    "    \n",
    "    #print('sampling reference points')\n",
    "    ref_values, ref_elevation = sample_refs(ds, refs)\n",
    "    \n",
    "    #print('calculating linear fits')\n",
    "    fits = linear_fits(ds, ref_values, ref_elevation)\n",
    "    \n",
    "    #print('correcting interferograms')\n",
    "    ds = correct_igrams(ds, fits)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82687ba4-a5c6-49b4-b82e-57e54175ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_noise(orbit_list, \n",
    "                 frame_list, \n",
    "                 year_list, \n",
    "                 subsets_desired, \n",
    "                 subset_type,\n",
    "                 subset_size=128, \n",
    "                 max_time_s=1,\n",
    "                 max_per_tile=2):\n",
    "    '''\n",
    "    subset hyp3 outputs using tiles\n",
    "    '''\n",
    "    \n",
    "    home_path = '/mnt/d/indennt'\n",
    "    # set number of subsets to 0\n",
    "    subset_counter = 0\n",
    "    granules_sampled = []\n",
    "    tiles = gpd.read_file(f'{home_path}/polygons/{subset_type}_RGI_grid_25km.shp')\n",
    "    \n",
    "    # continue to run until desired subset number is reached\n",
    "    while subset_counter < subsets_desired:\n",
    "        for orbit in orbit_list:\n",
    "            signal_path = f'{home_path}/signal_maps/{orbit}'\n",
    "            random.shuffle(frame_list)\n",
    "            for frame in frame_list:\n",
    "                random.shuffle(year_list)\n",
    "                for year in year_list:\n",
    "                    data_path = f'{home_path}/hyp3/{orbit}/{frame}/{year}'\n",
    "                    granule_list = glob(f'{data_path}/*P012*/')\n",
    "\n",
    "                    #with open('granules_sampled.pkl', 'rb') as f:\n",
    "                        #granules_sampled = pickle.load(f)\n",
    "                    \n",
    "                    # loop through noise maps\n",
    "                    random.shuffle(granule_list)\n",
    "                    for granule_path in granule_list:\n",
    "                        ds = hyp3_to_xarray_single(granule_path)\n",
    "                        \n",
    "                        #if ds.granule.item() in granules_sampled:\n",
    "                            #print(f'granule {ds.granule.item()} already sampled')\n",
    "                            #continue \n",
    "                        \n",
    "                        print(f'working on {orbit}, {frame}, {year}, {ds.granule.item()}')\n",
    "                        granule_counter=0\n",
    "                        \n",
    "                        signal_ds = xr.open_mfdataset(glob(f'{signal_path}/{orbit}_mean_signal_masked.tif'))\n",
    "                        corr_ds = xr.open_mfdataset(glob(f'{signal_path}/{orbit}_mean_corr.tif'))\n",
    "                        signal_ds = signal_ds.rio.clip_box(minx=ds.x.min(), miny=ds.y.min(), maxx=ds.x.max(), maxy=ds.y.max())\n",
    "                        corr_ds = corr_ds.rio.clip_box(minx=ds.x.min(), miny=ds.y.min(), maxx=ds.x.max(), maxy=ds.y.max())\n",
    "                        signal_ds = signal_ds.rio.reproject_match(ds.unw_phase, nodata=np.nan).squeeze()\n",
    "                        corr_ds = corr_ds.rio.reproject_match(ds.unw_phase, nodata=np.nan).squeeze()\n",
    "\n",
    "                        ds['signal'] = (('y', 'x'), signal_ds.band_data.values)\n",
    "                        ds['signal_corr'] = (('y', 'x'), corr_ds.band_data.values)\n",
    "            \n",
    "                        # loop through tiles\n",
    "                        tiles = tiles.sample(frac=1)\n",
    "                        for i, tile in tiles.iterrows():\n",
    "                            tile_counter = 0\n",
    "                            \n",
    "                            # clip to tile extent\n",
    "                            try:\n",
    "                                tile_ds = ds.rio.clip([tiles.iloc[i].geometry], crs=ds.rio.crs, drop=True)\n",
    "                            except: #except if tile does not overlap interferogram\n",
    "                                #print(f'no valid subsets in tile {i}')\n",
    "                                continue\n",
    "                            else:\n",
    "                                #check if valid subset exists in tile\n",
    "                                if np.invert(np.isnan(tile_ds.unw_phase.values)).sum() < subset_size**2:\n",
    "                                    #print(f'no valid subsets in tile {i}')\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    timeout = time.time() + max_time_s # set time to spend on each tile\n",
    "                                    # try to find appropriate subsets for a while\n",
    "                                    while time.time() < timeout:\n",
    "                                        # grab random subset within sample \n",
    "                                        subset_ds = sample_ds(tile_ds, subset_size)\n",
    "                                        \n",
    "                                        # test if subset elevation is above treeline\n",
    "                                        if np.median(subset_ds.elevation.values) >= 3300:\n",
    "                                            if (subset_ds.signal_corr > 0.85).sum() >= 100:\n",
    "                                                # interpolate small gaps\n",
    "                                                unw_phase_ds = subset_ds.unw_phase.interpolate_na(dim='x', use_coordinate=False)\n",
    "                                                unw_phase_ds = unw_phase_ds.interpolate_na(dim='y', use_coordinate=False)\n",
    "                                                \n",
    "                                                # murp also has gaps to be interpolated, the rest do not\n",
    "                                                murp_phase_ds = subset_ds.murp_phase.interpolate_na(dim='x', use_coordinate=False)\n",
    "                                                murp_phase_ds = murp_phase_ds.interpolate_na(dim='y', use_coordinate=False)\n",
    "            \n",
    "                                                # check if data gaps remain in subset\n",
    "                                                nan_count = (np.isnan(subset_ds.elevation.values).sum() + \n",
    "                                                             np.isnan(subset_ds.era5_phase.values).sum() +\n",
    "                                                             np.isnan(murp_phase_ds.values).sum() +\n",
    "                                                             np.isnan(subset_ds.signal.values).sum() +\n",
    "                                                             np.isnan(unw_phase_ds.values).sum())\n",
    "                \n",
    "                                                if nan_count == 0:\n",
    "                                                    subset_counter+=1\n",
    "                                                    tile_counter+=1\n",
    "                                                    granule_counter+=1\n",
    "                                                    subset_name = f'tile{i}_{orbit}_{ds.granule.item()[5:13]}_{ds.granule.item()[21:29]}_sub{subset_counter}.tif'\n",
    "            \n",
    "                                                    # calculate era5 and murp noise\n",
    "                                                    murp_noise = unw_phase_ds - murp_phase_ds\n",
    "                                                    era5_noise = unw_phase_ds - subset_ds.era5_phase\n",
    "            \n",
    "                                                    # center signal on 0 (effective local reference point)\n",
    "                                                    #subset_ds['signal'] = subset_ds['signal'] - subset_ds['signal'].median(dim=['x', 'y'])\n",
    "    \n",
    "                                                    # murp to correct signal maps\n",
    "                                                    subset_ds = MuRP(subset_ds)\n",
    "                                                    \n",
    "                                                    # save subset\n",
    "                                                    #unw_phase_ds.rio.to_raster(f'{home_path}/{subset_type}_subsets/noise/{subset_name}')\n",
    "                                                    #murp_noise.rio.to_raster(f'{home_path}/{subset_type}_subsets/murp/{subset_name}')\n",
    "                                                    #era5_noise.rio.to_raster(f'{home_path}/{subset_type}_subsets/era5/{subset_name}')\n",
    "                                                    #subset_ds.elevation.rio.to_raster(f'{home_path}/{subset_type}_subsets/dem/{subset_name}')\n",
    "                                                    #subset_ds.signal_MuRP.rio.to_raster(f'{home_path}/{subset_type}_subsets/signal/{subset_name}')\n",
    "                                                    if subset_counter >= subsets_desired:\n",
    "                                                        print('desired number of subsets reached, exiting')\n",
    "                                                        return\n",
    "                                                    if tile_counter >= max_per_tile:\n",
    "                                                        break\n",
    "                            #print(f'tile {i} subsets: {tile_counter}')\n",
    "                        print(f'{ds.granule.item()} subsets: {granule_counter}')\n",
    "                        granules_sampled.append(ds.granule.item())\n",
    "                        \n",
    "                        # save list of granules sampled\n",
    "                        with open('granules_sampled.pkl', 'wb') as f:\n",
    "                            pickle.dump(granules_sampled, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1bf11c1-beec-49be-a659-63df5a7c5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_list = ['DT56', 'AT151']\n",
    "year_list = ['2017', '2018', '2019', '2020', '2021', '2022']\n",
    "frame_list = ['frame_1', 'frame_2', 'frame_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5368274-19d2-43de-a13d-08649617e1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on DT56, frame_2, 2021, S1AA_20210914T130956_20210926T130957_VVP012_INT40_G_ueF_1D98\n"
     ]
    }
   ],
   "source": [
    "subset_noise(orbit_list, \n",
    "             frame_list, \n",
    "             year_list, \n",
    "             subsets_desired=40000, \n",
    "             subset_type='train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gda]",
   "language": "python",
   "name": "conda-env-gda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
