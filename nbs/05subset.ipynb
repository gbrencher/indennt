{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0a9712-533a-498e-b602-f445bfebc3e7",
   "metadata": {},
   "source": [
    "# Generate subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ace461-37cd-4125-9ce4-831bebedf876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "import rioxarray\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from glob import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b84828-afd2-49ed-a78e-cf56cccd64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in single igram and other data \n",
    "def hyp3_to_xarray_single(path):\n",
    "    '''\n",
    "    Reads hyp3 outputs into xarray dataset from single hyp3 folder \n",
    "    '''\n",
    "    # globs for data to load\n",
    "    unw_phase_path = glob(f'{path}/*unw_phase.tif')[0]\n",
    "    era5_path = glob(f'{path}/*ERA5.tif')[0]\n",
    "    murp_path = glob(f'{path}/*MuRP.tif')[0]\n",
    "    dem_path = glob(f'{path}/*dem.tif')[0]\n",
    "    corr_path = glob(f'{path}/*corr.tif')[0]\n",
    "    meta_path = glob(f'{path}/S1*.txt')[0]\n",
    "\n",
    "    # list granules for coordinate\n",
    "    granule = os.path.split(unw_phase_path)[-1][0:-14]\n",
    "\n",
    "    d = {}\n",
    "    with open(meta_path) as f:\n",
    "        for line in f:\n",
    "            (key, val) = line.split(':')\n",
    "            d[key] = str.strip(val)\n",
    "\n",
    "    # read unw_phase into data array and assign coordinates\n",
    "    da = xr.open_dataset(unw_phase_path)\n",
    "    da = da.assign_coords({'granule':('granule', [granule])})\n",
    "    for item in d.keys():\n",
    "            da = da.assign_coords({item:('granule', [d[item]])})\n",
    "    \n",
    "    # concatenate into dataset and rename variable\n",
    "    ds = da.rename({'band_data': 'unw_phase'})\n",
    "\n",
    "    #open coherence and dem into datasets\n",
    "    era5_ds = xr.open_dataset(era5_path)\n",
    "    murp_ds = xr.open_dataset(murp_path)\n",
    "    dem_ds = xr.open_dataset(dem_path)\n",
    "    corr_ds = xr.open_dataset(corr_path)\n",
    "\n",
    "    # add coherence and dem to unw_phase dataset\n",
    "    ds['era5_phase'] = (('band', 'y', 'x'), era5_ds.band_data.values)\n",
    "    ds['murp_phase'] = (('band', 'y', 'x'), murp_ds.band_data.values)\n",
    "    ds['elevation'] = (('band', 'y', 'x'), dem_ds.band_data.values)\n",
    "    ds['coherence'] = (('band', 'y', 'x'), era5_ds.band_data.values)\n",
    "\n",
    "    # remove band coordinate\n",
    "    ds = ds.squeeze()\n",
    "\n",
    "    return ds\n",
    "\n",
    "def sample_ds(ds, subset_size=128):\n",
    "    minx = 0\n",
    "    miny = 0\n",
    "    maxx = len(ds.x)-subset_size\n",
    "    maxy = len(ds.y)-subset_size\n",
    "\n",
    "    sub_minx = random.randint(minx, maxx)\n",
    "    sub_miny = random.randint(miny, maxy)\n",
    "    subset = ds.isel(x=slice(sub_minx, sub_minx+subset_size), y=slice(sub_miny, sub_miny+subset_size))\n",
    "    \n",
    "    return subset\n",
    "\n",
    "# set local ref with coherence, not in use currently\n",
    "def subset_ref(subset_ds, corr_thresh=0.95):\n",
    "    atmo_noise = subset_ds.signal.values[np.where(subset_ds.coherence >= corr_thresh, [subset_ds.signal, np.nan]).median(dim=['x', 'y'])\n",
    "    subset_ds.signal = subset_ds.signal - atmo_noise\n",
    "    return subset_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82687ba4-a5c6-49b4-b82e-57e54175ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_noise(orbit_list, \n",
    "                 frame_list, \n",
    "                 year_list, \n",
    "                 subsets_desired, \n",
    "                 subset_type,\n",
    "                 subset_size=128, \n",
    "                 max_time_s=5,\n",
    "                 max_per_tile=5):\n",
    "    '''\n",
    "    subset hyp3 outputs using tiles\n",
    "    '''\n",
    "    \n",
    "    home_path = '/mnt/d/indennt'\n",
    "    # set number of subsets to 0\n",
    "    subset_counter = 0\n",
    "    tiles = gpd.read_file(f'{home_path}/polygons/{subset_type}_RGI_grid_25km.shp')\n",
    "    tiles = gpd.read_file(tiles_path)\n",
    "    \n",
    "    # continue to run until desired subset number is reached\n",
    "    while subset_counter < subsets_desired:\n",
    "        for orbit in orbit_list:\n",
    "            signal_path = f'{home_path}/signal_maps/{orbit}'\n",
    "            signal_ds = xr.open_dataset(f'{signal_path}/{orbit}_mean_signal.tif')\n",
    "            #corr_ds = xr.open_dataset(f'{signal_path}/{orbit}_mean_corr.tif')\n",
    "            random.shuffle(frame_list)\n",
    "            for frame in frame_list:\n",
    "                random.shuffle(year_list)\n",
    "                for year in year_list:\n",
    "                    data_path = f'{home_path}/hyp3/{orbit}/{frame}/{year}'\n",
    "                    granule_list = glob(f'{data_path}/*P012*/')\n",
    "                    \n",
    "                    # loop through noise maps\n",
    "                    random.shuffle(granule_list)\n",
    "                    for granule_path in granule_list:\n",
    "                        ds = hyp3_to_xarray_single(granule_path)\n",
    "                        print(f'working on {ds.granule.item()}')\n",
    "                        local_signal_ds = signal_ds.rio.reproject_match(ds.unw_phase, nodata=np.nan)\n",
    "                        #local_corr_ds = corr_ds.rio.reproject_match(ds.unw_phase, nodata=np.nan)\n",
    "                        ds['signal'] = (('y', 'x'), local_signal_ds.band_data.values)\n",
    "                        #ds['signal_corr'] = (('y', 'x'), local_corr_ds.band_data.values)\n",
    "            \n",
    "                        # loop through tiles\n",
    "                        tiles = tiles.sample(frac=1)\n",
    "                        for i, tile in tiles.iterrows():\n",
    "                            tile_counter = 0\n",
    "                            \n",
    "                            # clip to tile extent\n",
    "                            try:\n",
    "                                tile_ds = ds.rio.clip([tiles.iloc[i].geometry], crs=ds.rio.crs, drop=True)\n",
    "                            except: #except if tile does not overlap interferogram\n",
    "                                print(f'no valid subsets in tile {i}')\n",
    "                                continue\n",
    "                            else:\n",
    "                                #check if valid subset exists in tile\n",
    "                                if np.invert(np.isnan(tile_ds.unw_phase.values)).sum() < subset_size**2:\n",
    "                                    print(f'no valid subsets in tile {i}')\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    timeout = time.time() + max_time_s # set time to spend on each tile\n",
    "                                    # try to find appropriate subsets for a while\n",
    "                                    while time.time() < timeout:\n",
    "                                        # grab random subset within sample \n",
    "                                        subset_ds = sample_ds(tile_ds, subset_size)\n",
    "                                        \n",
    "                                        # test if subset elevation is above treeline\n",
    "                                        if np.median(subset_ds.elevation.values) > 3300:\n",
    "                                            # interpolate small gaps\n",
    "                                            unw_phase_ds = subset_ds.unw_phase.interpolate_na(dim='x', use_coordinate=False)\n",
    "                                            unw_phase_ds = unw_phase_ds.interpolate_na(dim='y', use_coordinate=False)\n",
    "                                            \n",
    "                                            # murp also has gaps to be interpolated, the rest do not\n",
    "                                            murp_phase_ds = subset_ds.murp_phase.interpolate_na(dim='x', use_coordinate=False)\n",
    "                                            murp_phase_ds = murp_phase_ds.interpolate_na(dim='y', use_coordinate=False)\n",
    "        \n",
    "                                            # check if data gaps remain in subset\n",
    "                                            nan_count = (np.isnan(subset_ds.elevation.values).sum() + \n",
    "                                                         np.isnan(subset_ds.era5_phase.values).sum() +\n",
    "                                                         np.isnan(murp_phase_ds.values).sum() +\n",
    "                                                         np.isnan(subset_ds.signal.values).sum() +\n",
    "                                                         np.isnan(unw_phase_ds.values).sum())\n",
    "            \n",
    "                                            if nan_count == 0:\n",
    "                                                subset_counter+=1\n",
    "                                                tile_counter+=1\n",
    "                                                subset_name = f'tile{i}_{orbit}_{ds.granule.item()[5:13]}_{ds.granule.item()[21:29]}_sub{subset_counter}.tif'\n",
    "        \n",
    "                                                # calculate era5 and murp noise\n",
    "                                                murp_noise = unw_phase_ds - murp_phase_ds\n",
    "                                                era5_noise = unw_phase_ds - subset_ds.era5_phase\n",
    "        \n",
    "                                                # center signal on 0 (effective local reference point)\n",
    "                                                subset_ds['signal'] = subset_ds['signal'] - subset_ds['signal'].median(dim=['x', 'y'])\n",
    "        \n",
    "                                                \n",
    "                                                # save subset\n",
    "                                                unw_phase_ds.rio.to_raster(f'{home_path}/{subset_type}_subsets/noise/{subset_name}')\n",
    "                                                murp_noise.rio.to_raster(f'{home_path}/{subset_type}_subsets/murp/{subset_name}')\n",
    "                                                era5_noise.rio.to_raster(f'{home_path}/{subset_type}_subsets/era5/{subset_name}')\n",
    "                                                subset_ds.elevation.rio.to_raster(f'{home_path}/{subset_type}_subsets/dem/{subset_name}')\n",
    "                                                subset_ds.signal.rio.to_raster(f'{home_path}/{subset_type}_subsets/signal/{subset_name}')\n",
    "                                                if subset_counter >= subsets_desired:\n",
    "                                                    return\n",
    "                                                if tile_counter >= max_per_tile:\n",
    "                                                    break\n",
    "                            print(f'tile {i} subsets: {tile_counter}')\n",
    "                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bf11c1-beec-49be-a659-63df5a7c5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_list = ['DT56']\n",
    "year_list = ['2017']\n",
    "frame_list = ['frame_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1552915e-2d93-497b-9a8c-c299b0a5b437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on S1AA_20170923T131000_20171005T131000_VVP012_INT40_G_ueF_0EE0\n",
      "tile 65 subsets: 5\n",
      "tile 59 subsets: 5\n",
      "no valid subsets in tile 55\n",
      "no valid subsets in tile 72\n",
      "no valid subsets in tile 57\n",
      "no valid subsets in tile 25\n",
      "tile 42 subsets: 5\n",
      "tile 24 subsets: 5\n",
      "tile 8 subsets: 5\n",
      "no valid subsets in tile 14\n",
      "tile 36 subsets: 5\n",
      "no valid subsets in tile 4\n",
      "no valid subsets in tile 1\n",
      "no valid subsets in tile 22\n",
      "tile 75 subsets: 5\n",
      "no valid subsets in tile 10\n",
      "no valid subsets in tile 26\n",
      "tile 5 subsets: 0\n",
      "no valid subsets in tile 43\n",
      "tile 15 subsets: 5\n",
      "tile 30 subsets: 5\n",
      "no valid subsets in tile 70\n",
      "tile 76 subsets: 5\n",
      "no valid subsets in tile 34\n",
      "tile 68 subsets: 5\n",
      "tile 46 subsets: 0\n",
      "no valid subsets in tile 77\n",
      "tile 21 subsets: 0\n",
      "no valid subsets in tile 12\n",
      "no valid subsets in tile 69\n",
      "no valid subsets in tile 9\n",
      "tile 2 subsets: 5\n",
      "no valid subsets in tile 48\n",
      "no valid subsets in tile 23\n",
      "tile 63 subsets: 5\n",
      "no valid subsets in tile 6\n",
      "no valid subsets in tile 40\n",
      "no valid subsets in tile 17\n",
      "tile 61 subsets: 5\n",
      "tile 16 subsets: 5\n",
      "no valid subsets in tile 19\n",
      "no valid subsets in tile 7\n",
      "tile 67 subsets: 5\n",
      "tile 64 subsets: 5\n",
      "no valid subsets in tile 66\n",
      "no valid subsets in tile 60\n",
      "tile 31 subsets: 5\n",
      "tile 44 subsets: 5\n",
      "tile 20 subsets: 5\n",
      "tile 58 subsets: 5\n",
      "no valid subsets in tile 33\n",
      "no valid subsets in tile 47\n",
      "no valid subsets in tile 73\n",
      "tile 0 subsets: 5\n",
      "tile 41 subsets: 0\n",
      "no valid subsets in tile 62\n",
      "no valid subsets in tile 56\n",
      "tile 52 subsets: 0\n",
      "no valid subsets in tile 50\n",
      "tile 37 subsets: 5\n",
      "tile 32 subsets: 0\n",
      "tile 39 subsets: 0\n",
      "tile 11 subsets: 0\n",
      "no valid subsets in tile 29\n",
      "no valid subsets in tile 71\n",
      "no valid subsets in tile 18\n",
      "tile 35 subsets: 0\n",
      "tile 3 subsets: 0\n",
      "no valid subsets in tile 38\n",
      "tile 45 subsets: 5\n",
      "no valid subsets in tile 13\n",
      "no valid subsets in tile 51\n",
      "tile 53 subsets: 5\n",
      "tile 74 subsets: 5\n",
      "no valid subsets in tile 49\n",
      "no valid subsets in tile 28\n",
      "no valid subsets in tile 27\n",
      "tile 54 subsets: 5\n",
      "working on S1AA_20170911T131000_20170923T131000_VVP012_INT40_G_ueF_50D9\n",
      "no valid subsets in tile 41\n",
      "tile 61 subsets: 5\n",
      "tile 7 subsets: 0\n",
      "no valid subsets in tile 77\n",
      "no valid subsets in tile 33\n",
      "tile 22 subsets: 0\n",
      "no valid subsets in tile 24\n",
      "tile 73 subsets: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subset_noise(orbit_list, \n",
    "             frame_list,\n",
    "             year_list,\n",
    "             subsets_desired=20,\n",
    "             subset_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5368274-19d2-43de-a13d-08649617e1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gda]",
   "language": "python",
   "name": "conda-env-gda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
