{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f7bb06e-6e63-4d64-b7d6-8ccb6c97757b",
   "metadata": {},
   "source": [
    "# MintPy for signal maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c766f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import mintpy\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ed07a6-5cd1-428e-8e7b-aa8eebec1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_list = ['AT151']\n",
    "year_list = ['2017', '2018', '2019', '2020', '2021', '2022']\n",
    "frame_list = ['frame_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910045f-42cf-4bf6-8c42-abda85c05b03",
   "metadata": {},
   "source": [
    "## clip files to common extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ec0ec07-2bfd-4a78-b90a-df7ea38c24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_overlap(file_list: List[Union[str, Path]]) -> List[float]:\n",
    "    \"\"\"Get the common overlap of  a list of GeoTIFF files\n",
    "    \n",
    "    Arg:\n",
    "        file_list: a list of GeoTIFF files\n",
    "    \n",
    "    Returns:\n",
    "         [ulx, uly, lrx, lry], the upper-left x, upper-left y, lower-right x, and lower-right y\n",
    "         corner coordinates of the common overlap\n",
    "    \"\"\"\n",
    "    \n",
    "    corners = [gdal.Info(str(dem), format='json')['cornerCoordinates'] for dem in file_list]\n",
    "\n",
    "    ulx = max(corner['upperLeft'][0] for corner in corners)\n",
    "    uly = min(corner['upperLeft'][1] for corner in corners)\n",
    "    lrx = min(corner['lowerRight'][0] for corner in corners)\n",
    "    lry = max(corner['lowerRight'][1] for corner in corners)\n",
    "    return [ulx, uly, lrx, lry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8aeb241-e1b8-404d-b156-11177471a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_hyp3_products_to_common_overlap(data_path: Union[str, Path], overlap: List[float]) -> None:\n",
    "    \"\"\"Clip all GeoTIFF files to their common overlap\n",
    "    \n",
    "    Args:\n",
    "        data_dir:\n",
    "            directory containing the GeoTIFF files to clip\n",
    "        overlap:\n",
    "            a list of the upper-left x, upper-left y, lower-right-x, and lower-tight y\n",
    "            corner coordinates of the common overlap\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    \n",
    "    files_for_mintpy = ['_water_mask.tif', '_corr.tif', '_unw_phase_MuRP.tif', '_dem.tif', '_lv_theta.tif', '_lv_phi.tif']\n",
    "\n",
    "    for extension in files_for_mintpy:\n",
    "        print(f'working on {extension}') \n",
    "        for file in data_path.rglob(f'*{extension}'):\n",
    "\n",
    "            dst_file = file.parent / f'{file.stem}_clipped{file.suffix}'\n",
    "\n",
    "            gdal.Translate(destName=str(dst_file), srcDS=str(file), projWin=overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dc256-88c0-4ac9-88aa-4ee420ca1e1d",
   "metadata": {},
   "source": [
    "## Mintpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033276cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write to MintPy config file\n",
    "def write_config_file(out_file, CONFIG_TXT, mode='a'): \n",
    "    \"\"\"Write configuration files for MintPy to process products\"\"\"\n",
    "    if not os.path.isfile(out_file) or mode == 'w':\n",
    "        with open(out_file, \"w\") as fid:\n",
    "            fid.write(CONFIG_TXT)\n",
    "        print('write configuration to file: {}'.format(out_file))\n",
    "    else:\n",
    "        with open(out_file, \"a\") as fid:\n",
    "            fid.write(\"\\n\" + CONFIG_TXT)\n",
    "        print('add the following to file: \\n{}'.format(CONFIG_TXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42499563-1225-4427-8863-4ef390300f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clip files and run mintpy for multiple years \n",
    "def mintpy_multiyear(orbit_list, year_list, frame_list, clip=True, mintpy=True, clean_clip=True):\n",
    "    # hardcoded paths for now \n",
    "    home_path_d = '/mnt/d/indennt'\n",
    "    home_path = '/mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data'\n",
    "    for orbit in orbit_list:\n",
    "        for frame in frame_list:\n",
    "            for year in year_list:\n",
    "                print(f'working on {orbit}, {frame}, {year}')\n",
    "                data_path = f'{home_path_d}/hyp3/{orbit}/{frame}/{year}'\n",
    "                mintpy_path = f'{home_path}/signal_mintpy/{orbit}/{frame}/mintpy_{year}'\n",
    "                mintpy_path_d = f'{home_path_d}/signal_mintpy/{orbit}/{frame}/'\n",
    "    \n",
    "                if clip==True:\n",
    "                    # identify and crop to common overlap\n",
    "                    print('identifying common overlap')\n",
    "                    dem_files = Path(data_path).glob('*/*_dem.tif')\n",
    "                    overlap = get_common_overlap(dem_files)\n",
    "                    print('clipping to common overlap')\n",
    "                    clip_hyp3_products_to_common_overlap(Path(data_path), overlap)\n",
    "    \n",
    "                # make output dir for mintpy\n",
    "                if not os.path.exists(mintpy_path):\n",
    "                    os.mkdir(mintpy_path)\n",
    "    \n",
    "                # write config file for mintpy\n",
    "                CONFIG_TXT = f'''# vim: set filetype=cfg:\n",
    "                ##----------------------------- hyp3 ---------------------##\n",
    "                mintpy.load.processor        = hyp3\n",
    "                ##---------interferogram datasets:\n",
    "                mintpy.load.unwFile          = {data_path}/*/*{year}*unw_phase_MuRP_clipped.tif\n",
    "                mintpy.load.corFile          = {data_path}/*/*{year}*corr_clipped.tif\n",
    "                ##---------geometry datasets:\n",
    "                mintpy.load.demFile          = {data_path}/*/*{year}*dem_clipped.tif\n",
    "                mintpy.load.incAngleFile     = {data_path}/*/*{year}*lv_theta_clipped.tif\n",
    "                mintpy.load.waterMaskFile    = {data_path}/*/*{year}*water_mask_clipped.tif\n",
    "                \n",
    "                mintpy.deramp                = linear\n",
    "                mintpy.reference.lalo        = auto\n",
    "                mintpy.troposphericDelay.method   = no\n",
    "                \n",
    "                mintpy.compute.cluster    = local\n",
    "                mintpy.compute.numWorker  = 6\n",
    "                '''\n",
    "                \n",
    "                os.chdir(mintpy_path)\n",
    "                config_file = f'{mintpy_path}/{frame}_{year}_Sen{orbit}.txt'\n",
    "                write_config_file(config_file, CONFIG_TXT, mode='w')\n",
    "    \n",
    "                if mintpy==True:\n",
    "                    # run mintpy\n",
    "                    print('starting mintpy')\n",
    "                    !smallbaselineApp.py --dir {mintpy_path} {config_file}\n",
    "                    print('moving outputs to drive')\n",
    "                    !cp -r $mintpy_path $mintpy_path_d && rm -R $mintpy_path\n",
    "    \n",
    "                if clean_clip==True:\n",
    "                    # remove clipped files\n",
    "                    print('removing clipped files')\n",
    "                    clipped_files = f'{data_path}/*/*_clipped.tif'\n",
    "                    !rm {clipped_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf39b43-8dac-40e1-b054-406c9e8706a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on AT151, frame_3, 2017\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase_MuRP.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/frame_3_2017_SenAT151.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-06-21 20:17:01.415557--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: frame_3_2017_SenAT151\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/frame_3_2017_SenAT151.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2017/*/*2017*unw_phase_MuRP_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2017/*/*2017*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2017/*/*2017*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2017/*/*2017*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2017/*/*2017*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy frame_3_2017_SenAT151.txt to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg      to inputs   directory for backup.\n",
      "copy frame_3_2017_SenAT151.txt to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg      to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/frame_3_2017_SenAT151.txt --project frame_3_2017_SenAT151\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2017/*/*2017*unw_phase_MuRP_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2017/*/*2017*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2017/*/*2017*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2017/*/*2017*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2017/*/*2017*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3/AT151/frame_3/2017/S1BB_20170608T010056_20170702T010057_VVP024_INT40_G_ueF_0B6E/S1BB_20170608T010056_20170702T010057_VVP024_INT40_G_ueF_0B6E_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3/AT151/frame_3/2017/S1BB_20170608T010056_20170702T010057_VVP024_INT40_G_ueF_0B6E/S1BB_20170608T010056_20170702T010057_VVP024_INT40_G_ueF_0B6E_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3/AT151/frame_3/2017/S1BB_20170608T010056_20170702T010057_VVP024_INT40_G_ueF_0B6E/S1BB_20170608T010056_20170702T010057_VVP024_INT40_G_ueF_0B6E_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5763, 7269) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5763, 7269) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5763, 7269) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20170608T010056_20170702T010057_VVP024_INT40_G_ueF_0B6E_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5763, 7269) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3/AT151/frame_3/2017/*/*2017*unw_phase_MuRP_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3/AT151/frame_3/2017/*/*2017*corr_clipped.tif\n",
      "number of unwrapPhase     : 26\n",
      "number of coherence       : 26\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (26, 5763, 7269) with compression = None\n",
      "[==================================================] 20170924_20171006  125s /     5s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (26, 5763, 7269) with compression = None\n",
      "[==================================================] 20170924_20171006  114s /     4s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (26, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (26,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (26,)\n",
      "add extra metadata: {'PROJECT_NAME': 'frame_3_2017_SenAT151', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 05 mins 3.9 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file frame_3_2017_SenAT151.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file frame_3_2017_SenAT151.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5763, 7269)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 26/26   11s /     0s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 9\n",
      "number of interferograms: 26\n",
      "shift all perp baseline by 4.808229446411133 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 26\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 95.20 m\n",
      "max temporal      baseline: 60.0 days\n",
      "showing coherence\n",
      "data range: [0.53471506, 0.73807204]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 26/26   17s /     0s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5763, 7269)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/maskConnComp.h5\n",
      "time used: 00 mins 19.8 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   17s /     4s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5763, 7269)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/avgSpatialCoh.h5\n",
      "time used: 00 mins 25.3 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5 ...\n",
      "[=========>              20%                       ] lines 1440/5763    0s /     0s/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/objects/stack.py:1059: RuntimeWarning: Mean of empty slice\n",
      "  dmean[r0:r1, :] = np.nanmean(data, axis=0)\n",
      "[==================================================] lines 5763/5763   21s /     5s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (1886, 4523)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5\n",
      "{'REF_Y': '1886', 'REF_X': '4523', 'REF_LAT': '4244220.0', 'REF_LON': '451100.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   28s /     7s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5763, 7269)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/avgPhaseVelocity.h5\n",
      "time used: 00 mins 38.8 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 26\n",
      "number of triplets: 34\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (720, 7269), 9 blocks in total\n",
      "reference pixel in y/x: (1886, 4523) from dataset: unwrapPhase\n",
      "[==================================================] line 5760 / 5763   52s /     6s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5763, 7269)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/numTriNonzeroIntAmbiguity.png\n",
      "time used: 00 mins 58.1 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (1886, 4523) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 26\n",
      "number of acquisitions  : 9\n",
      "number of lines   : 5763\n",
      "number of columns : 7269\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (9,)                 with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (9,)                 with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (9, 5763, 7269)      with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5763, 7269)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5763, 7269)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5763 lines into 4 patches for processing\n",
      "    with each patch up to 1450 lines\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7269\n",
      "box length: 1450\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1212, 1450]\n",
      "submit a job to the worker for sub box 1: [1212, 0, 2424, 1450]\n",
      "submit a job to the worker for sub box 2: [2424, 0, 3636, 1450]\n",
      "submit a job to the worker for sub box 3: [3636, 0, 4848, 1450]\n",
      "submit a job to the worker for sub box 4: [4848, 0, 6060, 1450]\n",
      "submit a job to the worker for sub box 5: [6060, 0, 7269, 1450]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 0, 1212, 1450] * 26 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2424, 0, 3636, 1450] * 26 ...\n",
      "reading coherence in [1212, 0, 2424, 1450] * 26 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6060, 0, 7269, 1450] * 26 ...\n",
      "reading coherence in [4848, 0, 6060, 1450] * 26 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3636, 0, 4848, 1450] * 26 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 1 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 2 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 4 / 18\n",
      "chunk 3 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 5 / 18\n",
      "chunk 4 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 6 / 18\n",
      "chunk 5 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 8 / 18\n",
      "chunk 7 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [1212, 0, 2424, 1450] * 26 ...\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [0, 0, 1212, 1450] * 26 ...\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [2424, 0, 3636, 1450] * 26 ...\n",
      "chunk 18 / 18\n",
      "chunk 18 / 18\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [3636, 0, 4848, 1450] * 26 ...\n",
      "reading unwrapPhase in [4848, 0, 6060, 1450] * 26 ...\n",
      "reading unwrapPhase in [6060, 0, 7269, 1450] * 26 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 625104 out of 1757400 (35.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 1051138 out of 1757400 (59.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1157859 out of 1757400 (65.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 307966 out of 1757400 (17.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 449320 out of 1753050 (25.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]number of pixels to invert: 1171650 out of 1757400 (66.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 307966/307966 pixels   135s /   332s\n",
      "[======================= 68% =====>                ] 305800/449320 pixels  135s /    63sconverting LOS phase unit from radian to meter\n",
      "[======================= 68% =====>                ] 306000/449320 pixels  136s /    64ss\n",
      "FUTURE #1 complete. Time used: 149 seconds\n",
      "[==================================================] 449320/449320 pixels   193s /   301s\n",
      "[===================>    39%                       ] 452400/1171650 pixels  192s /   301sconverting LOS phase unit from radian to meter\n",
      "[===================>    39%                       ] 450000/1157859 pixels  193s /   302s\n",
      "FUTURE #2 complete. Time used: 206 seconds\n",
      "[==================================================] 625104/625104 pixels   246s /   164s\n",
      "[======================= 60% =>                    ] 626000/1051138 pixels  246s /   164sconverting LOS phase unit from radian to meter\n",
      "[======================= 54%                       ] 628200/1171650 pixels  245s /   209s\n",
      "FUTURE #3 complete. Time used: 259 seconds\n",
      "[==================================================] 1051138/1051138 pixels  367s /    40s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 90% ================>     ] 1037600/1157859 pixels  368s /    40s\n",
      "FUTURE #4 complete. Time used: 381 seconds\n",
      "[==================================================] 1157859/1157859 pixels  393s /     8s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1168200/1171650 pixels\n",
      "FUTURE #5 complete. Time used: 410 seconds\n",
      "[==================================================] 1171650/1171650 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 411 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 9, 0, 1450, 0, 7269]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 1450, 0, 7269]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 1450, 0, 7269]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 06 mins 55.8 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7269\n",
      "box length: 1450\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1450, 1212, 2900]\n",
      "submit a job to the worker for sub box 1: [1212, 1450, 2424, 2900]\n",
      "submit a job to the worker for sub box 2: [2424, 1450, 3636, 2900]\n",
      "submit a job to the worker for sub box 3: [3636, 1450, 4848, 2900]\n",
      "submit a job to the worker for sub box 4: [4848, 1450, 6060, 2900]\n",
      "submit a job to the worker for sub box 5: [6060, 1450, 7269, 2900]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2424, 1450, 3636, 2900] * 26 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 1450, 1212, 2900] * 26 ...\n",
      "reading coherence in [1212, 1450, 2424, 2900] * 26 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4848, 1450, 6060, 2900] * 26 ...\n",
      "reading coherence in [6060, 1450, 7269, 2900] * 26 ...\n",
      "reading coherence in [3636, 1450, 4848, 2900] * 26 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 18\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 1 / 18\n",
      "chunk 2 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 2 / 18\n",
      "chunk 3 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 3 / 18\n",
      "chunk 4 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 4 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 5 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 6 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 7 / 18\n",
      "chunk 8 / 18\n",
      "chunk 9 / 18\n",
      "chunk 8 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 8 / 18\n",
      "chunk 9 / 18\n",
      "chunk 10 / 18\n",
      "chunk 9 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 9 / 18\n",
      "chunk 10 / 18\n",
      "chunk 11 / 18\n",
      "chunk 10 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 10 / 18\n",
      "chunk 11 / 18\n",
      "chunk 12 / 18\n",
      "chunk 11 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 11 / 18\n",
      "chunk 12 / 18\n",
      "chunk 13 / 18\n",
      "chunk 12 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 12 / 18\n",
      "chunk 13 / 18\n",
      "chunk 14 / 18\n",
      "chunk 13 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 13 / 18\n",
      "chunk 14 / 18\n",
      "chunk 15 / 18\n",
      "chunk 14 / 18\n",
      "chunk 15 / 18\n",
      "chunk 14 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [2424, 1450, 3636, 2900] * 26 ...\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [1212, 1450, 2424, 2900] * 26 ...\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [0, 1450, 1212, 2900] * 26 ...\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [4848, 1450, 6060, 2900] * 26 ...\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 18 / 18\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [6060, 1450, 7269, 2900] * 26 ...\n",
      "reading unwrapPhase in [3636, 1450, 4848, 2900] * 26 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 1146487 out of 1757400 (65.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1753276 out of 1757400 (99.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1757400 out of 1757400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 898888 out of 1753050 (51.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1757399 out of 1757400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1757400 out of 1757400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 898888/898888 pixels   406s /   375s\n",
      "[======================= 50%                       ] 886600/1757400 pixels  406s /   406sconverting LOS phase unit from radian to meter\n",
      "[======================= 78% ==========>           ] 898000/1146487 pixels  407s /   114s\n",
      "FUTURE #1 complete. Time used: 419 seconds\n",
      "[==================================================] 1146487/1146487 pixels  499s /   257s\n",
      "[======================= 64% ===>                  ] 1132200/1757400 pixels  499s /   281sconverting LOS phase unit from radian to meter\n",
      "[======================= 64% ===>                  ] 1132400/1757400 pixels  499s /   281s\n",
      "FUTURE #2 complete. Time used: 512 seconds\n",
      "[==================================================] 1757400/1757400 pixels  683s /    13s\n",
      "[==================================================] 1751400/1757399 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1739600/1753276 pixels  683s /    13s\n",
      "FUTURE #3 complete. Time used: 696 seconds\n",
      "[==================================================] 1757399/1757399 pixels  685s /    13s\n",
      "[======================= 98% ====================> ] 1723200/1757400 pixels  685s /    13sconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1745600/1753276 pixels  685s /    13s\n",
      "FUTURE #4 complete. Time used: 698 seconds\n",
      "[==================================================] 1753276/1753276 pixels  687s /    14s\n",
      "[======================= 98% ====================> ] 1731000/1757400 pixels  687s /    14sconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1731400/1757400 pixels\n",
      "FUTURE #5 complete. Time used: 700 seconds\n",
      "[==================================================] 1757400/1757400 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 707 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 9, 1450, 2900, 0, 7269]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [1450, 2900, 0, 7269]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [1450, 2900, 0, 7269]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 18 mins 47.5 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7269\n",
      "box length: 1450\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2900, 1212, 4350]\n",
      "submit a job to the worker for sub box 1: [1212, 2900, 2424, 4350]\n",
      "submit a job to the worker for sub box 2: [2424, 2900, 3636, 4350]\n",
      "submit a job to the worker for sub box 3: [3636, 2900, 4848, 4350]\n",
      "submit a job to the worker for sub box 4: [4848, 2900, 6060, 4350]\n",
      "submit a job to the worker for sub box 5: [6060, 2900, 7269, 4350]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 2900, 1212, 4350] * 26 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2424, 2900, 3636, 4350] * 26 ...\n",
      "reading coherence in [6060, 2900, 7269, 4350] * 26 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1212, 2900, 2424, 4350] * 26 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3636, 2900, 4848, 4350] * 26 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4848, 2900, 6060, 4350] * 26 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 18 / 18\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [6060, 2900, 7269, 4350] * 26 ...\n",
      "reading unwrapPhase in [1212, 2900, 2424, 4350] * 26 ...\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [4848, 2900, 6060, 4350] * 26 ...\n",
      "chunk 18 / 18\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [3636, 2900, 4848, 4350] * 26 ...\n",
      "reading unwrapPhase in [2424, 2900, 3636, 4350] * 26 ...\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [0, 2900, 1212, 4350] * 26 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 1259975 out of 1753050 (71.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1757400 out of 1757400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1757400 out of 1757400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 825698 out of 1757400 (47.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1757400 out of 1757400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1757400 out of 1757400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 825698/825698 pixels   379s /   427s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 47%                       ] 825200/1757400 pixels  379s /   427s\n",
      "FUTURE #1 complete. Time used: 393 seconds\n",
      "[==================================================] 1259975/1259975 pixels  548s /   235s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 72% =======>              ] 1259800/1757400 pixels  549s /   213s\n",
      "FUTURE #2 complete. Time used: 563 seconds\n",
      "[==================================================] 1757400/1757400 pixels  710s /    21s\n",
      "[======================= 97% ===================>  ] 1710600/1757400 pixels  710s /    21sconverting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 1710800/1757400 pixels  710s /    21s\n",
      "FUTURE #3 complete. Time used: 724 seconds\n",
      "[==================================================] 1757400/1757400 pixels  711s /    14s\n",
      "[======================= 98% ====================> ] 1713600/1757400 pixels  711s /    14sconverting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 1713800/1757400 pixels  711s /    14s\n",
      "FUTURE #4 complete. Time used: 725 seconds\n",
      "[==================================================] 1757400/1757400 pixels  716s /    14s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1757000/1757400 pixels\n",
      "FUTURE #5 complete. Time used: 738 seconds\n",
      "[==================================================] 1757400/1757400 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 738 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 9, 2900, 4350, 0, 7269]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [2900, 4350, 0, 7269]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [2900, 4350, 0, 7269]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 31 mins 10.3 secs.\n",
      "\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7269\n",
      "box length: 1413\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4350, 1212, 5763]\n",
      "submit a job to the worker for sub box 1: [1212, 4350, 2424, 5763]\n",
      "submit a job to the worker for sub box 2: [2424, 4350, 3636, 5763]\n",
      "submit a job to the worker for sub box 3: [3636, 4350, 4848, 5763]\n",
      "submit a job to the worker for sub box 4: [4848, 4350, 6060, 5763]\n",
      "submit a job to the worker for sub box 5: [6060, 4350, 7269, 5763]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1212, 4350, 2424, 5763] * 26 ...\n",
      "reading coherence in [3636, 4350, 4848, 5763] * 26 ...\n",
      "reading coherence in [2424, 4350, 3636, 5763] * 26 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6060, 4350, 7269, 5763] * 26 ...\n",
      "reading coherence in [0, 4350, 1212, 5763] * 26 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4848, 4350, 6060, 5763] * 26 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 18 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "chunk 1 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 2 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 3 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 4 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 5 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 6 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 7 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 8 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 9 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 10 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 11 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 12 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 13 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 14 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 15 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 16 / 18\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 18 / 18\n",
      "chunk 17 / 18\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [1212, 4350, 2424, 5763] * 26 ...\n",
      "reading unwrapPhase in [2424, 4350, 3636, 5763] * 26 ...\n",
      "chunk 17 / 18\n",
      "chunk 17 / 18\n",
      "chunk 18 / 18\n",
      "chunk 17 / 18\n",
      "reading unwrapPhase in [4848, 4350, 6060, 5763] * 26 ...\n",
      "chunk 18 / 18\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [3636, 4350, 4848, 5763] * 26 ...\n",
      "reading unwrapPhase in [6060, 4350, 7269, 5763] * 26 ...\n",
      "chunk 18 / 18\n",
      "reading unwrapPhase in [0, 4350, 1212, 5763] * 26 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 1053706 out of 1712556 (61.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1101044 out of 1712556 (64.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 408632 out of 1712556 (23.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 598513 out of 1712556 (34.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 260597 out of 1708317 (15.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 984392 out of 1712556 (57.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 260597/260597 pixels   122s /   410s\n",
      "[======================= 62% ==>                   ] 251600/408632 pixels  122s /    75sconverting LOS phase unit from radian to meter\n",
      "[======================= 62% ==>                   ] 251800/408632 pixels  122s /    75ss\n",
      "FUTURE #1 complete. Time used: 136 seconds\n",
      "[==================================================] 408632/408632 pixels   185s /   303s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================>     38%                       ] 413400/1101044 pixels  185s /   303s\n",
      "FUTURE #2 complete. Time used: 200 seconds\n",
      "[==================================================] 598513/598513 pixels   246s /   210s\n",
      "[======================= 61% =>                    ] 595600/984392 pixels  246s /   157sconverting LOS phase unit from radian to meter\n",
      "[======================= 54%                       ] 594000/1101044 pixels  246s /   210s\n",
      "FUTURE #3 complete. Time used: 260 seconds\n",
      "[==================================================] 984392/984392 pixels   356s /    30s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 92% =================>    ] 973800/1053706 pixels  356s /    31s\n",
      "FUTURE #4 complete. Time used: 370 seconds\n",
      "[==================================================] 1053706/1053706 pixels  376s /    15s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 96% ===================>  ] 1054600/1101044 pixels  376s /    15s\n",
      "FUTURE #5 complete. Time used: 390 seconds\n",
      "[==================================================] 1101044/1101044 pixels  383s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 400 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 9, 4350, 5763, 0, 7269]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4350, 5763, 0, 7269]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4350, 5763, 0, 7269]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 37 mins 55.4 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (1886, 4523)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 26\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 37 mins 55.5 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5763, 7269)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/maskTempCoh.h5\n",
      "time used: 00 mins 1.6 secs.\n",
      "number of reliable pixels: 15612098\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (9,)                 with compression = None\n",
      "create dataset  : date       of |S8                       in size of (9,)                 with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (9, 5763, 7269)      with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 9/9   54s /     6s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 1.7 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5763, 7269)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (9,)                 with compression = None\n",
      "create dataset  : date       of |S8                       in size of (9,)                 with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (9, 5763, 7269)      with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (9,)                 with compression = None\n",
      "create dataset  : date       of |S8                       in size of (9,)                 with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (9, 5763, 7269)      with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 3 --------------\n",
      "box width:  7269\n",
      "box length: 1921\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1212, 1921]\n",
      "submit a job to the worker for sub box 1: [1212, 0, 2424, 1921]\n",
      "submit a job to the worker for sub box 2: [2424, 0, 3636, 1921]\n",
      "submit a job to the worker for sub box 3: [3636, 0, 4848, 1921]\n",
      "submit a job to the worker for sub box 4: [4848, 0, 6060, 1921]\n",
      "submit a job to the worker for sub box 5: [6060, 0, 7269, 1921]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1617058 out of 2328252 (69.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1723258 out of 2328252 (74.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 698685 out of 2328252 (30.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1186872 out of 2328252 (51.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 698770 out of 2322489 (30.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1737192 out of 2328252 (74.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 698685/698685   163s /   208s\n",
      "\n",
      "FUTURE #1 complete. Time used: 168 seconds\n",
      "[==================================================] 698770/698770   164s /   209s\n",
      "[=====================>  44%                       ] 714000/1617058  165s /   210s\n",
      "FUTURE #2 complete. Time used: 170 seconds\n",
      "[==================================================] 1186872/1186872  244s /    81s\n",
      "[======================= 75% =========>            ] 1212000/1617058  245s /    81s\n",
      "FUTURE #3 complete. Time used: 250 seconds\n",
      "[==================================================] 1617058/1617058  301s /    45s\n",
      "[======================= 88% ===============>      ] 1508000/1723258  301s /    41s\n",
      "FUTURE #4 complete. Time used: 306 seconds\n",
      "[==================================================] 1737192/1737192  322s /     9s\n",
      "[======================= 97% ===================>  ] 1672000/1723258  322s /     9s\n",
      "FUTURE #5 complete. Time used: 327 seconds\n",
      "[==================================================] 1723258/1723258  325s /     6s\n",
      "\n",
      "FUTURE #6 complete. Time used: 333 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1921, 0, 7269]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 9, 0, 1921, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 9, 0, 1921, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 3 --------------\n",
      "box width:  7269\n",
      "box length: 1921\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1921, 1212, 3842]\n",
      "submit a job to the worker for sub box 1: [1212, 1921, 2424, 3842]\n",
      "submit a job to the worker for sub box 2: [2424, 1921, 3636, 3842]\n",
      "submit a job to the worker for sub box 3: [3636, 1921, 4848, 3842]\n",
      "submit a job to the worker for sub box 4: [4848, 1921, 6060, 3842]\n",
      "submit a job to the worker for sub box 5: [6060, 1921, 7269, 3842]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 2328252 out of 2328252 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1313968 out of 2328252 (56.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 2328252 out of 2328252 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1419598 out of 2322489 (61.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 2328252 out of 2328252 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 2328250 out of 2328252 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 1313968/1313968  311s /   235s\n",
      "[======================= 58% >                     ] 1356000/2328252  311s /   225s\n",
      "FUTURE #1 complete. Time used: 316 seconds\n",
      "[==================================================] 1419598/1419598  329s /   219s\n",
      "[======================= 61% =>                    ] 1414000/2328252  330s /   211s\n",
      "FUTURE #2 complete. Time used: 335 seconds\n",
      "[==================================================] 2328252/2328252  474s /     9s\n",
      "[==================================================] 2320000/2328250  473s /     9s\n",
      "FUTURE #3 complete. Time used: 478 seconds\n",
      "[==================================================] 2328250/2328250  475s /     9s\n",
      "[======================= 98% ====================> ] 2282000/2328252  475s /     9s\n",
      "FUTURE #4 complete. Time used: 480 seconds\n",
      "[==================================================] 2328252/2328252  476s /     9s\n",
      "[==================================================] 2310000/2328252\n",
      "FUTURE #5 complete. Time used: 483 seconds\n",
      "[==================================================] 2328252/2328252 \n",
      "\n",
      "FUTURE #6 complete. Time used: 486 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1921, 3842, 0, 7269]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 9, 1921, 3842, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 9, 1921, 3842, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 3 --------------\n",
      "box width:  7269\n",
      "box length: 1921\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 3842, 1212, 5763]\n",
      "submit a job to the worker for sub box 1: [1212, 3842, 2424, 5763]\n",
      "submit a job to the worker for sub box 2: [2424, 3842, 3636, 5763]\n",
      "submit a job to the worker for sub box 3: [3636, 3842, 4848, 5763]\n",
      "submit a job to the worker for sub box 4: [4848, 3842, 6060, 5763]\n",
      "submit a job to the worker for sub box 5: [6060, 3842, 7269, 5763]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1664581 out of 2328252 (71.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1712420 out of 2328252 (73.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1208799 out of 2328252 (51.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 661470 out of 2328252 (28.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1595809 out of 2328252 (68.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 736795 out of 2322489 (31.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 661470/661470   162s /   132s\n",
      "[===================>    40%                       ] 662000/1664581  162s /   243s\n",
      "FUTURE #1 complete. Time used: 167 seconds\n",
      "[==================================================] 736795/736795   174s /   231s\n",
      "[=====================>  43%                       ] 720000/1664581  174s /   231s\n",
      "FUTURE #2 complete. Time used: 179 seconds\n",
      "[==================================================] 1208799/1208799  255s /    89s\n",
      "[======================= 71% =======>              ] 1214000/1712420  256s /   104s\n",
      "FUTURE #3 complete. Time used: 261 seconds\n",
      "[==================================================] 1595809/1595809  315s /     9s\n",
      "[======================= 96% ===================>  ] 1640000/1712420  315s /    13s\n",
      "FUTURE #4 complete. Time used: 320 seconds\n",
      "[==================================================] 1664581/1664581  320s /     6s\n",
      "[==================================================] 1690000/1712420\n",
      "FUTURE #5 complete. Time used: 326 seconds\n",
      "[==================================================] 1712420/1712420 \n",
      "\n",
      "FUTURE #6 complete. Time used: 329 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [3842, 5763, 0, 7269]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 9, 3842, 5763, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 9, 3842, 5763, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 19 mins 28.6 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (9,)                 with compression = None\n",
      "create dataset  : date       of |S8                       in size of (9,)                 with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (9, 5763, 7269)      with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 9/9   54s /     6s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 2.1 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 9/9   30s /     3s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20171006 - 0.0049\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0246)\n",
      "None.\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20171006\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 9, 0, 5763, 0, 7269)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20171006\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 9, 0, 5763, 0, 7269)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20171006\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 9, 0, 5763, 0, 7269)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20171006\n",
      "time used: 00 mins 37.3 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: []\n",
      "--------------------------------------------------\n",
      "dates from input file: 9\n",
      "['20170608', '20170702', '20170714', '20170726', '20170807', '20170819', '20170912', '20170924', '20171006']\n",
      "--------------------------------------------------\n",
      "using all dates to calculate the time function\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5763, 7269)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5763, 7269)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5763, 7269)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5763, 7269)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5763, 7269)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5\n",
      "split along y dimension (5763) into 2 boxes\n",
      "    with each box up to 2882 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 2 --------------\n",
      "box width:  7269\n",
      "box length: 2882\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13686599 out of 20949258 (65.3%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 2882, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 2882, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 2882, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 2882, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 2882, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 2 --------------\n",
      "box width:  7269\n",
      "box length: 2881\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13601683 out of 20941989 (64.9%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [2882, 5763, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [2882, 5763, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [2882, 5763, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [2882, 5763, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [2882, 5763, 0, 7269]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5.\n",
      "time used: 00 mins 18.0 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7269, 5763)\n",
      "subset coverage in y/x: (0, 0, 7269, 5763)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7269/5763\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.14, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 01 mins 28.2 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2017\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 71 mins 27.1 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "working on AT151, frame_3, 2018\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase_MuRP.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/frame_3_2018_SenAT151.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-06-21 21:59:46.338167--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: frame_3_2018_SenAT151\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/frame_3_2018_SenAT151.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2018/*/*2018*unw_phase_MuRP_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2018/*/*2018*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2018/*/*2018*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2018/*/*2018*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2018/*/*2018*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy frame_3_2018_SenAT151.txt to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg      to inputs   directory for backup.\n",
      "copy frame_3_2018_SenAT151.txt to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg      to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/frame_3_2018_SenAT151.txt --project frame_3_2018_SenAT151\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2018/*/*2018*unw_phase_MuRP_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2018/*/*2018*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2018/*/*2018*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2018/*/*2018*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2018/*/*2018*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3/AT151/frame_3/2018/S1BB_20180603T010102_20180627T010104_VVP024_INT40_G_ueF_ABFF/S1BB_20180603T010102_20180627T010104_VVP024_INT40_G_ueF_ABFF_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3/AT151/frame_3/2018/S1BB_20180603T010102_20180627T010104_VVP024_INT40_G_ueF_ABFF/S1BB_20180603T010102_20180627T010104_VVP024_INT40_G_ueF_ABFF_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3/AT151/frame_3/2018/S1BB_20180603T010102_20180627T010104_VVP024_INT40_G_ueF_ABFF/S1BB_20180603T010102_20180627T010104_VVP024_INT40_G_ueF_ABFF_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5763, 7267) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5763, 7267) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5763, 7267) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20180603T010102_20180627T010104_VVP024_INT40_G_ueF_ABFF_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5763, 7267) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3/AT151/frame_3/2018/*/*2018*unw_phase_MuRP_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3/AT151/frame_3/2018/*/*2018*corr_clipped.tif\n",
      "number of unwrapPhase     : 39\n",
      "number of coherence       : 39\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (39, 5763, 7267) with compression = None\n",
      "[==================================================] 20181001_20181013  214s /     6s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (39, 5763, 7267) with compression = None\n",
      "[==================================================] 20181001_20181013  205s /     6s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (39, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (39,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (39,)\n",
      "add extra metadata: {'PROJECT_NAME': 'frame_3_2018_SenAT151', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 08 mins 17.3 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file frame_3_2018_SenAT151.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file frame_3_2018_SenAT151.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5763, 7267)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 39/39   46s /     1s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 11\n",
      "number of interferograms: 39\n",
      "shift all perp baseline by -31.97492790222168 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 39\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 183.17 m\n",
      "max temporal      baseline: 60.0 days\n",
      "showing coherence\n",
      "data range: [0.60475856, 0.9132729]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 39/39   39s /     1s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5763, 7267)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/maskConnComp.h5\n",
      "time used: 00 mins 42.8 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   31s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5763, 7267)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/avgSpatialCoh.h5\n",
      "time used: 00 mins 42.1 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5 ...\n",
      "[=======>                17%                       ] lines 1150/5763    0s /     0s/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/objects/stack.py:1059: RuntimeWarning: Mean of empty slice\n",
      "  dmean[r0:r1, :] = np.nanmean(data, axis=0)\n",
      "[==================================================] lines 5763/5763   38s /     7s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (1718, 1935)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5\n",
      "{'REF_Y': '1718', 'REF_X': '1935', 'REF_LAT': '4250940.0', 'REF_LON': '347580.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   39s /     8s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5763, 7267)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/avgPhaseVelocity.h5\n",
      "time used: 00 mins 52.1 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 39\n",
      "number of triplets: 66\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (410, 7267), 15 blocks in total\n",
      "reference pixel in y/x: (1718, 1935) from dataset: unwrapPhase\n",
      "[==================================================] line 5740 / 5763   89s /     6s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5763, 7267)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/numTriNonzeroIntAmbiguity.png\n",
      "time used: 01 mins 36.5 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (1718, 1935) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 39\n",
      "number of acquisitions  : 11\n",
      "number of lines   : 5763\n",
      "number of columns : 7267\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (11, 5763, 7267)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5763, 7267)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5763, 7267)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5763 lines into 6 patches for processing\n",
      "    with each patch up to 970 lines\n",
      "\n",
      "------- processing patch 1 out of 6 --------------\n",
      "box width:  7267\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1212, 970]\n",
      "submit a job to the worker for sub box 1: [1212, 0, 2424, 970]\n",
      "submit a job to the worker for sub box 2: [2424, 0, 3636, 970]\n",
      "submit a job to the worker for sub box 3: [3636, 0, 4848, 970]\n",
      "submit a job to the worker for sub box 4: [4848, 0, 6060, 970]\n",
      "submit a job to the worker for sub box 5: [6060, 0, 7267, 970]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 0, 1212, 970] * 39 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4848, 0, 6060, 970] * 39 ...\n",
      "reading coherence in [2424, 0, 3636, 970] * 39 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1212, 0, 2424, 970] * 39 ...\n",
      "reading coherence in [3636, 0, 4848, 970] * 39 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6060, 0, 7267, 970] * 39 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 2 / 12\n",
      "chunk 1 / 12\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 4 / 12\n",
      "chunk 6 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 9 / 12\n",
      "chunk 8 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 10 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 11 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4848, 0, 6060, 970] * 39 ...\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 11 / 12\n",
      "reading unwrapPhase in [6060, 0, 7267, 970] * 39 ...\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2424, 0, 3636, 970] * 39 ...\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 0, 1212, 970] * 39 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1212, 0, 2424, 970] * 39 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3636, 0, 4848, 970] * 39 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "number of pixels to invert: 575156 out of 1175640 (48.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 469008 out of 1175640 (39.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 228003 out of 1170790 (19.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]number of pixels to invert: 67644 out of 1175640 (5.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 1175640 (0.0%)\n",
      "[>                                                 ]\n",
      "FUTURE #1 complete. Time used: 14 seconds\n",
      "number of pixels to invert: 589892 out of 1175640 (50.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 67644/67644 pixels    31s /   254s\n",
      "[=======>                15%                       ] 69800/469008 pixels   32s /   181sconverting LOS phase unit from radian to meter\n",
      "[=====>                  12%                       ] 68600/575156 pixels   32s /   236s\n",
      "FUTURE #2 complete. Time used: 45 seconds\n",
      "[==================================================] 228003/228003 pixels   87s /   142s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================>     38%                       ] 226600/589892 pixels   87s /   142s\n",
      "FUTURE #3 complete. Time used: 101 seconds\n",
      "[==================================================] 469008/469008 pixels  161s /    40s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 80% ===========>          ] 460400/575156 pixels  161s /    40s\n",
      "FUTURE #4 complete. Time used: 175 seconds\n",
      "[==================================================] 575156/575156 pixels  194s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 582600/589892 pixels\n",
      "FUTURE #5 complete. Time used: 209 seconds\n",
      "[==================================================] 589892/589892 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 210 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 970, 0, 7267]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 970, 0, 7267]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 970, 0, 7267]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 03 mins 35.9 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 6 --------------\n",
      "box width:  7267\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 970, 1212, 1940]\n",
      "submit a job to the worker for sub box 1: [1212, 970, 2424, 1940]\n",
      "submit a job to the worker for sub box 2: [2424, 970, 3636, 1940]\n",
      "submit a job to the worker for sub box 3: [3636, 970, 4848, 1940]\n",
      "submit a job to the worker for sub box 4: [4848, 970, 6060, 1940]\n",
      "submit a job to the worker for sub box 5: [6060, 970, 7267, 1940]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 970, 1212, 1940] * 39 ...\n",
      "reading coherence in [3636, 970, 4848, 1940] * 39 ...\n",
      "reading coherence in [2424, 970, 3636, 1940] * 39 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6060, 970, 7267, 1940] * 39 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4848, 970, 6060, 1940] * 39 ...\n",
      "reading coherence in [1212, 970, 2424, 1940] * 39 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 11 / 12\n",
      "reading unwrapPhase in [4848, 970, 6060, 1940] * 39 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6060, 970, 7267, 1940] * 39 ...\n",
      "reading unwrapPhase in [1212, 970, 2424, 1940] * 39 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 970, 1212, 1940] * 39 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2424, 970, 3636, 1940] * 39 ...\n",
      "reading unwrapPhase in [3636, 970, 4848, 1940] * 39 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 488262 out of 1170790 (41.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1147063 out of 1175640 (97.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 721477 out of 1175640 (61.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 643083/643083 pixels   314s /   257s\n",
      "[======================= 55%                       ] 641400/1175640 pixels  314s /   257sconverting LOS phase unit from radian to meter\n",
      "[======================= 55%                       ] 641400/1175640 pixels  314s /   257s\n",
      "FUTURE #1 complete. Time used: 329 seconds\n",
      "[==================================================] 741481/741481 pixels   355s /   209s\n",
      "[======================= 63% ===>                  ] 743200/1175640 pixels  356s /   209sconverting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #2 complete. Time used: 370 seconds\n",
      "[==================================================] 583208/583208 pixels   287s /   299s\n",
      "[======================= 49%                       ] 576200/1175640 pixels  287s /   299sconverting LOS phase unit from radian to meter\n",
      "[======================= 49%                       ] 571000/1175640 pixels  287s /   299s\n",
      "FUTURE #1 complete. Time used: 301 seconds\n",
      "[==================================================] 1175640/1175640 pixels  508s /    15s\n",
      "[==================================================] 1167600/1175640 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1158600/1175640 pixels  508s /    15s\n",
      "FUTURE #3 complete. Time used: 522 seconds\n",
      "[==================================================] 1175640/1175640 pixels  511s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1167000/1175640 pixels  511s /    10s\n",
      "FUTURE #4 complete. Time used: 525 seconds\n",
      "[==================================================] 1175640/1175640 pixels  512s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1163600/1175640 pixels\n",
      "FUTURE #5 complete. Time used: 528 seconds\n",
      "[==================================================] 1175640/1175640 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 532 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2910, 3880, 0, 7267]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [2910, 3880, 0, 7267]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [2910, 3880, 0, 7267]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 30 mins 8.9 secs.\n",
      "\n",
      "\n",
      "------- processing patch 5 out of 6 --------------\n",
      "box width:  7267\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 3880, 1212, 4850]\n",
      "submit a job to the worker for sub box 1: [1212, 3880, 2424, 4850]\n",
      "submit a job to the worker for sub box 2: [2424, 3880, 3636, 4850]\n",
      "submit a job to the worker for sub box 3: [3636, 3880, 4848, 4850]\n",
      "submit a job to the worker for sub box 4: [4848, 3880, 6060, 4850]\n",
      "submit a job to the worker for sub box 5: [6060, 3880, 7267, 4850]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2424, 3880, 3636, 4850] * 39 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4848, 3880, 6060, 4850] * 39 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 3880, 1212, 4850] * 39 ...\n",
      "reading coherence in [1212, 3880, 2424, 4850] * 39 ...\n",
      "reading coherence in [6060, 3880, 7267, 4850] * 39 ...\n",
      "reading coherence in [3636, 3880, 4848, 4850] * 39 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4848, 3880, 6060, 4850] * 39 ...\n",
      "reading unwrapPhase in [2424, 3880, 3636, 4850] * 39 ...\n",
      "reading unwrapPhase in [6060, 3880, 7267, 4850] * 39 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 3880, 1212, 4850] * 39 ...\n",
      "reading unwrapPhase in [1212, 3880, 2424, 4850] * 39 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3636, 3880, 4848, 4850] * 39 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 708281 out of 1170790 (60.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1102209 out of 1175640 (93.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 453058 out of 1175640 (38.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 453058/453058 pixels   224s /   351s\n",
      "converting LOS phase unit from radian to meter\n",
      "[===================>    39%                       ] 464200/1175640 pixels  225s /   352s\n",
      "FUTURE #1 complete. Time used: 239 seconds\n",
      "[==================================================] 1102209/1102209 pixels  467s /    24s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 95% ===================>  ] 1116600/1175640 pixels  467s /    24s\n",
      "FUTURE #3 complete. Time used: 481 seconds\n",
      "[==================================================] 1175640/1175640 pixels  485s /     9s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 1153200/1175640 pixels  485s /     9s\n",
      "FUTURE #4 complete. Time used: 500 seconds\n",
      "[==================================================] 1175640/1175640 pixels  487s /     9s\n",
      "[==================================================] 1161800/1175640 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1162000/1175640 pixels\n",
      "FUTURE #5 complete. Time used: 502 seconds\n",
      "[==================================================] 1175640/1175640 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 506 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 3880, 4850, 0, 7267]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [3880, 4850, 0, 7267]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [3880, 4850, 0, 7267]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 38 mins 39.7 secs.\n",
      "\n",
      "\n",
      "------- processing patch 6 out of 6 --------------\n",
      "box width:  7267\n",
      "box length: 913\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4850, 1212, 5763]\n",
      "submit a job to the worker for sub box 1: [1212, 4850, 2424, 5763]\n",
      "submit a job to the worker for sub box 2: [2424, 4850, 3636, 5763]\n",
      "submit a job to the worker for sub box 3: [3636, 4850, 4848, 5763]\n",
      "submit a job to the worker for sub box 4: [4848, 4850, 6060, 5763]\n",
      "submit a job to the worker for sub box 5: [6060, 4850, 7267, 5763]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6060, 4850, 7267, 5763] * 39 ...\n",
      "reading coherence in [0, 4850, 1212, 5763] * 39 ...\n",
      "reading coherence in [2424, 4850, 3636, 5763] * 39 ...\n",
      "reading coherence in [3636, 4850, 4848, 5763] * 39 ...\n",
      "reading coherence in [1212, 4850, 2424, 5763] * 39 ...\n",
      "reading coherence in [4848, 4850, 6060, 5763] * 39 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 4850, 1212, 5763] * 39 ...\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2424, 4850, 3636, 5763] * 39 ...\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6060, 4850, 7267, 5763] * 39 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4848, 4850, 6060, 5763] * 39 ...\n",
      "chunk 12 / 12\n",
      "chunk 11 / 12\n",
      "reading unwrapPhase in [1212, 4850, 2424, 5763] * 39 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3636, 4850, 4848, 5763] * 39 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 193678 out of 1106556 (17.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 0 out of 1101991 (0.0%)\n",
      "[>                                                 ]number of pixels to invert: 493388 out of 1106556 (44.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 446835 out of 1106556 (40.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 65225 out of 1106556 (5.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "\n",
      "FUTURE #1 complete. Time used: 13 seconds\n",
      "[>                                                 ]number of pixels to invert: 377610 out of 1106556 (34.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 65225/65225 pixels    27s /   185s\n",
      "[=======>                17%                       ] 63800/377610 pixels   27s /   134sconverting LOS phase unit from radian to meter\n",
      "[=======>                17%                       ] 64000/377610 pixels   27s /   134s\n",
      "FUTURE #2 complete. Time used: 41 seconds\n",
      "[==================================================] 193678/193678 pixels   74s /   103s\n",
      "[======================= 50%                       ] 188200/377610 pixels   74s /    74sconverting LOS phase unit from radian to meter\n",
      "[====================>   42%                       ] 189200/446835 pixels   75s /   103s\n",
      "FUTURE #3 complete. Time used: 88 seconds\n",
      "[==================================================] 493388/493388 pixels   94s /    70s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 173 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4850, 5763, 0, 7267]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4850, 5763, 0, 7267]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4850, 5763, 0, 7267]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 41 mins 37.2 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (1718, 1935)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 39\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 41 mins 37.2 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5763, 7267)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/maskTempCoh.h5\n",
      "time used: 00 mins 1.8 secs.\n",
      "number of reliable pixels: 17222858\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5763, 7267)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 11/11   75s /     7s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 24.3 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5763, 7267)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5763, 7267)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5763, 7267)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7267\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1212, 1441]\n",
      "submit a job to the worker for sub box 1: [1212, 0, 2424, 1441]\n",
      "submit a job to the worker for sub box 2: [2424, 0, 3636, 1441]\n",
      "submit a job to the worker for sub box 3: [3636, 0, 4848, 1441]\n",
      "submit a job to the worker for sub box 4: [4848, 0, 6060, 1441]\n",
      "submit a job to the worker for sub box 5: [6060, 0, 7267, 1441]\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 299658 out of 1746492 (17.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 611491 out of 1746492 (35.0%)\n",
      "number of pixels to invert: 439146 out of 1739287 (25.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1142599 out of 1746492 (65.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1157119 out of 1746492 (66.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1036570 out of 1746492 (59.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 299658/299658   68s /    33ss\n",
      "[=============>          27%                       ] 304000/1142599   69s /   186s\n",
      "FUTURE #1 complete. Time used: 73 seconds\n",
      "[==================================================] 439146/439146    96s /   150s\n",
      "[==================>     38%                       ] 434000/1157119   96s /   157s\n",
      "FUTURE #2 complete. Time used: 100 seconds\n",
      "[==================================================] 611491/611491   125s /   102s\n",
      "[======================= 55%                       ] 634000/1142599  125s /   102s\n",
      "FUTURE #3 complete. Time used: 129 seconds\n",
      "[==================================================] 1142599/1142599  195s /     8s\n",
      "[======================= 96% ===================>  ] 1114000/1157119  195s /     8s\n",
      "FUTURE #5 complete. Time used: 200 seconds\n",
      "[==================================================] 1157119/1157119  198s /     4s\n",
      "\n",
      "FUTURE #6 complete. Time used: 205 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1441, 0, 7267]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 1441, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 1441, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7267\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1441, 1212, 2882]\n",
      "submit a job to the worker for sub box 1: [1212, 1441, 2424, 2882]\n",
      "submit a job to the worker for sub box 2: [2424, 1441, 3636, 2882]\n",
      "submit a job to the worker for sub box 3: [3636, 1441, 4848, 2882]\n",
      "submit a job to the worker for sub box 4: [4848, 1441, 6060, 2882]\n",
      "submit a job to the worker for sub box 5: [6060, 1441, 7267, 2882]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1740989 out of 1746492 (99.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1746491 out of 1746492 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 884092 out of 1739287 (50.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1132913 out of 1746492 (64.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1746492 out of 1746492 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1746492 out of 1746492 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 884092/884092   202s /   194s\n",
      "[======================= 51%                       ] 890000/1746492  202s /   194s\n",
      "FUTURE #1 complete. Time used: 206 seconds\n",
      "[==================================================] 1132913/1132913  248s /   128s\n",
      "[======================= 66% ====>                 ] 1146000/1746491  249s /   128s\n",
      "FUTURE #2 complete. Time used: 253 seconds\n",
      "[==================================================] 1746492/1746492  344s /     7s\n",
      "[==================================================] 1746491/1746491 \n",
      "[==================================================] 1728000/1740989\n",
      "FUTURE #3 complete. Time used: 350 seconds\n",
      "\n",
      "FUTURE #4 complete. Time used: 351 seconds\n",
      "[==================================================] 1746492/1746492 \n",
      "[==================================================] 1738000/1740989\n",
      "FUTURE #5 complete. Time used: 352 seconds\n",
      "[==================================================] 1740989/1740989 \n",
      "\n",
      "FUTURE #6 complete. Time used: 352 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1441, 2882, 0, 7267]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 1441, 2882, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 1441, 2882, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7267\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2882, 1212, 4323]\n",
      "submit a job to the worker for sub box 1: [1212, 2882, 2424, 4323]\n",
      "submit a job to the worker for sub box 2: [2424, 2882, 3636, 4323]\n",
      "submit a job to the worker for sub box 3: [3636, 2882, 4848, 4323]\n",
      "submit a job to the worker for sub box 4: [4848, 2882, 6060, 4323]\n",
      "submit a job to the worker for sub box 5: [6060, 2882, 7267, 4323]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1746492 out of 1746492 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1746492 out of 1746492 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1746487 out of 1746492 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 819357 out of 1746492 (46.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1746492 out of 1746492 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1240706 out of 1739287 (71.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 819357/819357   194s /   100s\n",
      "[======================= 48%                       ] 834000/1746487  194s /   210s\n",
      "FUTURE #1 complete. Time used: 199 seconds\n",
      "[==================================================] 1240706/1240706  277s /   108s\n",
      "[======================= 72% =======>              ] 1264000/1746492  278s /   108s\n",
      "FUTURE #2 complete. Time used: 282 seconds\n",
      "[==================================================] 1746492/1746492  354s /     7s\n",
      "[==================================================] 1742000/1746492\n",
      "FUTURE #3 complete. Time used: 362 seconds\n",
      "[==================================================] 1746492/1746492 \n",
      "[==================================================] 1744000/1746492\n",
      "FUTURE #4 complete. Time used: 362 seconds\n",
      "[==================================================] 1746487/1746487 \n",
      "[==================================================] 1746492/1746492 \n",
      "\n",
      "FUTURE #5 complete. Time used: 363 seconds\n",
      "\n",
      "FUTURE #6 complete. Time used: 363 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2882, 4323, 0, 7267]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2882, 4323, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2882, 4323, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7267\n",
      "box length: 1440\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4323, 1212, 5763]\n",
      "submit a job to the worker for sub box 1: [1212, 4323, 2424, 5763]\n",
      "submit a job to the worker for sub box 2: [2424, 4323, 3636, 5763]\n",
      "submit a job to the worker for sub box 3: [3636, 4323, 4848, 5763]\n",
      "submit a job to the worker for sub box 4: [4848, 4323, 6060, 5763]\n",
      "submit a job to the worker for sub box 5: [6060, 4323, 7267, 5763]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 416107 out of 1745280 (23.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1129370 out of 1745280 (64.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 627125 out of 1745280 (35.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 282805 out of 1738080 (16.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1081609 out of 1745280 (62.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1013609 out of 1745280 (58.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 282805/282805   71s /    87ss\n",
      "[============>           26%                       ] 278000/1081609   71s /   202s\n",
      "FUTURE #1 complete. Time used: 75 seconds\n",
      "[==================================================] 416107/416107    94s /   168s\n",
      "[======================= 66% ====>                 ] 412000/627125   94s /    48ss\n",
      "FUTURE #2 complete. Time used: 99 seconds\n",
      "[==================================================] 627125/627125   131s /    77s\n",
      "[======================= 57%                       ] 618000/1081609  132s /    99s\n",
      "FUTURE #3 complete. Time used: 136 seconds\n",
      "[==================================================] 1013609/1013609 183s /    18s\n",
      "[======================= 91% =================>    ] 986000/1081609  183s /    18s\n",
      "FUTURE #4 complete. Time used: 188 seconds\n",
      "[==================================================] 1081609/1081609  195s /     8s\n",
      "[======================= 96% ===================>  ] 1084000/1129370  195s /     8s\n",
      "FUTURE #5 complete. Time used: 200 seconds\n",
      "[==================================================] 1129370/1129370  198s /     4s\n",
      "\n",
      "FUTURE #6 complete. Time used: 205 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4323, 5763, 0, 7267]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4323, 5763, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4323, 5763, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 19 mins 10.6 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5763, 7267)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 11/11   89s /     8s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 40.1 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 11/11   56s /     5s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20181013 - 0.0046\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0140)\n",
      "20180709 - 0.0153\n",
      "save date(s) to file: exclude_date.txt\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20181013\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5763, 0, 7267)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20181013\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5763, 0, 7267)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20181013\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5763, 0, 7267)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20181013\n",
      "time used: 00 mins 49.2 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: ['20180709']\n",
      "--------------------------------------------------\n",
      "dates from input file: 11\n",
      "['20180603', '20180627', '20180709', '20180721', '20180802', '20180814', '20180826', '20180907', '20180919', '20181001', '20181013']\n",
      "--------------------------------------------------\n",
      "dates used to estimate the time function: 10\n",
      "['20180603', '20180627', '20180721', '20180802', '20180814', '20180826', '20180907', '20180919', '20181001', '20181013']\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5763, 7267)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5763, 7267)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5763, 7267)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5763, 7267)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5763, 7267)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5\n",
      "split along y dimension (5763) into 2 boxes\n",
      "    with each box up to 2882 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 2 --------------\n",
      "box width:  7267\n",
      "box length: 2882\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13684053 out of 20943494 (65.3%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 2882, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 2882, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 2882, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 2882, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 2882, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 2 --------------\n",
      "box width:  7267\n",
      "box length: 2881\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13596651 out of 20936227 (64.9%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [2882, 5763, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [2882, 5763, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [2882, 5763, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [2882, 5763, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [2882, 5763, 0, 7267]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5.\n",
      "time used: 00 mins 17.9 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7267, 5763)\n",
      "subset coverage in y/x: (0, 0, 7267, 5763)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7267/5763\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.13, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 02 mins 11.1 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2018\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 82 mins 52.1 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "working on AT151, frame_3, 2019\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase_MuRP.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/frame_3_2019_SenAT151.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-06-21 23:55:39.375383--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: frame_3_2019_SenAT151\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/frame_3_2019_SenAT151.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2019/*/*2019*unw_phase_MuRP_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2019/*/*2019*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2019/*/*2019*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2019/*/*2019*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2019/*/*2019*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy frame_3_2019_SenAT151.txt to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg      to inputs   directory for backup.\n",
      "copy frame_3_2019_SenAT151.txt to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg      to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/frame_3_2019_SenAT151.txt --project frame_3_2019_SenAT151\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2019/*/*2019*unw_phase_MuRP_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2019/*/*2019*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2019/*/*2019*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2019/*/*2019*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2019/*/*2019*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3/AT151/frame_3/2019/S1BB_20190610T010109_20190622T010110_VVP012_INT40_G_ueF_94BA/S1BB_20190610T010109_20190622T010110_VVP012_INT40_G_ueF_94BA_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3/AT151/frame_3/2019/S1BB_20190610T010109_20190622T010110_VVP012_INT40_G_ueF_94BA/S1BB_20190610T010109_20190622T010110_VVP012_INT40_G_ueF_94BA_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3/AT151/frame_3/2019/S1BB_20190610T010109_20190622T010110_VVP012_INT40_G_ueF_94BA/S1BB_20190610T010109_20190622T010110_VVP012_INT40_G_ueF_94BA_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5763, 7271) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5763, 7271) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5763, 7271) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20190610T010109_20190622T010110_VVP012_INT40_G_ueF_94BA_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5763, 7271) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3/AT151/frame_3/2019/*/*2019*unw_phase_MuRP_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3/AT151/frame_3/2019/*/*2019*corr_clipped.tif\n",
      "number of unwrapPhase     : 40\n",
      "number of coherence       : 40\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (40, 5763, 7271) with compression = None\n",
      "[==================================================] 20190926_20191008  221s /     4s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (40, 5763, 7271) with compression = None\n",
      "[==================================================] 20190926_20191008  218s /     4s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (40, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (40,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (40,)\n",
      "add extra metadata: {'PROJECT_NAME': 'frame_3_2019_SenAT151', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 08 mins 38.1 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file frame_3_2019_SenAT151.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file frame_3_2019_SenAT151.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5763, 7271)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 40/40   42s /     0s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 11\n",
      "number of interferograms: 40\n",
      "shift all perp baseline by 3.665917158126831 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 40\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 132.94 m\n",
      "max temporal      baseline: 60.0 days\n",
      "showing coherence\n",
      "data range: [0.53159696, 0.9140594]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 40/40   46s /     0s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5763, 7271)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/maskConnComp.h5\n",
      "time used: 00 mins 49.5 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   32s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5763, 7271)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/avgSpatialCoh.h5\n",
      "time used: 00 mins 41.7 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5 ...\n",
      "[=======>                17%                       ] lines 1150/5763    0s /     0s/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/objects/stack.py:1059: RuntimeWarning: Mean of empty slice\n",
      "  dmean[r0:r1, :] = np.nanmean(data, axis=0)\n",
      "[==================================================] lines 5763/5763   33s /     6s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (5068, 2867)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5\n",
      "{'REF_Y': '5068', 'REF_X': '2867', 'REF_LAT': '4116940.0', 'REF_LON': '384780.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   43s /     8s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5763, 7271)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/avgPhaseVelocity.h5\n",
      "time used: 00 mins 56.1 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 40\n",
      "number of triplets: 70\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (380, 7271), 16 blocks in total\n",
      "reference pixel in y/x: (5068, 2867) from dataset: unwrapPhase\n",
      "[==================================================] line 5700 / 5763   90s /     5s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5763, 7271)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/numTriNonzeroIntAmbiguity.png\n",
      "time used: 01 mins 37.2 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (5068, 2867) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 40\n",
      "number of acquisitions  : 11\n",
      "number of lines   : 5763\n",
      "number of columns : 7271\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (11, 5763, 7271)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5763, 7271)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5763, 7271)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5763 lines into 6 patches for processing\n",
      "    with each patch up to 970 lines\n",
      "\n",
      "------- processing patch 1 out of 6 --------------\n",
      "box width:  7271\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1212, 970]\n",
      "submit a job to the worker for sub box 1: [1212, 0, 2424, 970]\n",
      "submit a job to the worker for sub box 2: [2424, 0, 3636, 970]\n",
      "submit a job to the worker for sub box 3: [3636, 0, 4848, 970]\n",
      "submit a job to the worker for sub box 4: [4848, 0, 6060, 970]\n",
      "submit a job to the worker for sub box 5: [6060, 0, 7271, 970]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3636, 0, 4848, 970] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 0, 1212, 970] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6060, 0, 7271, 970] * 40 ...\n",
      "reading coherence in [2424, 0, 3636, 970] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1212, 0, 2424, 970] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4848, 0, 6060, 970] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 2 / 12\n",
      "chunk 1 / 12\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 4 / 12\n",
      "chunk 3 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 5 / 12\n",
      "chunk 4 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 6 / 12\n",
      "chunk 5 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 7 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 8 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 9 / 12\n",
      "chunk 8 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 10 / 12\n",
      "chunk 9 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 9 / 12\n",
      "chunk 11 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 0, 1212, 970] * 40 ...\n",
      "chunk 11 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 11 / 12\n",
      "reading unwrapPhase in [2424, 0, 3636, 970] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 11 / 12\n",
      "reading unwrapPhase in [1212, 0, 2424, 970] * 40 ...\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4848, 0, 6060, 970] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6060, 0, 7271, 970] * 40 ...\n",
      "reading unwrapPhase in [3636, 0, 4848, 970] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 574063 out of 1175640 (48.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 0 out of 1175640 (0.0%)\n",
      "[>                                                 ]number of pixels to invert: 66659 out of 1175640 (5.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 468221 out of 1175640 (39.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 228310 out of 1174670 (19.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]\n",
      "FUTURE #1 complete. Time used: 13 seconds\n",
      "[>                                                 ]number of pixels to invert: 589065 out of 1175640 (50.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 66659/66659 pixels    34s /   212s\n",
      "[=====>                  12%                       ] 68800/574063 pixels   34s /   255sconverting LOS phase unit from radian to meter\n",
      "[======>                 14%                       ] 65800/468221 pixels   34s /   213s\n",
      "FUTURE #2 complete. Time used: 48 seconds\n",
      "[==================================================] 228310/228310 pixels   91s /   136s\n",
      "converting LOS phase unit from radian to meter\n",
      "[===================>    40%                       ] 234800/589065 pixels   91s /   136s\n",
      "FUTURE #3 complete. Time used: 105 seconds\n",
      "[==================================================] 489079/489079 pixels  239s /   117ss\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 67% =====>                ] 485200/719190 pixels  239s /   117ss\n",
      "FUTURE #1 complete. Time used: 252 seconds\n",
      "[==================================================] 1146616/1146616 pixels  477s /    14s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1171800/1175640 pixels  477s /    14s\n",
      "FUTURE #3 complete. Time used: 491 seconds\n",
      "[==================================================] 1175640/1175640 pixels  478s /    14s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 1143000/1175640 pixels  479s /    14s\n",
      "FUTURE #4 complete. Time used: 492 seconds\n",
      "[==================================================] 1175640/1175640 pixels  479s /    14s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 1144400/1175640 pixels  479s /    14s\n",
      "FUTURE #5 complete. Time used: 492 seconds\n",
      "[==================================================] 1175640/1175640 pixels  483s /     9s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 500 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 970, 1940, 0, 7271]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [970, 1940, 0, 7271]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [970, 1940, 0, 7271]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 11 mins 54.1 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 6 --------------\n",
      "box width:  7271\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1940, 1212, 2910]\n",
      "submit a job to the worker for sub box 1: [1212, 1940, 2424, 2910]\n",
      "submit a job to the worker for sub box 2: [2424, 1940, 3636, 2910]\n",
      "submit a job to the worker for sub box 3: [3636, 1940, 4848, 2910]\n",
      "submit a job to the worker for sub box 4: [4848, 1940, 6060, 2910]\n",
      "submit a job to the worker for sub box 5: [6060, 1940, 7271, 2910]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 1940, 1212, 2910] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6060, 1940, 7271, 2910] * 40 ...\n",
      "reading coherence in [4848, 1940, 6060, 2910] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2424, 1940, 3636, 2910] * 40 ...\n",
      "reading coherence in [3636, 1940, 4848, 2910] * 40 ...\n",
      "reading coherence in [1212, 1940, 2424, 2910] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4848, 1940, 6060, 2910] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 1940, 1212, 2910] * 40 ...\n",
      "reading unwrapPhase in [1212, 1940, 2424, 2910] * 40 ...\n",
      "reading unwrapPhase in [6060, 1940, 7271, 2910] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2424, 1940, 3636, 2910] * 40 ...\n",
      "reading unwrapPhase in [3636, 1940, 4848, 2910] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 739068 out of 1175640 (62.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 643905 out of 1174670 (54.8%)\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[======================= 51%                       ] 602000/1175640 pixels  287s /   276schunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1212, 2910, 2424, 3880] * 40 ...\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4848, 2910, 6060, 3880] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 2910, 1212, 3880] * 40 ...\n",
      "reading unwrapPhase in [6060, 2910, 7271, 3880] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2424, 2910, 3636, 3880] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3636, 2910, 4848, 3880] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 807372 out of 1174670 (68.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 580779 out of 1175640 (49.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 580779/580779 pixels   278s /   278s\n",
      "[======================= 50%                       ] 583000/1175640 pixels  278s /   278sconverting LOS phase unit from radian to meter\n",
      "[======================= 48%                       ] 569400/1175640 pixels  278s /   301s\n",
      "FUTURE #1 complete. Time used: 292 seconds\n",
      "[==================================================] 709615/709615 pixels   328s /   218s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 61% =>                    ] 711600/1175640 pixels  328s /   209s\n",
      "FUTURE #2 complete. Time used: 342 seconds\n",
      "[==================================================] 192568/192568 pixels   75s /    75ss\n",
      "[==================>     38%                       ] 188200/494249 pixels   75s /   123sconverting LOS phase unit from radian to meter\n",
      "[======================= 50%                       ] 189000/378432 pixels   75s /    75s\n",
      "FUTURE #3 complete. Time used: 89 seconds\n",
      "[==================================================] 378432/378432 pixels  129s /    22s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 85% =============>        ] 379000/446958 pixels  129s /    22s\n",
      "FUTURE #4 complete. Time used: 143 seconds\n",
      "[==================================================] 446958/446958 pixels  148s /    14s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 91% =================>    ] 449400/494249 pixels  148s /    14s\n",
      "FUTURE #5 complete. Time used: 161 seconds\n",
      "[==================================================] 494249/494249 pixels  157s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 172 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4850, 5763, 0, 7271]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4850, 5763, 0, 7271]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4850, 5763, 0, 7271]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 40 mins 52.6 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (5068, 2867)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 40\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 40 mins 52.6 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5763, 7271)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/maskTempCoh.h5\n",
      "time used: 00 mins 1.8 secs.\n",
      "number of reliable pixels: 19126271\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5763, 7271)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 11/11   74s /     7s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "[==================================================] 299415/299415    67s /   192s\n",
      "[============>           26%                       ] 302000/1141791   67s /   192s\n",
      "FUTURE #1 complete. Time used: 72 seconds\n",
      "[==================================================] 442722/442722    98s /   141s\n",
      "[======================= 70% ======>               ] 430000/611179   98s /    42ss\n",
      "FUTURE #2 complete. Time used: 102 seconds\n",
      "[==================================================] 611179/611179   128s /    93s\n",
      "[======================= 55%                       ] 636000/1156446  128s /   105s\n",
      "FUTURE #3 complete. Time used: 133 seconds\n",
      "[==================================================] 1035971/1035971  189s /     9s\n",
      "[======================= 95% ===================>  ] 1104000/1156446  189s /     9s\n",
      "FUTURE #4 complete. Time used: 194 seconds\n",
      "[==================================================] 1141791/1141791  194s /     3s\n",
      "[==================================================] 1142000/1156446\n",
      "FUTURE #5 complete. Time used: 199 seconds\n",
      "[==================================================] 1156446/1156446 \n",
      "\n",
      "FUTURE #6 complete. Time used: 201 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1441, 0, 7271]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 1441, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 1441, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7271\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1441, 1212, 2882]\n",
      "submit a job to the worker for sub box 1: [1212, 1441, 2424, 2882]\n",
      "submit a job to the worker for sub box 2: [2424, 1441, 3636, 2882]\n",
      "submit a job to the worker for sub box 3: [3636, 1441, 4848, 2882]\n",
      "submit a job to the worker for sub box 4: [4848, 1441, 6060, 2882]\n",
      "submit a job to the worker for sub box 5: [6060, 1441, 7271, 2882]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1132425 out of 1746492 (64.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 889122 out of 1745051 (51.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1746492 out of 1746492 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1740868 out of 1746492 (99.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1746492 out of 1746492 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1746492 out of 1746492 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 889122/889122   197s /   197s\n",
      "[======================= 51%                       ] 886000/1746492  198s /   190s\n",
      "FUTURE #1 complete. Time used: 203 seconds\n",
      "[==================================================] 818784/818784   185s /    95ss\n",
      "[======================> 46%                       ] 812000/1746492  185s /   218s\n",
      "FUTURE #1 complete. Time used: 190 seconds\n",
      "[==================================================] 1746491/1746491  341s /     6s\n",
      "[==================================================] 1728000/1746492\n",
      "FUTURE #3 complete. Time used: 346 seconds\n",
      "[==================================================] 1746492/1746492  343s /     7s\n",
      "[==================================================] 1746492/1746492 \n",
      "[==================================================] 1732000/1746492\n",
      "FUTURE #4 complete. Time used: 349 seconds\n",
      "\n",
      "FUTURE #5 complete. Time used: 349 seconds\n",
      "[==================================================] 1746492/1746492 \n",
      "\n",
      "FUTURE #6 complete. Time used: 351 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2882, 4323, 0, 7271]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2882, 4323, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2882, 4323, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7271\n",
      "box length: 1440\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4323, 1212, 5763]\n",
      "submit a job to the worker for sub box 1: [1212, 4323, 2424, 5763]\n",
      "submit a job to the worker for sub box 2: [2424, 4323, 3636, 5763]\n",
      "submit a job to the worker for sub box 3: [3636, 4323, 4848, 5763]\n",
      "submit a job to the worker for sub box 4: [4848, 4323, 6060, 5763]\n",
      "submit a job to the worker for sub box 5: [6060, 4323, 7271, 5763]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1130475 out of 1745280 (64.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 284426 out of 1743840 (16.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1082290 out of 1745280 (62.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 415882 out of 1745280 (23.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 628202 out of 1745280 (36.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1014528 out of 1745280 (58.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 284426/284426   64s /    28ss\n",
      "[============>           26%                       ] 292000/1130475   64s /   183s\n",
      "FUTURE #1 complete. Time used: 68 seconds\n",
      "[==================================================] 415882/415882    87s /   126s\n",
      "[==================>     38%                       ] 416000/1082290   88s /   143s\n",
      "FUTURE #2 complete. Time used: 92 seconds\n",
      "[==================================================] 628202/628202   124s /    93s\n",
      "[======================= 63% ===>                  ] 640000/1014528  124s /    73s\n",
      "FUTURE #3 complete. Time used: 128 seconds\n",
      "[==================================================] 11/11   86s /     8s /    40s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 36.5 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 11/11   49s /     4s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20191008 - 0.0063\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0203)\n",
      "None.\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20191008\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5763, 0, 7271)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20191008\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5763, 0, 7271)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20191008\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5763, 0, 7271)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20191008\n",
      "time used: 00 mins 54.1 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: []\n",
      "--------------------------------------------------\n",
      "dates from input file: 11\n",
      "['20190610', '20190622', '20190704', '20190716', '20190728', '20190809', '20190821', '20190902', '20190914', '20190926', '20191008']\n",
      "--------------------------------------------------\n",
      "using all dates to calculate the time function\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5763, 7271)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5763, 7271)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5763, 7271)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5763, 7271)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5763, 7271)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5\n",
      "split along y dimension (5763) into 2 boxes\n",
      "    with each box up to 2882 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 2 --------------\n",
      "box width:  7271\n",
      "box length: 2882\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13689415 out of 20955022 (65.3%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 2882, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 2882, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 2882, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 2882, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 2882, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 2 --------------\n",
      "box width:  7271\n",
      "box length: 2881\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13606283 out of 20947751 (65.0%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [2882, 5763, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [2882, 5763, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [2882, 5763, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [2882, 5763, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [2882, 5763, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5.\n",
      "time used: 00 mins 20.2 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7271, 5763)\n",
      "subset coverage in y/x: (0, 0, 7271, 5763)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7271/5763\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.14, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 02 mins 24.1 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2019\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 82 mins 8.6 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "working on AT151, frame_3, 2020\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase_MuRP.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/frame_3_2020_SenAT151.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-06-22 01:51:17.444834--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: frame_3_2020_SenAT151\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/frame_3_2020_SenAT151.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2020/*/*2020*unw_phase_MuRP_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2020/*/*2020*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2020/*/*2020*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2020/*/*2020*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2020/*/*2020*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy frame_3_2020_SenAT151.txt to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg      to inputs   directory for backup.\n",
      "copy frame_3_2020_SenAT151.txt to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg      to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/frame_3_2020_SenAT151.txt --project frame_3_2020_SenAT151\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2020/*/*2020*unw_phase_MuRP_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2020/*/*2020*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2020/*/*2020*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2020/*/*2020*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2020/*/*2020*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3/AT151/frame_3/2020/S1BB_20200616T010116_20200628T010116_VVP012_INT40_G_ueF_8A1B/S1BB_20200616T010116_20200628T010116_VVP012_INT40_G_ueF_8A1B_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3/AT151/frame_3/2020/S1BB_20200616T010116_20200628T010116_VVP012_INT40_G_ueF_8A1B/S1BB_20200616T010116_20200628T010116_VVP012_INT40_G_ueF_8A1B_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3/AT151/frame_3/2020/S1BB_20200616T010116_20200628T010116_VVP012_INT40_G_ueF_8A1B/S1BB_20200616T010116_20200628T010116_VVP012_INT40_G_ueF_8A1B_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5765, 7271) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5765, 7271) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5765, 7271) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20200616T010116_20200628T010116_VVP012_INT40_G_ueF_8A1B_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5765, 7271) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3/AT151/frame_3/2020/*/*2020*unw_phase_MuRP_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3/AT151/frame_3/2020/*/*2020*corr_clipped.tif\n",
      "number of unwrapPhase     : 40\n",
      "number of coherence       : 40\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (40, 5765, 7271) with compression = None\n",
      "[==================================================] 20201002_20201014  226s /     4s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (40, 5765, 7271) with compression = None\n",
      "[==================================================] 20201002_20201014  206s /     4s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (40, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (40,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (40,)\n",
      "add extra metadata: {'PROJECT_NAME': 'frame_3_2020_SenAT151', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 08 mins 31.7 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file frame_3_2020_SenAT151.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file frame_3_2020_SenAT151.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5765, 7271)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 40/40   45s /     0s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 11\n",
      "number of interferograms: 40\n",
      "shift all perp baseline by -24.592687606811523 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 40\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 216.66 m\n",
      "max temporal      baseline: 60.0 days\n",
      "showing coherence\n",
      "data range: [0.62144727, 0.90902776]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 40/40   40s /     0s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5765, 7271)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/maskConnComp.h5\n",
      "time used: 00 mins 43.5 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   30s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5765, 7271)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/avgSpatialCoh.h5\n",
      "time used: 00 mins 40.3 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5 ...\n",
      "[=======>                17%                       ] lines 1150/5765    0s /     0s/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/objects/stack.py:1059: RuntimeWarning: Mean of empty slice\n",
      "  dmean[r0:r1, :] = np.nanmean(data, axis=0)\n",
      "[==================================================] lines 5765/5765   34s /     7s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (2638, 2902)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5\n",
      "{'REF_Y': '2638', 'REF_X': '2902', 'REF_LAT': '4214140.0', 'REF_LON': '386260.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   44s /     9s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5765, 7271)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/avgPhaseVelocity.h5\n",
      "time used: 00 mins 56.2 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 40\n",
      "number of triplets: 70\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (380, 7271), 16 blocks in total\n",
      "reference pixel in y/x: (2638, 2902) from dataset: unwrapPhase\n",
      "[==================================================] line 5700 / 5765   89s /     5s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5765, 7271)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/numTriNonzeroIntAmbiguity.png\n",
      "time used: 01 mins 36.4 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (2638, 2902) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 40\n",
      "number of acquisitions  : 11\n",
      "number of lines   : 5765\n",
      "number of columns : 7271\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (11, 5765, 7271)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5765, 7271)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5765, 7271)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5765 lines into 6 patches for processing\n",
      "    with each patch up to 970 lines\n",
      "\n",
      "------- processing patch 1 out of 6 --------------\n",
      "box width:  7271\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1212, 970]\n",
      "submit a job to the worker for sub box 1: [1212, 0, 2424, 970]\n",
      "submit a job to the worker for sub box 2: [2424, 0, 3636, 970]\n",
      "submit a job to the worker for sub box 3: [3636, 0, 4848, 970]\n",
      "submit a job to the worker for sub box 4: [4848, 0, 6060, 970]\n",
      "submit a job to the worker for sub box 5: [6060, 0, 7271, 970]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4848, 0, 6060, 970] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2424, 0, 3636, 970] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3636, 0, 4848, 970] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6060, 0, 7271, 970] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 0, 1212, 970] * 40 ...\n",
      "reading coherence in [1212, 0, 2424, 970] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 2 / 12\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "chunk 2 / 12\n",
      "chunk 1 / 12\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 3 / 12\n",
      "chunk 1 / 12\n",
      "chunk 3 / 12\n",
      "chunk 2 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 4 / 12\n",
      "chunk 2 / 12\n",
      "chunk 4 / 12\n",
      "chunk 3 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 5 / 12\n",
      "chunk 4 / 12\n",
      "chunk 3 / 12\n",
      "chunk 5 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 6 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 7 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 8 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 9 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 10 / 12\n",
      "chunk 8 / 12\n",
      "chunk 10 / 12\n",
      "chunk 9 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 11 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 9 / 12\n",
      "chunk 12 / 12\n",
      "chunk 9 / 12\n",
      "reading unwrapPhase in [2424, 0, 3636, 970] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 10 / 12\n",
      "reading unwrapPhase in [4848, 0, 6060, 970] * 40 ...\n",
      "chunk 11 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6060, 0, 7271, 970] * 40 ...\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3636, 0, 4848, 970] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1212, 0, 2424, 970] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 0, 1212, 970] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 466601 out of 1175640 (39.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]number of pixels to invert: 226484 out of 1174670 (19.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]convert zero value in unwrapPhase to NaN (no-data value)\n",
      "[>                                                 ]skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "[>                                                 ]number of pixels to invert: 573082 out of 1175640 (48.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]skip pixels with unwrapPhase = NaN in all interferograms\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 66536 out of 1175640 (5.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 587426 out of 1175640 (50.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 0 out of 1175640 (0.0%)\n",
      "[>                                                 ]\n",
      "FUTURE #1 complete. Time used: 13 seconds\n",
      "[==================================================] 66536/66536 pixels    29s /   183s\n",
      "[=====>                  12%                       ] 66000/573082 pixels   29s /   217sconverting LOS phase unit from radian to meter\n",
      "[======>                 14%                       ] 66200/466601 pixels   30s /   184s\n",
      "FUTURE #2 complete. Time used: 42 seconds\n",
      "[==================================================] 486668/486668 pixels   238s /   316s\n",
      "converting LOS phase unit from radian to meter\n",
      "[===================>    41%                       ] 486200/1175640 pixels  238s /   343s\n",
      "FUTURE #1 complete. Time used: 252 seconds\n",
      "[==================================================] 1146505/1146505 pixels  477s /    14s\n",
      "[======================= 98% ====================> ] 1152400/1175640 pixels  477s /     9sconverting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 1152600/1175640 pixels  477s /     9s\n",
      "FUTURE #3 complete. Time used: 491 seconds\n",
      "[==================================================] 1175640/1175640 pixels  482s /     9s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1161600/1175640 pixels\n",
      "FUTURE #4 complete. Time used: 497 seconds\n",
      "[==================================================] 1175640/1175640 pixels \n",
      "[==================================================] 1163800/1175640 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1164000/1175640 pixels\n",
      "FUTURE #5 complete. Time used: 497 seconds\n",
      "[==================================================] 1175640/1175640 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 500 seconds\n",
      "close dask client\n",
      "2023-06-22 02:17:33,907 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/worker.py\", line 1237, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/utils_comm.py\", line 413, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/core.py\", line 1365, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/core.py\", line 1124, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 241, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48920 remote=tcp://127.0.0.1:44019>: Stream is closed\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 970, 1940, 0, 7271]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [970, 1940, 0, 7271]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [970, 1940, 0, 7271]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 11 mins 53.6 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 6 --------------\n",
      "box width:  7271\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1940, 1212, 2910]\n",
      "submit a job to the worker for sub box 1: [1212, 1940, 2424, 2910]\n",
      "submit a job to the worker for sub box 2: [2424, 1940, 3636, 2910]\n",
      "submit a job to the worker for sub box 3: [3636, 1940, 4848, 2910]\n",
      "submit a job to the worker for sub box 4: [4848, 1940, 6060, 2910]\n",
      "submit a job to the worker for sub box 5: [6060, 1940, 7271, 2910]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6060, 1940, 7271, 2910] * 40 ...\n",
      "reading coherence in [2424, 1940, 3636, 2910] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3636, 1940, 4848, 2910] * 40 ...\n",
      "reading coherence in [1212, 1940, 2424, 2910] * 40 ...\n",
      "reading coherence in [4848, 1940, 6060, 2910] * 40 ...\n",
      "reading coherence in [0, 1940, 1212, 2910] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4848, 1940, 6060, 2910] * 40 ...\n",
      "reading unwrapPhase in [1212, 1940, 2424, 2910] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6060, 1940, 7271, 2910] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2424, 1940, 3636, 2910] * 40 ...\n",
      "reading unwrapPhase in [3636, 1940, 4848, 2910] * 40 ...\n",
      "reading unwrapPhase in [0, 1940, 1212, 2910] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 641479 out of 1174670 (54.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 1175639 out of 1175640 (100.0%)\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 741744 out of 1175640 (63.1%)\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[===============>        31%                       ] 358800/1175640 pixels  170s /   378sskip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 453382 out of 1175640 (38.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 707517 out of 1174670 (60.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1102469 out of 1175640 (93.8%)\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1175640 out of 1175640 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 11/11   77s /     7sls  448s /     9s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 26.5 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5765, 7271)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7271)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7271)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7271\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1212, 1442]\n",
      "submit a job to the worker for sub box 1: [1212, 0, 2424, 1442]\n",
      "submit a job to the worker for sub box 2: [2424, 0, 3636, 1442]\n",
      "submit a job to the worker for sub box 3: [3636, 0, 4848, 1442]\n",
      "submit a job to the worker for sub box 4: [4848, 0, 6060, 1442]\n",
      "submit a job to the worker for sub box 5: [6060, 0, 7271, 1442]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 300030 out of 1747704 (17.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 612386 out of 1747704 (35.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1037201 out of 1747704 (59.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 439727 out of 1746262 (25.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1157510 out of 1747704 (66.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1143413 out of 1747704 (65.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 300030/300030    68s /   167s\n",
      "[===========>            25%                       ] 292000/1157510   68s /   205s\n",
      "FUTURE #1 complete. Time used: 72 seconds\n",
      "[==================================================] 439727/439727    96s /   157s\n",
      "[=====================>  44%                       ] 452000/1037201   97s /   123s\n",
      "FUTURE #2 complete. Time used: 100 seconds\n",
      "[==================================================] 612386/612386   122s /    78s\n",
      "[======================= 61% =>                    ] 630000/1037201  122s /    78s\n",
      "FUTURE #3 complete. Time used: 126 seconds\n",
      "[======================= 60% =>                    ] 686000/1143413  132s /    88sclose HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 1442, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7271\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1442, 1212, 2884]\n",
      "submit a job to the worker for sub box 1: [1212, 1442, 2424, 2884]\n",
      "submit a job to the worker for sub box 2: [2424, 1442, 3636, 2884]\n",
      "submit a job to the worker for sub box 3: [3636, 1442, 4848, 2884]\n",
      "submit a job to the worker for sub box 4: [4848, 1442, 6060, 2884]\n",
      "submit a job to the worker for sub box 5: [6060, 1442, 7271, 2884]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 885338 out of 1746262 (50.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1134500 out of 1747704 (64.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1742357 out of 1747704 (99.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1747704 out of 1747704 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1747703 out of 1747704 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1747704 out of 1747704 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 885338/885338   201s /    53s\n",
      "[======================= 53%                       ] 928000/1742357  201s /   178s\n",
      "FUTURE #1 complete. Time used: 205 seconds\n",
      "[==================================================] 1742357/1742357  338s /     6s\n",
      "[======================= 98% ====================> ] 1720000/1747704  338s /     6s\n",
      "FUTURE #3 complete. Time used: 342 seconds\n",
      "[==================================================] 1747704/1747704  341s /     6s\n",
      "[==================================================] 1744000/1747704  342s /     6s\n",
      "FUTURE #4 complete. Time used: 346 seconds\n",
      "[==================================================] 1747704/1747704  342s /     6s\n",
      "\n",
      "FUTURE #5 complete. Time used: 347 seconds\n",
      "[==================================================] 1747703/1747703  343s /     7s\n",
      "\n",
      "FUTURE #6 complete. Time used: 351 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1442, 2884, 0, 7271]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 1442, 2884, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 1442, 2884, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7271\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2884, 1212, 4326]\n",
      "submit a job to the worker for sub box 1: [1212, 2884, 2424, 4326]\n",
      "submit a job to the worker for sub box 2: [2424, 2884, 3636, 4326]\n",
      "submit a job to the worker for sub box 3: [3636, 2884, 4848, 4326]\n",
      "submit a job to the worker for sub box 4: [4848, 2884, 6060, 4326]\n",
      "submit a job to the worker for sub box 5: [6060, 2884, 7271, 4326]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1747704 out of 1747704 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 820317 out of 1747704 (46.9%)\n",
      "number of pixels to invert: 1747704 out of 1747704 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1747704 out of 1747704 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1242430 out of 1746262 (71.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1747702 out of 1747704 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 820317/820317   183s /   215s\n",
      "[======================= 47%                       ] 824000/1747704  183s /   207s\n",
      "FUTURE #1 complete. Time used: 188 seconds\n",
      "[======================= 93% =================>    ] 1156000/1242430  242s /    18s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 1747704/1747704  338s /     6s\n",
      "[======================= 98% ====================> ] 1714000/1747702  339s /     6s\n",
      "FUTURE #3 complete. Time used: 344 seconds\n",
      "[==================================================] 1747704/1747704  339s /     6s\n",
      "[======================= 98% ====================> ] 1718000/1747704  340s /     6s\n",
      "FUTURE #4 complete. Time used: 344 seconds\n",
      "[==================================================] 1747702/1747702  340s /     6s\n",
      "[==================================================] 1747704/1747704 \n",
      "\n",
      "FUTURE #5 complete. Time used: 349 seconds\n",
      "\n",
      "FUTURE #6 complete. Time used: 349 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2884, 4326, 0, 7271]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2884, 4326, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2884, 4326, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7271\n",
      "box length: 1439\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "[==================================================] 281471/281471    65s /   195s\n",
      "[======================> 46%                       ] 286000/625131   65s /    76ss\n",
      "FUTURE #1 complete. Time used: 70 seconds\n",
      "[==================================================] 415813/415813    89s /   159s\n",
      "[=================>      36%                       ] 410000/1127635   89s /   159s\n",
      "FUTURE #2 complete. Time used: 94 seconds\n",
      "[==================================================] 625131/625131   128s /   104s\n",
      "[======================= 59% =>                    ] 632000/1079659  128s /    89s\n",
      "FUTURE #3 complete. Time used: 133 seconds\n",
      "[==================================================] 1011405/1011405 175s /    15s\n",
      "\n",
      "FUTURE #4 complete. Time used: 180 seconds\n",
      "[==================================================] 1079659/1079659  184s /     9s\n",
      "[======================= 95% ===================>  ] 1068000/1127635  185s /     9s\n",
      "FUTURE #5 complete. Time used: 189 seconds\n",
      "[==================================================] 1127635/1127635  189s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 196 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4326, 5765, 0, 7271]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4326, 5765, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4326, 5765, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 18 mins 39.4 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7271)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 11/11   84s /     8s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 34.5 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 11/11   53s /     5s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20201014 - 0.0036\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0155)\n",
      "20200710 - 0.0178\n",
      "save date(s) to file: exclude_date.txt\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20201014\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5765, 0, 7271)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20201014\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5765, 0, 7271)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20201014\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5765, 0, 7271)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20201014\n",
      "time used: 00 mins 50.7 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: ['20200710']\n",
      "--------------------------------------------------\n",
      "dates from input file: 11\n",
      "['20200616', '20200628', '20200710', '20200722', '20200803', '20200815', '20200827', '20200908', '20200920', '20201002', '20201014']\n",
      "--------------------------------------------------\n",
      "dates used to estimate the time function: 10\n",
      "['20200616', '20200628', '20200722', '20200803', '20200815', '20200827', '20200908', '20200920', '20201002', '20201014']\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5765, 7271)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5765, 7271)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5765, 7271)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5765, 7271)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5765, 7271)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5\n",
      "split along y dimension (5765) into 2 boxes\n",
      "    with each box up to 2883 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 2 --------------\n",
      "box width:  7271\n",
      "box length: 2883\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13689320 out of 20962293 (65.3%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 2883, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 2883, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 2883, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 2883, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 2883, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 2 --------------\n",
      "box width:  7271\n",
      "box length: 2882\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13600929 out of 20955022 (64.9%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [2883, 5765, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [2883, 5765, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [2883, 5765, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [2883, 5765, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [2883, 5765, 0, 7271]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5.\n",
      "time used: 00 mins 24.3 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7271, 5765)\n",
      "subset coverage in y/x: (0, 0, 7271, 5765)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7271/5765\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.13, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 02 mins 29.3 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2020\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 81 mins 28.9 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "working on AT151, frame_3, 2021\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase_MuRP.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/frame_3_2021_SenAT151.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-06-22 06:01:00.389208--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: frame_3_2021_SenAT151\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/frame_3_2021_SenAT151.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2021/*/*2021*unw_phase_MuRP_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2021/*/*2021*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2021/*/*2021*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2021/*/*2021*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3/AT151/frame_3/2021/*/*2021*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy frame_3_2021_SenAT151.txt to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg      to inputs   directory for backup.\n",
      "copy frame_3_2021_SenAT151.txt to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg      to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/frame_3_2021_SenAT151.txt --project frame_3_2021_SenAT151\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2021/*/*2021*unw_phase_MuRP_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2021/*/*2021*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2021/*/*2021*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2021/*/*2021*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3/AT151/frame_3/2021/*/*2021*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3/AT151/frame_3/2021/S1BB_20210611T010121_20210623T010122_VVP012_INT40_G_ueF_E099/S1BB_20210611T010121_20210623T010122_VVP012_INT40_G_ueF_E099_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3/AT151/frame_3/2021/S1BB_20210611T010121_20210623T010122_VVP012_INT40_G_ueF_E099/S1BB_20210611T010121_20210623T010122_VVP012_INT40_G_ueF_E099_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3/AT151/frame_3/2021/S1BB_20210611T010121_20210623T010122_VVP012_INT40_G_ueF_E099/S1BB_20210611T010121_20210623T010122_VVP012_INT40_G_ueF_E099_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5771, 7315) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5771, 7315) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5771, 7315) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20210611T010121_20210623T010122_VVP012_INT40_G_ueF_E099_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5771, 7315) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3/AT151/frame_3/2021/*/*2021*unw_phase_MuRP_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3/AT151/frame_3/2021/*/*2021*corr_clipped.tif\n",
      "number of unwrapPhase     : 40\n",
      "number of coherence       : 40\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (40, 5771, 7315) with compression = None\n",
      "[==================================================] 20210927_20211009  226s /     4s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (40, 5771, 7315) with compression = None\n",
      "[==================================================] 20210927_20211009  211s /     4s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (40, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (40,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (40,)\n",
      "add extra metadata: {'PROJECT_NAME': 'frame_3_2021_SenAT151', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 08 mins 37.7 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file frame_3_2021_SenAT151.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file frame_3_2021_SenAT151.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5771, 7315)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 40/40   41s /     0s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 11\n",
      "number of interferograms: 40\n",
      "shift all perp baseline by 12.2614164352417 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 40\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 131.33 m\n",
      "max temporal      baseline: 60.0 days\n",
      "showing coherence\n",
      "data range: [0.5612883, 0.8931435]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 40/40   40s /     0s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5771, 7315)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/maskConnComp.h5\n",
      "time used: 00 mins 42.9 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5771/5771   29s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5771, 7315)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/avgSpatialCoh.h5\n",
      "time used: 00 mins 39.3 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5 ...\n",
      "[=======>                17%                       ] lines 1150/5771    0s /     0s/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/objects/stack.py:1059: RuntimeWarning: Mean of empty slice\n",
      "  dmean[r0:r1, :] = np.nanmean(data, axis=0)\n",
      "[==================================================] lines 5771/5771   34s /     7s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (4088, 4716)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5\n",
      "{'REF_Y': '4088', 'REF_X': '4716', 'REF_LAT': '4156460.0', 'REF_LON': '458820.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5771/5771   37s /     7s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5771, 7315)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/avgPhaseVelocity.h5\n",
      "time used: 00 mins 49.1 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 40\n",
      "number of triplets: 70\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (380, 7315), 16 blocks in total\n",
      "reference pixel in y/x: (4088, 4716) from dataset: unwrapPhase\n",
      "[==================================================] line 5700 / 5771   85s /     5s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5771, 7315)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/numTriNonzeroIntAmbiguity.png\n",
      "time used: 01 mins 32.3 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT151/frame_3/mintpy_2021/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (4088, 4716) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 40\n",
      "number of acquisitions  : 11\n",
      "number of lines   : 5771\n",
      "number of columns : 7315\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (11, 5771, 7315)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5771, 7315)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5771, 7315)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5771 lines into 6 patches for processing\n",
      "    with each patch up to 970 lines\n",
      "\n",
      "------- processing patch 1 out of 6 --------------\n",
      "box width:  7315\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1220, 970]\n",
      "submit a job to the worker for sub box 1: [1220, 0, 2440, 970]\n",
      "submit a job to the worker for sub box 2: [2440, 0, 3660, 970]\n",
      "submit a job to the worker for sub box 3: [3660, 0, 4880, 970]\n",
      "submit a job to the worker for sub box 4: [4880, 0, 6100, 970]\n",
      "submit a job to the worker for sub box 5: [6100, 0, 7315, 970]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4880, 0, 6100, 970] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6100, 0, 7315, 970] * 40 ...\n",
      "reading coherence in [0, 0, 1220, 970] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2440, 0, 3660, 970] * 40 ...\n",
      "reading coherence in [1220, 0, 2440, 970] * 40 ...\n",
      "reading coherence in [3660, 0, 4880, 970] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 2 / 12\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "chunk 3 / 12\n",
      "chunk 1 / 12\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 3 / 12\n",
      "chunk 1 / 12\n",
      "chunk 4 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 4 / 12\n",
      "chunk 2 / 12\n",
      "chunk 5 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 6 / 12\n",
      "chunk 3 / 12\n",
      "chunk 5 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 7 / 12\n",
      "chunk 4 / 12\n",
      "chunk 6 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 8 / 12\n",
      "chunk 5 / 12\n",
      "chunk 7 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 10 / 12\n",
      "chunk 9 / 12\n",
      "chunk 8 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 11 / 12\n",
      "chunk 9 / 12\n",
      "chunk 8 / 12\n",
      "chunk 10 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4880, 0, 6100, 970] * 40 ...\n",
      "chunk 10 / 12\n",
      "chunk 9 / 12\n",
      "chunk 11 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6100, 0, 7315, 970] * 40 ...\n",
      "chunk 11 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 0, 1220, 970] * 40 ...\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2440, 0, 3660, 970] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1220, 0, 2440, 970] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3660, 0, 4880, 970] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "use input reference value\n",
      "use input reference value\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "number of pixels to invert: 201304 out of 1178550 (17.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "number of pixels to invert: 574894 out of 1183400 (48.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]skip pixels with unwrapPhase = NaN in all interferograms\n",
      "[>                                                 ]number of pixels to invert: 464626 out of 1183400 (39.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]number of pixels to invert: 0 out of 1183400 (0.0%)\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]number of pixels to invert: 578672 out of 1183400 (48.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]\n",
      "FUTURE #1 complete. Time used: 12 seconds\n",
      "[>                                                 ]number of pixels to invert: 65127 out of 1183400 (5.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 65127/65127 pixels    19s /    42s\n",
      "[=====>                  12%                       ] 68400/574894 pixels   19s /   146sconverting LOS phase unit from radian to meter\n",
      "[=====>                  11%                       ] 65400/578672 pixels   19s /   157s\n",
      "FUTURE #2 complete. Time used: 32 seconds\n",
      "[==================================================] 201304/201304 pixels   55s /    70s\n",
      "[=================>      36%                       ] 209800/574894 pixels   55s /    99sconverting LOS phase unit from radian to meter\n",
      "[=================>      37%                       ] 210000/574894 pixels   55s /    95s\n",
      "FUTURE #3 complete. Time used: 68 seconds\n",
      "[==================================================] 464626/464626 pixels  136s /    34s\n",
      "[======================= 80% ===========>          ] 461600/578672 pixels  136s /    34sconverting LOS phase unit from radian to meter\n",
      "[======================= 80% ===========>          ] 461800/578672 pixels  136s /    34s\n",
      "FUTURE #4 complete. Time used: 148 seconds\n",
      "[==================================================] 574894/574894 pixels  154s /     8s\n",
      "[======================= 95% ===================>  ] 552400/578672 pixels  154s /     8sconverting LOS phase unit from radian to meter\n",
      "[======================= 95% ===================>  ] 552600/578672 pixels  154s /     8s\n",
      "FUTURE #5 complete. Time used: 167 seconds\n",
      "[==================================================] 578672/578672 pixels  158s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 172 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 970, 0, 7315]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 970, 0, 7315]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 970, 0, 7315]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 02 mins 57.4 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 6 --------------\n",
      "box width:  7315\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 970, 1220, 1940]\n",
      "submit a job to the worker for sub box 1: [1220, 970, 2440, 1940]\n",
      "submit a job to the worker for sub box 2: [2440, 970, 3660, 1940]\n",
      "submit a job to the worker for sub box 3: [3660, 970, 4880, 1940]\n",
      "submit a job to the worker for sub box 4: [4880, 970, 6100, 1940]\n",
      "submit a job to the worker for sub box 5: [6100, 970, 7315, 1940]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1220, 970, 2440, 1940] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 970, 1220, 1940] * 40 ...\n",
      "reading coherence in [3660, 970, 4880, 1940] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6100, 970, 7315, 1940] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2440, 970, 3660, 1940] * 40 ...\n",
      "reading coherence in [4880, 970, 6100, 1940] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 970, 1220, 1940] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4880, 970, 6100, 1940] * 40 ...\n",
      "reading unwrapPhase in [3660, 970, 4880, 1940] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1220, 970, 2440, 1940] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6100, 970, 7315, 1940] * 40 ...\n",
      "reading unwrapPhase in [2440, 970, 3660, 1940] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 719277 out of 1183400 (60.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 447788 out of 1178550 (38.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1151976 out of 1183400 (97.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1183400 out of 1183400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1183400 out of 1183400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1183400 out of 1183400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 447788/447788 pixels   188s /   294s\n",
      "[===================>    39%                       ] 456800/1183400 pixels  188s /   294sconverting LOS phase unit from radian to meter\n",
      "[===================>    39%                       ] 457000/1183400 pixels  188s /   294s\n",
      "FUTURE #1 complete. Time used: 201 seconds\n",
      "[==================================================] 719277/719277 pixels   289s /   185s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 61% =>                    ] 718200/1183400 pixels  290s /   185s\n",
      "FUTURE #2 complete. Time used: 303 seconds\n",
      "[==================================================] 1151976/1151976 pixels  425s /    13s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 1143200/1183400 pixels  425s /    13s\n",
      "FUTURE #3 complete. Time used: 438 seconds\n",
      "[==================================================] 1183400/1183400 pixels  431s /     8s\n",
      "[==================================================] 1172200/1183400 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1167200/1183400 pixels\n",
      "FUTURE #4 complete. Time used: 445 seconds\n",
      "[==================================================] 1183400/1183400 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1178200/1183400 pixels\n",
      "FUTURE #5 complete. Time used: 447 seconds\n",
      "[==================================================] 1183400/1183400 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 448 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 970, 1940, 0, 7315]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [970, 1940, 0, 7315]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [970, 1940, 0, 7315]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 10 mins 29.7 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 6 --------------\n",
      "box width:  7315\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1940, 1220, 2910]\n",
      "submit a job to the worker for sub box 1: [1220, 1940, 2440, 2910]\n",
      "submit a job to the worker for sub box 2: [2440, 1940, 3660, 2910]\n",
      "submit a job to the worker for sub box 3: [3660, 1940, 4880, 2910]\n",
      "submit a job to the worker for sub box 4: [4880, 1940, 6100, 2910]\n",
      "submit a job to the worker for sub box 5: [6100, 1940, 7315, 2910]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4880, 1940, 6100, 2910] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6100, 1940, 7315, 2910] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 1940, 1220, 2910] * 40 ...\n",
      "reading coherence in [2440, 1940, 3660, 2910] * 40 ...\n",
      "reading coherence in [1220, 1940, 2440, 2910] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3660, 1940, 4880, 2910] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4880, 1940, 6100, 2910] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2440, 1940, 3660, 2910] * 40 ...\n",
      "reading unwrapPhase in [3660, 1940, 4880, 2910] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1220, 1940, 2440, 2910] * 40 ...\n",
      "reading unwrapPhase in [6100, 1940, 7315, 2910] * 40 ...\n",
      "reading unwrapPhase in [0, 1940, 1220, 2910] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 750027 out of 1183400 (63.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1183400 out of 1183400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 602527 out of 1178550 (51.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1183400 out of 1183400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1183400 out of 1183400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1183400 out of 1183400 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[=====>                  12%                       ] 72000/591192 pixels 2225s / 16322sss"
     ]
    }
   ],
   "source": [
    "mintpy_multiyear(orbit_list, year_list, ['frame_3'], clip=True, mintpy=True, clean_clip=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mintpy] *",
   "language": "python",
   "name": "conda-env-mintpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
