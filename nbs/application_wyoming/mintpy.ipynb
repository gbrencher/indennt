{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f7bb06e-6e63-4d64-b7d6-8ccb6c97757b",
   "metadata": {},
   "source": [
    "# MintPy for signal maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c766f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import mintpy\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ed07a6-5cd1-428e-8e7b-aa8eebec1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_list = ['AT137']\n",
    "year_list = ['2017', '2018', '2019', '2020', '2021']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910045f-42cf-4bf6-8c42-abda85c05b03",
   "metadata": {},
   "source": [
    "## clip files to common extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ec0ec07-2bfd-4a78-b90a-df7ea38c24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_overlap(file_list: List[Union[str, Path]]) -> List[float]:\n",
    "    \"\"\"Get the common overlap of  a list of GeoTIFF files\n",
    "    \n",
    "    Arg:\n",
    "        file_list: a list of GeoTIFF files\n",
    "    \n",
    "    Returns:\n",
    "         [ulx, uly, lrx, lry], the upper-left x, upper-left y, lower-right x, and lower-right y\n",
    "         corner coordinates of the common overlap\n",
    "    \"\"\"\n",
    "    \n",
    "    corners = [gdal.Info(str(dem), format='json')['cornerCoordinates'] for dem in file_list]\n",
    "\n",
    "    ulx = max(corner['upperLeft'][0] for corner in corners)\n",
    "    uly = min(corner['upperLeft'][1] for corner in corners)\n",
    "    lrx = min(corner['lowerRight'][0] for corner in corners)\n",
    "    lry = max(corner['lowerRight'][1] for corner in corners)\n",
    "    return [ulx, uly, lrx, lry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8aeb241-e1b8-404d-b156-11177471a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_hyp3_products_to_common_overlap(data_path: Union[str, Path], overlap: List[float]) -> None:\n",
    "    \"\"\"Clip all GeoTIFF files to their common overlap\n",
    "    \n",
    "    Args:\n",
    "        data_dir:\n",
    "            directory containing the GeoTIFF files to clip\n",
    "        overlap:\n",
    "            a list of the upper-left x, upper-left y, lower-right-x, and lower-tight y\n",
    "            corner coordinates of the common overlap\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    \n",
    "    files_for_mintpy = ['_water_mask.tif', '_corr.tif', '_unw_phase_CNN_signal.tif', '_dem.tif', '_lv_theta.tif', '_lv_phi.tif']\n",
    "\n",
    "    for extension in files_for_mintpy:\n",
    "        print(f'working on {extension}') \n",
    "        for file in data_path.rglob(f'*{extension}'):\n",
    "\n",
    "            dst_file = file.parent / f'{file.stem}_clipped{file.suffix}'\n",
    "\n",
    "            gdal.Translate(destName=str(dst_file), srcDS=str(file), projWin=overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dc256-88c0-4ac9-88aa-4ee420ca1e1d",
   "metadata": {},
   "source": [
    "## Mintpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033276cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write to MintPy config file\n",
    "def write_config_file(out_file, CONFIG_TXT, mode='a'): \n",
    "    \"\"\"Write configuration files for MintPy to process products\"\"\"\n",
    "    if not os.path.isfile(out_file) or mode == 'w':\n",
    "        with open(out_file, \"w\") as fid:\n",
    "            fid.write(CONFIG_TXT)\n",
    "        print('write configuration to file: {}'.format(out_file))\n",
    "    else:\n",
    "        with open(out_file, \"a\") as fid:\n",
    "            fid.write(\"\\n\" + CONFIG_TXT)\n",
    "        print('add the following to file: \\n{}'.format(CONFIG_TXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42499563-1225-4427-8863-4ef390300f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clip files and run mintpy for multiple years \n",
    "def mintpy_multiyear(orbit_list, year_list, clip=True, mintpy=True, clean_clip=True):\n",
    "    # hardcoded paths for now \n",
    "    home_path_d = '/mnt/d/indennt'\n",
    "    home_path = '/mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data'\n",
    "    for orbit in orbit_list:\n",
    "        for year in year_list:\n",
    "            print(f'working on {orbit}, {year}')\n",
    "            data_path = f'{home_path_d}/hyp3_app/{orbit}/{year}'\n",
    "            mintpy_path = f'{home_path}/signal_mintpy/{orbit}/mintpy_{year}'\n",
    "            mintpy_path_d = f'{home_path_d}/mintpy_app/{orbit}/'\n",
    "\n",
    "            if clip==True:\n",
    "                # identify and crop to common overlap\n",
    "                print('identifying common overlap')\n",
    "                dem_files = Path(data_path).glob('*/*_dem.tif')\n",
    "                overlap = get_common_overlap(dem_files)\n",
    "                print('clipping to common overlap')\n",
    "                clip_hyp3_products_to_common_overlap(Path(data_path), overlap)\n",
    "\n",
    "            # make output dir for mintpy\n",
    "            if not os.path.exists(mintpy_path):\n",
    "                os.mkdir(mintpy_path)\n",
    "\n",
    "            # write config file for mintpy\n",
    "            CONFIG_TXT = f'''# vim: set filetype=cfg:\n",
    "            ##----------------------------- hyp3 ---------------------##\n",
    "            mintpy.load.processor        = hyp3\n",
    "            ##---------interferogram datasets:\n",
    "            mintpy.load.unwFile          = {data_path}/*/*{year}*unw_phase_CNN_signal_clipped.tif\n",
    "            mintpy.load.corFile          = {data_path}/*/*{year}*corr_clipped.tif\n",
    "            ##---------geometry datasets:\n",
    "            mintpy.load.demFile          = {data_path}/*/*{year}*dem_clipped.tif\n",
    "            mintpy.load.incAngleFile     = {data_path}/*/*{year}*lv_theta_clipped.tif\n",
    "            mintpy.load.waterMaskFile    = {data_path}/*/*{year}*water_mask_clipped.tif\n",
    "\n",
    "            mintpy.deramp                = linear\n",
    "            mintpy.reference.lalo        = auto\n",
    "            mintpy.troposphericDelay.method  = no\n",
    "\n",
    "            mintpy.compute.cluster    = local\n",
    "            mintpy.compute.numWorker  = 10\n",
    "            '''\n",
    "\n",
    "            os.chdir(mintpy_path)\n",
    "            config_file = f'{mintpy_path}/{year}_Sen{orbit}.txt'\n",
    "            write_config_file(config_file, CONFIG_TXT, mode='w')\n",
    "\n",
    "            if mintpy==True:\n",
    "                # run mintpy\n",
    "                print('starting mintpy')\n",
    "                !smallbaselineApp.py --dir {mintpy_path} {config_file}\n",
    "                print('moving outputs to drive')\n",
    "                !cp -r $mintpy_path $mintpy_path_d && rm -R $mintpy_path\n",
    "\n",
    "            if clean_clip==True:\n",
    "                # remove clipped files\n",
    "                print('removing clipped files')\n",
    "                clipped_files = f'{data_path}/*/*_clipped.tif'\n",
    "                !rm {clipped_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf39b43-8dac-40e1-b054-406c9e8706a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on AT137, 2017\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase_CNN_signal.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/2017_SenAT137.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-07-06 17:38:59.655515--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: 2017_SenAT137\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/2017_SenAT137.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 10\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*unw_phase_CNN_signal_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy 2017_SenAT137.txt    to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg to inputs   directory for backup.\n",
      "copy 2017_SenAT137.txt    to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/2017_SenAT137.txt --project 2017_SenAT137\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*unw_phase_CNN_signal_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3_app/AT137/2017/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3_app/AT137/2017/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3_app/AT137/2017/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5763, 7327) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5763, 7327) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5763, 7327) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5763, 7327) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*unw_phase_CNN_signal_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*corr_clipped.tif\n",
      "number of unwrapPhase     : 45\n",
      "number of coherence       : 45\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (45, 5763, 7327) with compression = None\n",
      "[==================================================] 20170929_20171011  257s /     5s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (45, 5763, 7327) with compression = None\n",
      "[==================================================] 20170929_20171011  254s /     5s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (45, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (45,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (45,)\n",
      "add extra metadata: {'PROJECT_NAME': '2017_SenAT137', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 09 mins 40.3 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file 2017_SenAT137.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file 2017_SenAT137.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 45/45   46s /     0s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 10\n",
      "number of interferograms: 45\n",
      "shift all perp baseline by 19.02423095703125 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 45\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 201.27 m\n",
      "max temporal      baseline: 120.0 days\n",
      "showing coherence\n",
      "data range: [0.5309866, 0.8892115]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 45/45   42s /     0s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/maskConnComp.h5\n",
      "time used: 00 mins 45.7 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   63s /    10s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/avgSpatialCoh.h5\n",
      "time used: 01 mins 12.9 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   39s /     6s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (3677, 6281)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5\n",
      "{'REF_Y': '3677', 'REF_X': '6281', 'REF_LAT': '4740500.0', 'REF_LON': '750300.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   41s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/avgPhaseVelocity.h5\n",
      "time used: 00 mins 53.7 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 45\n",
      "number of triplets: 120\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (250, 7327), 24 blocks in total\n",
      "reference pixel in y/x: (3677, 6281) from dataset: unwrapPhase\n",
      "[==================================================] line 5750 / 5763  184s /     7s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/numTriNonzeroIntAmbiguity.png\n",
      "time used: 03 mins 14.6 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (3677, 6281) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 45\n",
      "number of acquisitions  : 10\n",
      "number of lines   : 5763\n",
      "number of columns : 7327\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5763 lines into 6 patches for processing\n",
      "    with each patch up to 970 lines\n",
      "\n",
      "------- processing patch 1 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 10 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 10 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 733, 970]\n",
      "submit a job to the worker for sub box 1: [733, 0, 1466, 970]\n",
      "submit a job to the worker for sub box 2: [1466, 0, 2199, 970]\n",
      "submit a job to the worker for sub box 3: [2199, 0, 2932, 970]\n",
      "submit a job to the worker for sub box 4: [2932, 0, 3665, 970]\n",
      "submit a job to the worker for sub box 5: [3665, 0, 4398, 970]\n",
      "submit a job to the worker for sub box 6: [4398, 0, 5131, 970]\n",
      "submit a job to the worker for sub box 7: [5131, 0, 5864, 970]\n",
      "submit a job to the worker for sub box 8: [5864, 0, 6597, 970]\n",
      "submit a job to the worker for sub box 9: [6597, 0, 7327, 970]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2932, 0, 3665, 970] * 45 ...\n",
      "reading coherence in [3665, 0, 4398, 970] * 45 ...\n",
      "reading coherence in [5131, 0, 5864, 970] * 45 ...\n",
      "reading coherence in [6597, 0, 7327, 970] * 45 ...\n",
      "reading coherence in [2199, 0, 2932, 970] * 45 ...\n",
      "reading coherence in [5864, 0, 6597, 970] * 45 ...\n",
      "reading coherence in [1466, 0, 2199, 970] * 45 ...\n",
      "reading coherence in [4398, 0, 5131, 970] * 45 ...\n",
      "reading coherence in [0, 0, 733, 970] * 45 ...\n",
      "reading coherence in [733, 0, 1466, 970] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "reading unwrapPhase in [6597, 0, 7327, 970] * 45 ...\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1466, 0, 2199, 970] * 45 ...\n",
      "reading unwrapPhase in [5131, 0, 5864, 970] * 45 ...\n",
      "reading unwrapPhase in [4398, 0, 5131, 970] * 45 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [733, 0, 1466, 970] * 45 ...\n",
      "reading unwrapPhase in [5864, 0, 6597, 970] * 45 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [0, 0, 733, 970] * 45 ...\n",
      "reading unwrapPhase in [2199, 0, 2932, 970] * 45 ...\n",
      "reading unwrapPhase in [3665, 0, 4398, 970] * 45 ...\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [2932, 0, 3665, 970] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 0 out of 708100 (0.0%)\n",
      "number of pixels to invert: 0 out of 711010 (0.0%)\n",
      "number of pixels to invert: 129870 out of 711010 (18.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 0 out of 711010 (0.0%)\n",
      "\n",
      "FUTURE #1 complete. Time used: 23 seconds\n",
      "number of pixels to invert: 0 out of 711010 (0.0%)\n",
      "number of pixels to invert: 337475 out of 711010 (47.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 354886 out of 711010 (49.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 343859 out of 711010 (48.4%)\n",
      "number of pixels to invert: 249497 out of 711010 (35.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "\n",
      "FUTURE #2 complete. Time used: 23 seconds\n",
      "[>                                                 ]number of pixels to invert: 250601 out of 711010 (35.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "\n",
      "FUTURE #3 complete. Time used: 24 seconds\n",
      "[>                                                 ]\n",
      "FUTURE #4 complete. Time used: 24 seconds\n",
      "[==================================================] 129870/129870 pixels  130s /   231s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=================>      36%                       ] 128000/354886 pixels  130s /   232s\n",
      "FUTURE #5 complete. Time used: 154 seconds\n",
      "[==================================================] 250601/250601 pixels  230s /    85s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 72% =======>              ] 247400/343859 pixels  230s /    89s\n",
      "FUTURE #6 complete. Time used: 254 seconds\n",
      "[==================================================] 249497/249497 pixels  231s /    89s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 73% =======>              ] 246000/337475 pixels  231s /    85s\n",
      "FUTURE #7 complete. Time used: 254 seconds\n",
      "[==================================================] 337475/337475 pixels  284s /    11s\n",
      "[======================= 96% ===================>  ] 340000/354886 pixels  284s /    11sconverting LOS phase unit from radian to meter\n",
      "[==================================================] 339200/343859 pixels\n",
      "FUTURE #8 complete. Time used: 308 seconds\n",
      "[==================================================] 343859/343859 pixels  287s /     8s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 344800/354886 pixels  287s /     8s\n",
      "FUTURE #9 complete. Time used: 310 seconds\n",
      "[==================================================] 354886/354886 pixels  289s /     5s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #10 complete. Time used: 314 seconds\n",
      "close dask client\n",
      "2023-07-06 18:02:07,850 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/worker.py\", line 1237, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/utils_comm.py\", line 413, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/core.py\", line 1365, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/core.py\", line 1124, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 241, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50866 remote=tcp://127.0.0.1:37947>: Stream is closed\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 970, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 970, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 970, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 05 mins 24.7 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 10 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 10 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 970, 733, 1940]\n",
      "submit a job to the worker for sub box 1: [733, 970, 1466, 1940]\n",
      "submit a job to the worker for sub box 2: [1466, 970, 2199, 1940]\n",
      "submit a job to the worker for sub box 3: [2199, 970, 2932, 1940]\n",
      "submit a job to the worker for sub box 4: [2932, 970, 3665, 1940]\n",
      "submit a job to the worker for sub box 5: [3665, 970, 4398, 1940]\n",
      "submit a job to the worker for sub box 6: [4398, 970, 5131, 1940]\n",
      "submit a job to the worker for sub box 7: [5131, 970, 5864, 1940]\n",
      "submit a job to the worker for sub box 8: [5864, 970, 6597, 1940]\n",
      "submit a job to the worker for sub box 9: [6597, 970, 7327, 1940]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [5131, 970, 5864, 1940] * 45 ...\n",
      "reading coherence in [1466, 970, 2199, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 970, 733, 1940] * 45 ...\n",
      "reading coherence in [733, 970, 1466, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [5864, 970, 6597, 1940] * 45 ...\n",
      "reading coherence in [3665, 970, 4398, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2199, 970, 2932, 1940] * 45 ...\n",
      "reading coherence in [4398, 970, 5131, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6597, 970, 7327, 1940] * 45 ...\n",
      "reading coherence in [2932, 970, 3665, 1940] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "chunk 1 / 8\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "reading unwrapPhase in [733, 970, 1466, 1940] * 45 ...\n",
      "chunk 8 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 7 / 8\n",
      "reading unwrapPhase in [5131, 970, 5864, 1940] * 45 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [5864, 970, 6597, 1940] * 45 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1466, 970, 2199, 1940] * 45 ...\n",
      "reading unwrapPhase in [3665, 970, 4398, 1940] * 45 ...\n",
      "reading unwrapPhase in [4398, 970, 5131, 1940] * 45 ...\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "reading unwrapPhase in [0, 970, 733, 1940] * 45 ...\n",
      "reading unwrapPhase in [2199, 970, 2932, 1940] * 45 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [6597, 970, 7327, 1940] * 45 ...\n",
      "reading unwrapPhase in [2932, 970, 3665, 1940] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 693813 out of 711010 (97.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 268026 out of 711010 (37.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 631955 out of 711010 (88.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 709413 out of 711010 (99.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 527672 out of 711010 (74.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 707917 out of 711010 (99.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 35380 out of 708100 (5.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 35380/35380 pixels    44s /   297s\n",
      "[=>                       5%                       ] 35800/711010 pixels   44s /   845sconverting LOS phase unit from radian to meter\n",
      "[=>                       5%                       ] 34200/709413 pixels   44s /   847s\n",
      "FUTURE #1 complete. Time used: 67 seconds\n",
      "[==================================================] 268026/268026 pixels  284s /   463s\n",
      "[======================= 52%                       ] 272400/527672 pixels  284s /   262sconverting LOS phase unit from radian to meter\n",
      "[==================>     38%                       ] 273400/711010 pixels  283s /   462s\n",
      "FUTURE #2 complete. Time used: 307 seconds\n",
      "[==================================================] 527672/527672 pixels  543s /   200s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 73% =======>              ] 521600/711010 pixels  543s /   201s\n",
      "FUTURE #3 complete. Time used: 566 seconds\n",
      "[==================================================] 631955/631955 pixels  641s /    79s\n",
      "[======================= 87% ===============>      ] 621800/711010 pixels  641s /    95sconverting LOS phase unit from radian to meter\n",
      "[======================= 92% =================>    ] 638200/693813 pixels  641s /    55s\n",
      "FUTURE #4 complete. Time used: 664 seconds\n",
      "[==================================================] 693813/693813 pixels  689s /    36s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #5 complete. Time used: 712 seconds\n",
      "[==================================================] 709413/709413 pixels  707s /    14s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 705000/707917 pixels\n",
      "FUTURE #6 complete. Time used: 730 seconds\n",
      "[==================================================] 707917/707917 pixels  708s /    14s\n",
      "[==================================================] 710800/711010 pixelsconverting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #7 complete. Time used: 732 seconds\n",
      "[==================================================] 711010/711010 pixels \n",
      "[==================================================] 702800/711010 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 704000/711010 pixels\n",
      "FUTURE #8 complete. Time used: 733 seconds\n",
      "[==================================================] 711010/711010 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 710200/711010 pixels\n",
      "FUTURE #9 complete. Time used: 737 seconds\n",
      "[==================================================] 711010/711010 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #10 complete. Time used: 737 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 970, 1940, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [970, 1940, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [970, 1940, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 17 mins 49.6 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 10 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 10 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1940, 733, 2910]\n",
      "submit a job to the worker for sub box 1: [733, 1940, 1466, 2910]\n",
      "submit a job to the worker for sub box 2: [1466, 1940, 2199, 2910]\n",
      "submit a job to the worker for sub box 3: [2199, 1940, 2932, 2910]\n",
      "submit a job to the worker for sub box 4: [2932, 1940, 3665, 2910]\n",
      "submit a job to the worker for sub box 5: [3665, 1940, 4398, 2910]\n",
      "submit a job to the worker for sub box 6: [4398, 1940, 5131, 2910]\n",
      "submit a job to the worker for sub box 7: [5131, 1940, 5864, 2910]\n",
      "submit a job to the worker for sub box 8: [5864, 1940, 6597, 2910]\n",
      "submit a job to the worker for sub box 9: [6597, 1940, 7327, 2910]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4398, 1940, 5131, 2910] * 45 ...\n",
      "reading coherence in [2932, 1940, 3665, 2910] * 45 ...\n",
      "reading coherence in [5131, 1940, 5864, 2910] * 45 ...\n",
      "reading coherence in [6597, 1940, 7327, 2910] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [733, 1940, 1466, 2910] * 45 ...\n",
      "reading coherence in [0, 1940, 733, 2910] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3665, 1940, 4398, 2910] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2199, 1940, 2932, 2910] * 45 ...\n",
      "reading coherence in [5864, 1940, 6597, 2910] * 45 ...\n",
      "reading coherence in [1466, 1940, 2199, 2910] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [4398, 1940, 5131, 2910] * 45 ...\n",
      "chunk 7 / 8\n",
      "reading unwrapPhase in [6597, 1940, 7327, 2910] * 45 ...\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [3665, 1940, 4398, 2910] * 45 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 6 / 8\n",
      "reading unwrapPhase in [5864, 1940, 6597, 2910] * 45 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [5131, 1940, 5864, 2910] * 45 ...\n",
      "reading unwrapPhase in [733, 1940, 1466, 2910] * 45 ...\n",
      "reading unwrapPhase in [2199, 1940, 2932, 2910] * 45 ...\n",
      "reading unwrapPhase in [1466, 1940, 2199, 2910] * 45 ...\n",
      "reading unwrapPhase in [0, 1940, 733, 2910] * 45 ...\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [2932, 1940, 3665, 2910] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 201515 out of 708100 (28.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 652624 out of 711010 (91.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 293371 out of 711010 (41.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 201515/201515 pixels  189s /   539s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 67% =====>                ] 198000/293371 pixels  189s /    93s\n",
      "FUTURE #1 complete. Time used: 214 seconds\n",
      "[==================================================] 293371/293371 pixels  287s /   397s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================> 46%                       ] 297800/652624 pixels  287s /   337s\n",
      "FUTURE #2 complete. Time used: 312 seconds\n",
      "[==================================================] 652624/652624 pixels  653s /    64s\n",
      "[======================= 89% ===============>      ] 633600/711010 pixels  652s /    80sconverting LOS phase unit from radian to meter\n",
      "[======================= 89% ===============>      ] 636200/711010 pixels  652s /    80s\n",
      "FUTURE #3 complete. Time used: 678 seconds\n",
      "[==================================================] 711010/711010 pixels  708s /    14s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 690600/711010 pixels  708s /    21s\n",
      "FUTURE #4 complete. Time used: 733 seconds\n",
      "[==================================================] 711010/711010 pixels  713s /    14s\n",
      "[======================= 98% ====================> ] 696200/711010 pixels  714s /    14sconverting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 699400/711010 pixels  714s /    14s\n",
      "FUTURE #5 complete. Time used: 739 seconds\n",
      "[==================================================] 711010/711010 pixels  714s /    14s\n",
      "[==================================================] 706400/711010 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 709200/711010 pixels  715s /    14s\n",
      "FUTURE #6 complete. Time used: 740 seconds\n",
      "[==================================================] 711010/711010 pixels  716s /    14s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 708400/711010 pixels\n",
      "FUTURE #7 complete. Time used: 741 seconds\n",
      "[==================================================] 711010/711010 pixels  717s /    14s\n",
      "[==================================================] 701600/711010 pixelsconverting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #8 complete. Time used: 743 seconds\n",
      "[==================================================] 711010/711010 pixels \n",
      "[==================================================] 707600/711010 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 707800/711010 pixels\n",
      "FUTURE #9 complete. Time used: 748 seconds\n",
      "[==================================================] 711010/711010 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #10 complete. Time used: 749 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1940, 2910, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [1940, 2910, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [1940, 2910, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 30 mins 28.9 secs.\n",
      "\n",
      "\n",
      "------- processing patch 4 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 10 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 10 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2910, 733, 3880]\n",
      "submit a job to the worker for sub box 1: [733, 2910, 1466, 3880]\n",
      "submit a job to the worker for sub box 2: [1466, 2910, 2199, 3880]\n",
      "submit a job to the worker for sub box 3: [2199, 2910, 2932, 3880]\n",
      "submit a job to the worker for sub box 4: [2932, 2910, 3665, 3880]\n",
      "submit a job to the worker for sub box 5: [3665, 2910, 4398, 3880]\n",
      "submit a job to the worker for sub box 6: [4398, 2910, 5131, 3880]\n",
      "submit a job to the worker for sub box 7: [5131, 2910, 5864, 3880]\n",
      "submit a job to the worker for sub box 8: [5864, 2910, 6597, 3880]\n",
      "submit a job to the worker for sub box 9: [6597, 2910, 7327, 3880]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2199, 2910, 2932, 3880] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2932, 2910, 3665, 3880] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1466, 2910, 2199, 3880] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6597, 2910, 7327, 3880] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 2910, 733, 3880] * 45 ...\n",
      "reading coherence in [5131, 2910, 5864, 3880] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [5864, 2910, 6597, 3880] * 45 ...\n",
      "reading coherence in [4398, 2910, 5131, 3880] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3665, 2910, 4398, 3880] * 45 ...\n",
      "reading coherence in [733, 2910, 1466, 3880] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "reading unwrapPhase in [0, 2910, 733, 3880] * 45 ...\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1466, 2910, 2199, 3880] * 45 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [5864, 2910, 6597, 3880] * 45 ...\n",
      "reading unwrapPhase in [6597, 2910, 7327, 3880] * 45 ...\n",
      "reading unwrapPhase in [2199, 2910, 2932, 3880] * 45 ...\n",
      "chunk 8 / 8\n",
      "chunk 7 / 8\n",
      "reading unwrapPhase in [4398, 2910, 5131, 3880] * 45 ...\n",
      "reading unwrapPhase in [733, 2910, 1466, 3880] * 45 ...\n",
      "reading unwrapPhase in [5131, 2910, 5864, 3880] * 45 ...\n",
      "chunk 8 / 8\n",
      "chunk 7 / 8\n",
      "reading unwrapPhase in [3665, 2910, 4398, 3880] * 45 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [2932, 2910, 3665, 3880] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "use input reference value\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 96887 out of 711010 (13.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 390919 out of 708100 (55.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 711009 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 709877 out of 711010 (99.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 96887/96887 pixels    90s /   663s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=====>                  13%                       ] 95800/711010 pixels   89s /   602s\n",
      "FUTURE #1 complete. Time used: 114 seconds\n",
      "[==================================================] 390919/390919 pixels  394s /   322s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 55%                       ] 392400/711010 pixels  394s /   322s\n",
      "FUTURE #2 complete. Time used: 418 seconds\n",
      "[==================================================] 711010/711010 pixels  706s /    29s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 96% ===================>  ] 684200/711010 pixels  706s /    29s\n",
      "FUTURE #3 complete. Time used: 730 seconds\n",
      "[==================================================] 709877/709877 pixels  709s /    21s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 687000/711010 pixels  709s /    21s\n",
      "FUTURE #4 complete. Time used: 732 seconds\n",
      "[==================================================] 711009/711009 pixels  711s /    22s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 706400/711010 pixels  711s /    22s\n",
      "FUTURE #5 complete. Time used: 735 seconds\n",
      "[==================================================] 711010/711010 pixels  714s /    22s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 708800/711010 pixels  714s /    22s\n",
      "FUTURE #6 complete. Time used: 738 seconds\n",
      "[==================================================] 711010/711010 pixels  716s /    14s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 710800/711010 pixels  716s /    14s\n",
      "FUTURE #7 complete. Time used: 740 seconds\n",
      "[==================================================] 711010/711010 pixels  716s /    14s\n",
      "[==================================================] 711000/711010 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 711010/711010 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 694200/711010 pixels  716s /    14s\n",
      "FUTURE #8 complete. Time used: 740 seconds\n",
      "\n",
      "FUTURE #9 complete. Time used: 740 seconds\n",
      "[==================================================] 711010/711010 pixels  719s /    14s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #10 complete. Time used: 748 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2910, 3880, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [2910, 3880, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [2910, 3880, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 43 mins 5.8 secs.\n",
      "\n",
      "\n",
      "------- processing patch 5 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 10 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 10 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 3880, 733, 4850]\n",
      "submit a job to the worker for sub box 1: [733, 3880, 1466, 4850]\n",
      "submit a job to the worker for sub box 2: [1466, 3880, 2199, 4850]\n",
      "submit a job to the worker for sub box 3: [2199, 3880, 2932, 4850]\n",
      "submit a job to the worker for sub box 4: [2932, 3880, 3665, 4850]\n",
      "submit a job to the worker for sub box 5: [3665, 3880, 4398, 4850]\n",
      "submit a job to the worker for sub box 6: [4398, 3880, 5131, 4850]\n",
      "submit a job to the worker for sub box 7: [5131, 3880, 5864, 4850]\n",
      "submit a job to the worker for sub box 8: [5864, 3880, 6597, 4850]\n",
      "submit a job to the worker for sub box 9: [6597, 3880, 7327, 4850]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6597, 3880, 7327, 4850] * 45 ...\n",
      "reading coherence in [733, 3880, 1466, 4850] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [5131, 3880, 5864, 4850] * 45 ...\n",
      "reading coherence in [4398, 3880, 5131, 4850] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [5864, 3880, 6597, 4850] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2199, 3880, 2932, 4850] * 45 ...\n",
      "reading coherence in [3665, 3880, 4398, 4850] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1466, 3880, 2199, 4850] * 45 ...\n",
      "reading coherence in [2932, 3880, 3665, 4850] * 45 ...\n",
      "reading coherence in [0, 3880, 733, 4850] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 1 / 8\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 2 / 8\n",
      "chunk 4 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 3 / 8\n",
      "chunk 5 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 6 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 7 / 8\n",
      "reading unwrapPhase in [5131, 3880, 5864, 4850] * 45 ...\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [4398, 3880, 5131, 4850] * 45 ...\n",
      "reading unwrapPhase in [5864, 3880, 6597, 4850] * 45 ...\n",
      "chunk 8 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [6597, 3880, 7327, 4850] * 45 ...\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "reading unwrapPhase in [733, 3880, 1466, 4850] * 45 ...\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [3665, 3880, 4398, 4850] * 45 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1466, 3880, 2199, 4850] * 45 ...\n",
      "chunk 7 / 8\n",
      "reading unwrapPhase in [2199, 3880, 2932, 4850] * 45 ...\n",
      "chunk 8 / 8\n",
      "chunk 7 / 8\n",
      "reading unwrapPhase in [0, 3880, 733, 4850] * 45 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [2932, 3880, 3665, 4850] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "use input reference value\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 660278 out of 711010 (92.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 589960 out of 711010 (83.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 575564 out of 711010 (81.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 602618 out of 711010 (84.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 380860 out of 708100 (53.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 711010 (0.0%)\n",
      "number of pixels to invert: 679380 out of 711010 (95.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]\n",
      "FUTURE #1 complete. Time used: 23 seconds\n",
      "[>                                                 ]number of pixels to invert: 711010 out of 711010 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 380860/380860 pixels  374s /   345s\n",
      "[======================= 62% ==>                   ] 372600/602618 pixels  375s /   229sconverting LOS phase unit from radian to meter\n",
      "[======================= 54%                       ] 383000/711010 pixels  375s /   319s\n",
      "FUTURE #2 complete. Time used: 399 seconds\n",
      "[==================================================] 575564/575564 pixels  463s /   108s\n",
      "[======================= 80% ===========>          ] 568600/711010 pixels  464s /   116sconverting LOS phase unit from radian to meter\n",
      "[======================= 86% ==============>       ] 582800/679380 pixels  464s /    75s\n",
      "FUTURE #3 complete. Time used: 488 seconds\n",
      "[==================================================] 589960/589960 pixels  471s /    96s\n",
      "[======================= 90% ================>     ] 593600/660278 pixels  471s /    52sconverting LOS phase unit from radian to meter\n",
      "[======================= 83% =============>        ] 593600/711010 pixels  471s /    96s\n",
      "FUTURE #4 complete. Time used: 495 seconds\n",
      "[==================================================] 602618/602618 pixels  477s /    77s\n",
      "[======================= 91% =================>    ] 615400/679380 pixels  478s /    47sconverting LOS phase unit from radian to meter\n",
      "[======================= 91% =================>    ] 615600/679380 pixels  478s /    47s\n",
      "FUTURE #5 complete. Time used: 502 seconds\n",
      "[==================================================] 660278/660278 pixels  495s /    10s\n",
      "[======================= 91% =================>    ] 649600/711010 pixels  495s /    49sconverting LOS phase unit from radian to meter\n",
      "[======================= 94% ==================>   ] 667000/711010 pixels  495s /    31s\n",
      "FUTURE #6 complete. Time used: 519 seconds\n",
      "[==================================================] 679380/679380 pixels  499s /    26s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 96% ===================>  ] 679800/711010 pixels  500s /    20s\n",
      "FUTURE #7 complete. Time used: 523 seconds\n",
      "[==================================================] 711010/711010 pixels  509s /    15s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 705000/711010 pixels  509s /    15s\n",
      "FUTURE #8 complete. Time used: 533 seconds\n",
      "[==================================================] 711010/711010 pixels  511s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 698600/711010 pixels  511s /    10s\n",
      "FUTURE #9 complete. Time used: 535 seconds\n",
      "[==================================================] 711010/711010 pixels  512s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #10 complete. Time used: 539 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 3880, 4850, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [3880, 4850, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [3880, 4850, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 52 mins 12.3 secs.\n",
      "\n",
      "\n",
      "------- processing patch 6 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 913\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 10 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 10 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4850, 733, 5763]\n",
      "submit a job to the worker for sub box 1: [733, 4850, 1466, 5763]\n",
      "submit a job to the worker for sub box 2: [1466, 4850, 2199, 5763]\n",
      "submit a job to the worker for sub box 3: [2199, 4850, 2932, 5763]\n",
      "submit a job to the worker for sub box 4: [2932, 4850, 3665, 5763]\n",
      "submit a job to the worker for sub box 5: [3665, 4850, 4398, 5763]\n",
      "submit a job to the worker for sub box 6: [4398, 4850, 5131, 5763]\n",
      "submit a job to the worker for sub box 7: [5131, 4850, 5864, 5763]\n",
      "submit a job to the worker for sub box 8: [5864, 4850, 6597, 5763]\n",
      "submit a job to the worker for sub box 9: [6597, 4850, 7327, 5763]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 4850, 733, 5763] * 45 ...\n",
      "reading coherence in [3665, 4850, 4398, 5763] * 45 ...\n",
      "reading coherence in [4398, 4850, 5131, 5763] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [5131, 4850, 5864, 5763] * 45 ...\n",
      "reading coherence in [6597, 4850, 7327, 5763] * 45 ...\n",
      "reading coherence in [2932, 4850, 3665, 5763] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1466, 4850, 2199, 5763] * 45 ...\n",
      "reading coherence in [733, 4850, 1466, 5763] * 45 ...\n",
      "reading coherence in [2199, 4850, 2932, 5763] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [5864, 4850, 6597, 5763] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 7\n",
      "chunk 1 / 7\n",
      "chunk 1 / 7\n",
      "chunk 1 / 7\n",
      "chunk 1 / 7\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "chunk 1 / 7\n",
      "chunk 1 / 7\n",
      "chunk 1 / 7\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 7\n",
      "chunk 2 / 7\n",
      "chunk 2 / 7\n",
      "chunk 2 / 7\n",
      "chunk 2 / 7\n",
      "chunk 2 / 7\n",
      "chunk 1 / 7\n",
      "chunk 2 / 7\n",
      "chunk 2 / 7\n",
      "chunk 2 / 7\n",
      "chunk 2 / 7\n",
      "chunk 3 / 7\n",
      "chunk 3 / 7\n",
      "chunk 3 / 7\n",
      "chunk 3 / 7\n",
      "chunk 3 / 7\n",
      "chunk 3 / 7\n",
      "chunk 2 / 7\n",
      "chunk 3 / 7\n",
      "chunk 3 / 7\n",
      "chunk 3 / 7\n",
      "chunk 4 / 7\n",
      "chunk 4 / 7\n",
      "chunk 4 / 7\n",
      "chunk 3 / 7\n",
      "chunk 4 / 7\n",
      "chunk 4 / 7\n",
      "chunk 4 / 7\n",
      "chunk 4 / 7\n",
      "chunk 4 / 7\n",
      "chunk 4 / 7\n",
      "chunk 5 / 7\n",
      "chunk 5 / 7\n",
      "chunk 5 / 7\n",
      "chunk 5 / 7\n",
      "chunk 4 / 7\n",
      "chunk 5 / 7\n",
      "chunk 5 / 7\n",
      "chunk 5 / 7\n",
      "chunk 5 / 7\n",
      "chunk 5 / 7\n",
      "chunk 6 / 7\n",
      "chunk 6 / 7\n",
      "chunk 6 / 7\n",
      "chunk 6 / 7\n",
      "chunk 6 / 7\n",
      "chunk 5 / 7\n",
      "chunk 6 / 7\n",
      "chunk 6 / 7\n",
      "chunk 6 / 7\n",
      "chunk 6 / 7\n",
      "chunk 7 / 7\n",
      "chunk 7 / 7\n",
      "reading unwrapPhase in [4398, 4850, 5131, 5763] * 45 ...\n",
      "chunk 7 / 7\n",
      "chunk 7 / 7\n",
      "chunk 7 / 7\n",
      "reading unwrapPhase in [3665, 4850, 4398, 5763] * 45 ...\n",
      "reading unwrapPhase in [6597, 4850, 7327, 5763] * 45 ...\n",
      "reading unwrapPhase in [5131, 4850, 5864, 5763] * 45 ...\n",
      "chunk 7 / 7\n",
      "chunk 7 / 7\n",
      "reading unwrapPhase in [0, 4850, 733, 5763] * 45 ...\n",
      "reading unwrapPhase in [2199, 4850, 2932, 5763] * 45 ...\n",
      "reading unwrapPhase in [733, 4850, 1466, 5763] * 45 ...\n",
      "chunk 7 / 7\n",
      "chunk 6 / 7\n",
      "chunk 7 / 7\n",
      "reading unwrapPhase in [5864, 4850, 6597, 5763] * 45 ...\n",
      "reading unwrapPhase in [1466, 4850, 2199, 5763] * 45 ...\n",
      "chunk 7 / 7\n",
      "reading unwrapPhase in [2932, 4850, 3665, 5763] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "use input reference value\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 319872 out of 669229 (47.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 669229 (0.0%)\n",
      "number of pixels to invert: 0 out of 669229 (0.0%)\n",
      "number of pixels to invert: 0 out of 666490 (0.0%)\n",
      "number of pixels to invert: 0 out of 669229 (0.0%)\n",
      "number of pixels to invert: 2874 out of 669229 (0.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1600 out of 669229 (0.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 411652 out of 669229 (61.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 305174 out of 669229 (45.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 106823 out of 669229 (16.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ] 200/1600 pixels    0s /     1s\n",
      "FUTURE #1 complete. Time used: 19 seconds\n",
      "[>                                                 ]\n",
      "FUTURE #2 complete. Time used: 19 seconds\n",
      "\n",
      "FUTURE #3 complete. Time used: 19 seconds\n",
      "[======>                 14%                       ] 400/2874 pixels    0s /     2s\n",
      "FUTURE #4 complete. Time used: 19 seconds\n",
      "[==================================================] 1600/1600 pixels    1s /     1s\n",
      "converting LOS phase unit from radian to meter\n",
      "[>                                                 ]\n",
      "FUTURE #5 complete. Time used: 20 seconds\n",
      "[==================================================] 2874/2874 pixels s    2s /   124s\n",
      "converting LOS phase unit from radian to meter\n",
      "[>                                                 ]\n",
      "FUTURE #6 complete. Time used: 22 seconds\n",
      "[==================================================] 106823/106823 pixels   48s /   136s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=================>      36%                       ] 108600/305174 pixels   47s /    85s\n",
      "FUTURE #7 complete. Time used: 67 seconds\n",
      "[==================================================] 305174/305174 pixels   98s /    34s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 74% ========>             ] 306400/411652 pixels   98s /    34s\n",
      "FUTURE #8 complete. Time used: 117 seconds\n",
      "[==================================================] 319872/319872 pixels  102s /    27s\n",
      "[======================= 79% ===========>          ] 323600/411652 pixels  102s /    27sconverting LOS phase unit from radian to meter\n",
      "[======================= 79% ===========>          ] 323800/411652 pixels  102s /    27s\n",
      "FUTURE #9 complete. Time used: 121 seconds\n",
      "[==================================================] 411652/411652 pixels  120s /     2s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #10 complete. Time used: 140 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4850, 5763, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4850, 5763, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4850, 5763, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 54 mins 39.0 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (3677, 6281)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 45\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 54 mins 39.0 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/maskTempCoh.h5\n",
      "time used: 00 mins 1.9 secs.\n",
      "number of reliable pixels: 22946231\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  73s /     8s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 20.7 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7327\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 10 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 10 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 733, 1441]\n",
      "submit a job to the worker for sub box 1: [733, 0, 1466, 1441]\n",
      "submit a job to the worker for sub box 2: [1466, 0, 2199, 1441]\n",
      "submit a job to the worker for sub box 3: [2199, 0, 2932, 1441]\n",
      "submit a job to the worker for sub box 4: [2932, 0, 3665, 1441]\n",
      "submit a job to the worker for sub box 5: [3665, 0, 4398, 1441]\n",
      "submit a job to the worker for sub box 6: [4398, 0, 5131, 1441]\n",
      "submit a job to the worker for sub box 7: [5131, 0, 5864, 1441]\n",
      "submit a job to the worker for sub box 8: [5864, 0, 6597, 1441]\n",
      "submit a job to the worker for sub box 9: [6597, 0, 7327, 1441]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 700129 out of 1056253 (66.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 161905 out of 1056253 (15.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 266188 out of 1056253 (25.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 594740 out of 1056253 (56.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 48474 out of 1056253 (4.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 682718 out of 1056253 (64.6%)\n",
      "number of pixels to invert: 671905 out of 1056253 (63.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 708 out of 1051930 (0.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 472020 out of 1056253 (44.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 595844 out of 1056253 (56.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 708/708 \n",
      "\n",
      "FUTURE #1 complete. Time used: 5 seconds\n",
      "[==================================================] 48474/48474    12s /   108s\n",
      "[===============>        31%                       ] 50000/161905   12s /    27s\n",
      "FUTURE #2 complete. Time used: 17 seconds\n",
      "[==================================================] 161905/161905   39s /    75s\n",
      "[===========>            23%                       ] 160000/682718   39s /   130s\n",
      "FUTURE #3 complete. Time used: 44 seconds\n",
      "[==================================================] 266188/266188   64s /    50s\n",
      "[=====================>  44%                       ] 262000/595844   64s /    82s\n",
      "FUTURE #4 complete. Time used: 70 seconds\n",
      "[==================================================] 472020/472020  135s /    38s\n",
      "[======================= 67% =====>                ] 468000/700129  135s /    66s\n",
      "FUTURE #5 complete. Time used: 140 seconds\n",
      "[==================================================] 595844/595844  159s /    28s\n",
      "[==================================================] 592000/594740  159s /    21s\n",
      "FUTURE #6 complete. Time used: 164 seconds\n",
      "[==================================================] 594740/594740  160s /    21s\n",
      "[======================= 90% ================>     ] 604000/671905  160s /    17s\n",
      "FUTURE #7 complete. Time used: 165 seconds\n",
      "[==================================================] 671905/671905  169s /     3s\n",
      "[======================= 96% ===================>  ] 670000/700129  169s /     7s\n",
      "FUTURE #8 complete. Time used: 174 seconds\n",
      "[==================================================] 682718/682718  171s /     3s\n",
      "\n",
      "FUTURE #9 complete. Time used: 176 seconds\n",
      "[==================================================] 700129/700129  171s /     3s\n",
      "\n",
      "FUTURE #10 complete. Time used: 178 seconds\n",
      "close dask client\n",
      "2023-07-06 18:55:55,369 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/worker.py\", line 1237, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/utils_comm.py\", line 413, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/core.py\", line 1365, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/core.py\", line 1124, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 241, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56602 remote=tcp://127.0.0.1:38901>: Stream is closed\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1441, 0, 7327]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1441, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1441, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7327\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 10 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 10 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1441, 733, 2882]\n",
      "submit a job to the worker for sub box 1: [733, 1441, 1466, 2882]\n",
      "submit a job to the worker for sub box 2: [1466, 1441, 2199, 2882]\n",
      "submit a job to the worker for sub box 3: [2199, 1441, 2932, 2882]\n",
      "submit a job to the worker for sub box 4: [2932, 1441, 3665, 2882]\n",
      "submit a job to the worker for sub box 5: [3665, 1441, 4398, 2882]\n",
      "submit a job to the worker for sub box 6: [4398, 1441, 5131, 2882]\n",
      "submit a job to the worker for sub box 7: [5131, 1441, 5864, 2882]\n",
      "submit a job to the worker for sub box 8: [5864, 1441, 6597, 2882]\n",
      "submit a job to the worker for sub box 9: [6597, 1441, 7327, 2882]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 507163 out of 1056253 (48.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1056253 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 996270 out of 1056253 (94.3%)\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1056253 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1056253 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1056253 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1056253 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1056253 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 227826 out of 1051930 (21.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1056253 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 227826/227826   67s /   226ss\n",
      "[==========>             22%                       ] 228000/1056253   68s /   241s\n",
      "FUTURE #1 complete. Time used: 73 seconds\n",
      "[==================================================] 507163/507163   162s /   176s\n",
      "[======================= 47%                       ] 498000/1056253  162s /   183s\n",
      "FUTURE #2 complete. Time used: 168 seconds\n",
      "[==================================================] 996270/996270   326s /    20ss\n",
      "[======================= 93% =================>    ] 984000/1056253  326s /    24s\n",
      "FUTURE #3 complete. Time used: 331 seconds\n",
      "[==================================================] 1056253/1056253  337s /     6s\n",
      "[==================================================] 1050000/1056253  337s /     6s\n",
      "FUTURE #4 complete. Time used: 343 seconds\n",
      "[==================================================] 1056253/1056253  337s /     6s\n",
      "[==================================================] 1056253/1056253  338s /     6s\n",
      "\n",
      "FUTURE #5 complete. Time used: 344 seconds\n",
      "[==================================================] 1056253/1056253 \n",
      "[======================= 98% ====================> ] 1040000/1056253  339s /     6s\n",
      "FUTURE #6 complete. Time used: 344 seconds\n",
      "[==================================================] 1050000/1056253\n",
      "FUTURE #7 complete. Time used: 344 seconds\n",
      "[==================================================] 1056253/1056253 \n",
      "[==================================================] 1048000/1056253\n",
      "FUTURE #8 complete. Time used: 345 seconds\n",
      "[==================================================] 1056253/1056253 \n",
      "[==================================================] 1052000/1056253\n",
      "FUTURE #9 complete. Time used: 346 seconds\n",
      "[==================================================] 1056253/1056253 \n",
      "\n",
      "FUTURE #10 complete. Time used: 346 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1441, 2882, 0, 7327]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1441, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1441, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7327\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 10 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 10 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2882, 733, 4323]\n",
      "submit a job to the worker for sub box 1: [733, 2882, 1466, 4323]\n",
      "submit a job to the worker for sub box 2: [1466, 2882, 2199, 4323]\n",
      "submit a job to the worker for sub box 3: [2199, 2882, 2932, 4323]\n",
      "submit a job to the worker for sub box 4: [2932, 2882, 3665, 4323]\n",
      "submit a job to the worker for sub box 5: [3665, 2882, 4398, 4323]\n",
      "submit a job to the worker for sub box 6: [4398, 2882, 5131, 4323]\n",
      "submit a job to the worker for sub box 7: [5131, 2882, 5864, 4323]\n",
      "submit a job to the worker for sub box 8: [5864, 2882, 6597, 4323]\n",
      "submit a job to the worker for sub box 9: [6597, 2882, 7327, 4323]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1023899 out of 1056253 (96.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1056253 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 102647 out of 1056253 (9.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 641417 out of 1051930 (61.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1056252 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1056253 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1056253 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1056253 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1056253 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1056252 out of 1056253 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 102647/102647   35s /   362ss\n",
      "[===>                     9%                       ] 96000/1056252   35s /   363ss\n",
      "FUTURE #1 complete. Time used: 41 seconds\n",
      "[==================================================] 641417/641417   228s /   134s\n",
      "[======================= 59% =>                    ] 628000/1056253  228s /   159s\n",
      "FUTURE #2 complete. Time used: 234 seconds\n",
      "[==================================================] 1023899/1023899  359s /    14s\n",
      "[======================= 96% ===================>  ] 1018000/1056252  359s /    14s\n",
      "FUTURE #3 complete. Time used: 365 seconds\n",
      "[==================================================] 1056252/1056252  367s /     7s\n",
      "[==================================================] 1048000/1056253\n",
      "FUTURE #4 complete. Time used: 373 seconds\n",
      "[==================================================] 1056253/1056253  369s /     7s\n",
      "[==================================================] 1056253/1056253 \n",
      "\n",
      "FUTURE #5 complete. Time used: 375 seconds\n",
      "[==================================================] 1052000/1056253\n",
      "FUTURE #6 complete. Time used: 376 seconds\n",
      "[==================================================] 1056253/1056253 \n",
      "\n",
      "FUTURE #7 complete. Time used: 377 seconds\n",
      "[==================================================] 1056252/1056252 \n",
      "\n",
      "FUTURE #8 complete. Time used: 377 seconds\n",
      "[==================================================] 1056253/1056253 \n",
      "\n",
      "FUTURE #9 complete. Time used: 378 seconds\n",
      "[==================================================] 1056253/1056253 \n",
      "\n",
      "FUTURE #10 complete. Time used: 378 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2882, 4323, 0, 7327]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2882, 4323, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2882, 4323, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7327\n",
      "box length: 1440\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 10 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 10 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4323, 733, 5763]\n",
      "submit a job to the worker for sub box 1: [733, 4323, 1466, 5763]\n",
      "submit a job to the worker for sub box 2: [1466, 4323, 2199, 5763]\n",
      "submit a job to the worker for sub box 3: [2199, 4323, 2932, 5763]\n",
      "submit a job to the worker for sub box 4: [2932, 4323, 3665, 5763]\n",
      "submit a job to the worker for sub box 5: [3665, 4323, 4398, 5763]\n",
      "submit a job to the worker for sub box 6: [4398, 4323, 5131, 5763]\n",
      "submit a job to the worker for sub box 7: [5131, 4323, 5864, 5763]\n",
      "submit a job to the worker for sub box 8: [5864, 4323, 6597, 5763]\n",
      "submit a job to the worker for sub box 9: [6597, 4323, 7327, 5763]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 0 out of 1055520 (0.0%)\n",
      "number of pixels to invert: 628992 out of 1055520 (59.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 797943 out of 1055520 (75.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 250845 out of 1055520 (23.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 357535 out of 1055520 (33.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 265241 out of 1055520 (25.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 337159 out of 1055520 (31.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 138723 out of 1051200 (13.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 493114 out of 1055520 (46.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 691465 out of 1055520 (65.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "\n",
      "FUTURE #1 complete. Time used: 5 seconds\n",
      "[==================================================] 138723/138723   43s /    65s\n",
      "[=======>                17%                       ] 138000/797943   43s /   213s\n",
      "FUTURE #2 complete. Time used: 49 seconds\n",
      "[==================================================] 250845/250845   82s /   184s\n",
      "[======================= 74% ========>             ] 248000/337159   82s /    29s\n",
      "FUTURE #3 complete. Time used: 88 seconds\n",
      "[==================================================] 265241/265241   88s /    23s\n",
      "\n",
      "FUTURE #4 complete. Time used: 93 seconds\n",
      "[==================================================] 337159/337159  105s /    47s\n",
      "[======================= 50%                       ] 346000/691465  105s /   105s\n",
      "FUTURE #5 complete. Time used: 111 seconds\n",
      "[==================================================] 357535/357535  109s /    42s\n",
      "[=====================>  45%                       ] 358000/797943  109s /   134s\n",
      "FUTURE #6 complete. Time used: 115 seconds\n",
      "[==================================================] 493114/493114  133s /    49s\n",
      "[======================= 78% ==========>           ] 492000/628992  133s /    37s\n",
      "FUTURE #7 complete. Time used: 139 seconds\n",
      "[==================================================] 628992/628992  154s /     9s\n",
      "\n",
      "FUTURE #8 complete. Time used: 160 seconds\n",
      "[==================================================] 691465/691465  160s /    30s\n",
      "\n",
      "FUTURE #9 complete. Time used: 165 seconds\n",
      "[==================================================] 797943/797943  173s /     3s\n",
      "\n",
      "FUTURE #10 complete. Time used: 180 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4323, 5763, 0, 7327]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4323, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4323, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 18 mins 31.8 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  81s /     9s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 30.4 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 10/10  46s /     5s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20170812 - 0.0003\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0009)\n",
      "None.\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20170812\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5763, 0, 7327)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20170812\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5763, 0, 7327)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20170812\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5763, 0, 7327)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20170812\n",
      "time used: 00 mins 47.7 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: []\n",
      "--------------------------------------------------\n",
      "dates from input file: 10\n",
      "['20170613', '20170625', '20170707', '20170731', '20170812', '20170824', '20170905', '20170917', '20170929', '20171011']\n",
      "--------------------------------------------------\n",
      "using all dates to calculate the time function\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5\n",
      "split along y dimension (5763) into 2 boxes\n",
      "    with each box up to 2882 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 2 --------------\n",
      "box width:  7327\n",
      "box length: 2882\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13319661 out of 21116414 (63.1%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 2 --------------\n",
      "box width:  7327\n",
      "box length: 2881\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13122750 out of 21109087 (62.2%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5.\n",
      "time used: 00 mins 23.0 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7327, 5763)\n",
      "subset coverage in y/x: (0, 0, 7327, 5763)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7327/5763\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.26, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 02 mins 59.2 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 99 mins 28.0 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "working on AT137, 2018\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase_CNN_signal.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n"
     ]
    }
   ],
   "source": [
    "mintpy_multiyear(orbit_list, year_list, clip=True, mintpy=True, clean_clip=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mintpy]",
   "language": "python",
   "name": "conda-env-mintpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
