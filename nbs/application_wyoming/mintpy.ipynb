{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f7bb06e-6e63-4d64-b7d6-8ccb6c97757b",
   "metadata": {},
   "source": [
    "# MintPy for signal maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c766f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import mintpy\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ed07a6-5cd1-428e-8e7b-aa8eebec1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_list = ['AT137']\n",
    "year_list = ['2017', '2018', '2019', '2020', '2021']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910045f-42cf-4bf6-8c42-abda85c05b03",
   "metadata": {},
   "source": [
    "## clip files to common extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ec0ec07-2bfd-4a78-b90a-df7ea38c24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_overlap(file_list: List[Union[str, Path]]) -> List[float]:\n",
    "    \"\"\"Get the common overlap of  a list of GeoTIFF files\n",
    "    \n",
    "    Arg:\n",
    "        file_list: a list of GeoTIFF files\n",
    "    \n",
    "    Returns:\n",
    "         [ulx, uly, lrx, lry], the upper-left x, upper-left y, lower-right x, and lower-right y\n",
    "         corner coordinates of the common overlap\n",
    "    \"\"\"\n",
    "    \n",
    "    corners = [gdal.Info(str(dem), format='json')['cornerCoordinates'] for dem in file_list]\n",
    "\n",
    "    ulx = max(corner['upperLeft'][0] for corner in corners)\n",
    "    uly = min(corner['upperLeft'][1] for corner in corners)\n",
    "    lrx = min(corner['lowerRight'][0] for corner in corners)\n",
    "    lry = max(corner['lowerRight'][1] for corner in corners)\n",
    "    return [ulx, uly, lrx, lry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8aeb241-e1b8-404d-b156-11177471a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_hyp3_products_to_common_overlap(data_path: Union[str, Path], overlap: List[float]) -> None:\n",
    "    \"\"\"Clip all GeoTIFF files to their common overlap\n",
    "    \n",
    "    Args:\n",
    "        data_dir:\n",
    "            directory containing the GeoTIFF files to clip\n",
    "        overlap:\n",
    "            a list of the upper-left x, upper-left y, lower-right-x, and lower-tight y\n",
    "            corner coordinates of the common overlap\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    \n",
    "    files_for_mintpy = ['_water_mask.tif', '_corr.tif', '_unw_phase_CNN_signal.tif', '_dem.tif', '_lv_theta.tif', '_lv_phi.tif']\n",
    "\n",
    "    for extension in files_for_mintpy:\n",
    "        print(f'working on {extension}') \n",
    "        for file in data_path.rglob(f'*{extension}'):\n",
    "\n",
    "            dst_file = file.parent / f'{file.stem}_clipped{file.suffix}'\n",
    "\n",
    "            gdal.Translate(destName=str(dst_file), srcDS=str(file), projWin=overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dc256-88c0-4ac9-88aa-4ee420ca1e1d",
   "metadata": {},
   "source": [
    "## Mintpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033276cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write to MintPy config file\n",
    "def write_config_file(out_file, CONFIG_TXT, mode='a'): \n",
    "    \"\"\"Write configuration files for MintPy to process products\"\"\"\n",
    "    if not os.path.isfile(out_file) or mode == 'w':\n",
    "        with open(out_file, \"w\") as fid:\n",
    "            fid.write(CONFIG_TXT)\n",
    "        print('write configuration to file: {}'.format(out_file))\n",
    "    else:\n",
    "        with open(out_file, \"a\") as fid:\n",
    "            fid.write(\"\\n\" + CONFIG_TXT)\n",
    "        print('add the following to file: \\n{}'.format(CONFIG_TXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42499563-1225-4427-8863-4ef390300f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clip files and run mintpy for multiple years \n",
    "def mintpy_multiyear(orbit_list, year_list, clip=True, mintpy=True, clean_clip=True):\n",
    "    # hardcoded paths for now \n",
    "    home_path_d = '/mnt/d/indennt'\n",
    "    home_path = '/mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data'\n",
    "    for orbit in orbit_list:\n",
    "        for year in year_list:\n",
    "            print(f'working on {orbit}, {year}')\n",
    "            data_path = f'{home_path_d}/hyp3_app/{orbit}/{year}'\n",
    "            mintpy_path = f'{home_path}/signal_mintpy/{orbit}/mintpy_{year}'\n",
    "            mintpy_path_d = f'{home_path_d}/mintpy_app/{orbit}/'\n",
    "\n",
    "            if clip==True:\n",
    "                # identify and crop to common overlap\n",
    "                print('identifying common overlap')\n",
    "                dem_files = Path(data_path).glob('*/*_dem.tif')\n",
    "                overlap = get_common_overlap(dem_files)\n",
    "                print('clipping to common overlap')\n",
    "                clip_hyp3_products_to_common_overlap(Path(data_path), overlap)\n",
    "\n",
    "            # make output dir for mintpy\n",
    "            if not os.path.exists(mintpy_path):\n",
    "                os.mkdir(mintpy_path)\n",
    "\n",
    "            # write config file for mintpy\n",
    "            CONFIG_TXT = f'''# vim: set filetype=cfg:\n",
    "            ##----------------------------- hyp3 ---------------------##\n",
    "            mintpy.load.processor        = hyp3\n",
    "            ##---------interferogram datasets:\n",
    "            mintpy.load.unwFile          = {data_path}/*/*{year}*unw_phase_CNN_signal_clipped.tif\n",
    "            mintpy.load.corFile          = {data_path}/*/*{year}*corr_clipped.tif\n",
    "            ##---------geometry datasets:\n",
    "            mintpy.load.demFile          = {data_path}/*/*{year}*dem_clipped.tif\n",
    "            mintpy.load.incAngleFile     = {data_path}/*/*{year}*lv_theta_clipped.tif\n",
    "            mintpy.load.waterMaskFile    = {data_path}/*/*{year}*water_mask_clipped.tif\n",
    "\n",
    "            mintpy.deramp                = linear\n",
    "            mintpy.reference.lalo        = auto\n",
    "            mintpy.troposphericDelay.method  = no\n",
    "\n",
    "            mintpy.compute.cluster    = local\n",
    "            mintpy.compute.numWorker  = 6\n",
    "            '''\n",
    "\n",
    "            os.chdir(mintpy_path)\n",
    "            config_file = f'{mintpy_path}/{year}_Sen{orbit}.txt'\n",
    "            write_config_file(config_file, CONFIG_TXT, mode='w')\n",
    "\n",
    "            if mintpy==True:\n",
    "                # run mintpy\n",
    "                print('starting mintpy')\n",
    "                !smallbaselineApp.py --dir {mintpy_path} {config_file}\n",
    "                print('moving outputs to drive')\n",
    "                !cp -r $mintpy_path $mintpy_path_d && rm -R $mintpy_path\n",
    "\n",
    "            if clean_clip==True:\n",
    "                # remove clipped files\n",
    "                print('removing clipped files')\n",
    "                clipped_files = f'{data_path}/*/*_clipped.tif'\n",
    "                !rm {clipped_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf39b43-8dac-40e1-b054-406c9e8706a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on AT137, 2021\n",
      "identifying common overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase_CNN_signal.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/2021_SenAT137.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-07-07 10:29:16.326406--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: 2021_SenAT137\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/2021_SenAT137.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.numWorker: 10 --> 6\n",
      "copy 2021_SenAT137.txt    to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg to inputs   directory for backup.\n",
      "copy 2021_SenAT137.txt    to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/2021_SenAT137.txt --project 2021_SenAT137\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*unw_phase_CNN_signal_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3_app/AT137/2021/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3_app/AT137/2021/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3_app/AT137/2021/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7_water_mask_clipped.tif\n",
      "All datasets exists in file geometryGeo.h5 with same size as required, no need to re-load.\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*unw_phase_CNN_signal_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*corr_clipped.tif\n",
      "number of unwrapPhase     : 55\n",
      "number of coherence       : 55\n",
      "All date12   exists in file ifgramStack.h5 with same size as required, no need to re-load.\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 00 mins 54.9 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file 2021_SenAT137.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file 2021_SenAT137.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/geometryGeo.h5 for conveniency\n",
      "delete exsited file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/waterMask.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 55/55   84s /     1s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 11\n",
      "number of interferograms: 55\n",
      "shift all perp baseline by 106.92715454101562 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 55\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 210.00 m\n",
      "max temporal      baseline: 132.0 days\n",
      "showing coherence\n",
      "data range: [0.44810608, 0.909137]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 55/55   73s /     1s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/maskConnComp.h5\n",
      "time used: 01 mins 17.3 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   69s /     9s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/avgSpatialCoh.h5\n",
      "time used: 01 mins 22.0 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   82s /    11s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (1591, 3088)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5\n",
      "{'REF_Y': '1591', 'REF_X': '3088', 'REF_LAT': '4823940.0', 'REF_LON': '622500.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   89s /    12s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/avgPhaseVelocity.h5\n",
      "time used: 01 mins 45.4 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 55\n",
      "number of triplets: 165\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (190, 7331), 31 blocks in total\n",
      "reference pixel in y/x: (1591, 3088) from dataset: unwrapPhase\n",
      "[==================================================] line 5700 / 5765  296s /     9s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/numTriNonzeroIntAmbiguity.png\n",
      "time used: 05 mins 11.7 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (1591, 3088) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 55\n",
      "number of acquisitions  : 11\n",
      "number of lines   : 5765\n",
      "number of columns : 7331\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5765 lines into 8 patches for processing\n",
      "    with each patch up to 730 lines\n",
      "\n",
      "------- processing patch 1 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 730]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 730]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 730]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 730]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 730]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 730]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 0, 3666, 730] * 55 ...\n",
      "reading coherence in [1222, 0, 2444, 730] * 55 ...\n",
      "reading coherence in [4888, 0, 6110, 730] * 55 ...\n",
      "reading coherence in [6110, 0, 7331, 730] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 0, 4888, 730] * 55 ...\n",
      "reading coherence in [0, 0, 1222, 730] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [4888, 0, 6110, 730] * 55 ...\n",
      "reading unwrapPhase in [6110, 0, 7331, 730] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [0, 0, 1222, 730] * 55 ...\n",
      "reading unwrapPhase in [2444, 0, 3666, 730] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [1222, 0, 2444, 730] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [3666, 0, 4888, 730] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "use input reference value\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 267376 out of 892060 (30.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 892060 (0.0%)\n",
      "number of pixels to invert: 116192 out of 891330 (13.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 892060 (0.0%)\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 75612 out of 892060 (8.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]\n",
      "FUTURE #1 complete. Time used: 19 seconds\n",
      "[>                                                 ]\n",
      "FUTURE #2 complete. Time used: 19 seconds\n",
      "number of pixels to invert: 220161 out of 892060 (24.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 75612/75612 pixels    45s /    24s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 65% ===>                  ] 75600/116192 pixels   46s /    24s\n",
      "FUTURE #3 complete. Time used: 65 seconds\n",
      "[==================================================] 116192/116192 pixels   66s /    61s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 53%                       ] 115600/220161 pixels   66s /    59s\n",
      "FUTURE #4 complete. Time used: 86 seconds\n",
      "[==================================================] 220161/220161 pixels  110s /    24s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 82% ============>         ] 219000/267376 pixels  110s /    24s\n",
      "FUTURE #5 complete. Time used: 129 seconds\n",
      "[==================================================] 267376/267376 pixels  127s /     2s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 147 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 730, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 730, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 730, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 02 mins 34.5 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 730, 1222, 1460]\n",
      "submit a job to the worker for sub box 1: [1222, 730, 2444, 1460]\n",
      "submit a job to the worker for sub box 2: [2444, 730, 3666, 1460]\n",
      "submit a job to the worker for sub box 3: [3666, 730, 4888, 1460]\n",
      "submit a job to the worker for sub box 4: [4888, 730, 6110, 1460]\n",
      "submit a job to the worker for sub box 5: [6110, 730, 7331, 1460]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 730, 3666, 1460] * 55 ...\n",
      "reading coherence in [0, 730, 1222, 1460] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 730, 4888, 1460] * 55 ...\n",
      "reading coherence in [6110, 730, 7331, 1460] * 55 ...\n",
      "reading coherence in [4888, 730, 6110, 1460] * 55 ...\n",
      "reading coherence in [1222, 730, 2444, 1460] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [1222, 730, 2444, 1460] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [6110, 730, 7331, 1460] * 55 ...\n",
      "reading unwrapPhase in [3666, 730, 4888, 1460] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [2444, 730, 3666, 1460] * 55 ...\n",
      "reading unwrapPhase in [4888, 730, 6110, 1460] * 55 ...\n",
      "reading unwrapPhase in [0, 730, 1222, 1460] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 313794 out of 891330 (35.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 161100 out of 892060 (18.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 485123 out of 892060 (54.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 880908 out of 892060 (98.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 161100/161100 pixels  173s /   160s\n",
      "[========>               18%                       ] 160400/892060 pixels  173s /   792sconverting LOS phase unit from radian to meter\n",
      "[======================= 52%                       ] 164600/313794 pixels  174s /   160s\n",
      "FUTURE #1 complete. Time used: 193 seconds\n",
      "[==================================================] 313794/313794 pixels  302s /   538s\n",
      "converting LOS phase unit from radian to meter\n",
      "[================>       34%                       ] 306400/892060 pixels  303s /   588s\n",
      "FUTURE #2 complete. Time used: 322 seconds\n",
      "[==================================================] 485123/485123 pixels  416s /   327s\n",
      "[======================= 54%                       ] 485800/892060 pixels  416s /   354sconverting LOS phase unit from radian to meter\n",
      "[======================= 54%                       ] 486000/892060 pixels  416s /   355s\n",
      "FUTURE #3 complete. Time used: 436 seconds\n",
      "[==================================================] 880908/880908 pixels  619s /    12s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 870600/892060 pixels  620s /    12s\n",
      "FUTURE #4 complete. Time used: 639 seconds\n",
      "[==================================================] 892060/892060 pixels  626s /    12s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 885000/892060 pixels\n",
      "FUTURE #5 complete. Time used: 648 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 650 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 730, 1460, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [730, 1460, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [730, 1460, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 13 mins 30.5 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1460, 1222, 2190]\n",
      "submit a job to the worker for sub box 1: [1222, 1460, 2444, 2190]\n",
      "submit a job to the worker for sub box 2: [2444, 1460, 3666, 2190]\n",
      "submit a job to the worker for sub box 3: [3666, 1460, 4888, 2190]\n",
      "submit a job to the worker for sub box 4: [4888, 1460, 6110, 2190]\n",
      "submit a job to the worker for sub box 5: [6110, 1460, 7331, 2190]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 1460, 2444, 2190] * 55 ...\n",
      "reading coherence in [0, 1460, 1222, 2190] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 1460, 7331, 2190] * 55 ...\n",
      "reading coherence in [3666, 1460, 4888, 2190] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 1460, 6110, 2190] * 55 ...\n",
      "reading coherence in [2444, 1460, 3666, 2190] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "chunk 8 / 9\n",
      "reading unwrapPhase in [2444, 1460, 3666, 2190] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [0, 1460, 1222, 2190] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [6110, 1460, 7331, 2190] * 55 ...\n",
      "reading unwrapPhase in [4888, 1460, 6110, 2190] * 55 ...\n",
      "reading unwrapPhase in [1222, 1460, 2444, 2190] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [3666, 1460, 4888, 2190] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 892059 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 659422 out of 892060 (73.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 424488 out of 891330 (47.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 853863 out of 892060 (95.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 424488/424488 pixels  422s /   439s\n",
      "[======================= 49%                       ] 433000/892060 pixels  422s /   439sconverting LOS phase unit from radian to meter\n",
      "[======================= 65% ===>                  ] 428800/659422 pixels  422s /   227s\n",
      "FUTURE #1 complete. Time used: 441 seconds\n",
      "[==================================================] 659422/659422 pixels  628s /   209s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 75% =========>            ] 667600/892060 pixels  629s /   209s\n",
      "FUTURE #2 complete. Time used: 648 seconds\n",
      "[==================================================] 853863/853863 pixels  782s /    24s\n",
      "[======================= 97% ===================>  ] 861000/892059 pixels  782s /    24sconverting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 863600/892060 pixels  782s /    24s\n",
      "FUTURE #3 complete. Time used: 801 seconds\n",
      "[==================================================] 892060/892060 pixels  787s /    24s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 868200/892059 pixels  787s /    24s\n",
      "FUTURE #4 complete. Time used: 806 seconds\n",
      "[==================================================] 892060/892060 pixels  792s /    16s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 888400/892059 pixels\n",
      "FUTURE #5 complete. Time used: 816 seconds\n",
      "[==================================================] 892059/892059 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 817 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 1460, 2190, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [1460, 2190, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [1460, 2190, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 27 mins 13.3 secs.\n",
      "\n",
      "\n",
      "------- processing patch 4 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2190, 1222, 2920]\n",
      "submit a job to the worker for sub box 1: [1222, 2190, 2444, 2920]\n",
      "submit a job to the worker for sub box 2: [2444, 2190, 3666, 2920]\n",
      "submit a job to the worker for sub box 3: [3666, 2190, 4888, 2920]\n",
      "submit a job to the worker for sub box 4: [4888, 2190, 6110, 2920]\n",
      "submit a job to the worker for sub box 5: [6110, 2190, 7331, 2920]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 2190, 2444, 2920] * 55 ...\n",
      "reading coherence in [2444, 2190, 3666, 2920] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 2190, 1222, 2920] * 55 ...\n",
      "reading coherence in [4888, 2190, 6110, 2920] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 2190, 7331, 2920] * 55 ...\n",
      "reading coherence in [3666, 2190, 4888, 2920] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [1222, 2190, 2444, 2920] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [0, 2190, 1222, 2920] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [3666, 2190, 4888, 2920] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [2444, 2190, 3666, 2920] * 55 ...\n",
      "reading unwrapPhase in [4888, 2190, 6110, 2920] * 55 ...\n",
      "reading unwrapPhase in [6110, 2190, 7331, 2920] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 555530 out of 892060 (62.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 870274 out of 892060 (97.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 526293 out of 891330 (59.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 526293/526293 pixels  483s /   322s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 95% ===================>  ] 528600/555530 pixels  483s /    25s\n",
      "FUTURE #1 complete. Time used: 501 seconds\n",
      "[==================================================] 555530/555530 pixels  503s /   295s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 65% ===>                  ] 567800/870274 pixels  503s /   271s\n",
      "FUTURE #2 complete. Time used: 521 seconds\n",
      "[==================================================] 870274/870274 pixels  712s /    29s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 96% ===================>  ] 860000/892060 pixels  712s /    29s\n",
      "FUTURE #3 complete. Time used: 730 seconds\n",
      "[==================================================] 892060/892060 pixels  732s /    14s\n",
      "[======================= 98% ====================> ] 875000/892060 pixels  732s /    14sconverting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 875200/892060 pixels  732s /    14s\n",
      "FUTURE #4 complete. Time used: 750 seconds\n",
      "[==================================================] 892060/892060 pixels  734s /    14s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 880800/892060 pixels\n",
      "FUTURE #5 complete. Time used: 753 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 759 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2190, 2920, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [2190, 2920, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [2190, 2920, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 39 mins 58.7 secs.\n",
      "\n",
      "\n",
      "------- processing patch 5 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2920, 1222, 3650]\n",
      "submit a job to the worker for sub box 1: [1222, 2920, 2444, 3650]\n",
      "submit a job to the worker for sub box 2: [2444, 2920, 3666, 3650]\n",
      "submit a job to the worker for sub box 3: [3666, 2920, 4888, 3650]\n",
      "submit a job to the worker for sub box 4: [4888, 2920, 6110, 3650]\n",
      "submit a job to the worker for sub box 5: [6110, 2920, 7331, 3650]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 2920, 1222, 3650] * 55 ...\n",
      "reading coherence in [6110, 2920, 7331, 3650] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 2920, 4888, 3650] * 55 ...\n",
      "reading coherence in [1222, 2920, 2444, 3650] * 55 ...\n",
      "reading coherence in [4888, 2920, 6110, 3650] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 2920, 3666, 3650] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "chunk 1 / 9\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [2444, 2920, 3666, 3650] * 55 ...\n",
      "reading unwrapPhase in [1222, 2920, 2444, 3650] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [0, 2920, 1222, 3650] * 55 ...\n",
      "reading unwrapPhase in [6110, 2920, 7331, 3650] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [3666, 2920, 4888, 3650] * 55 ...\n",
      "reading unwrapPhase in [4888, 2920, 6110, 3650] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 444904 out of 892060 (49.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 633133 out of 891330 (71.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 444904/444904 pixels  490s /   490s\n",
      "[======================= 51%                       ] 456200/892060 pixels  490s /   471sconverting LOS phase unit from radian to meter\n",
      "[======================= 50%                       ] 447000/892060 pixels  490s /   490s\n",
      "FUTURE #1 complete. Time used: 511 seconds\n",
      "[==================================================] 633133/633133 pixels  647s /   251s\n",
      "[======================= 70% ======>               ] 628800/892060 pixels  647s /   277sconverting LOS phase unit from radian to meter\n",
      "[======================= 72% =======>              ] 641000/892060 pixels  647s /   251s\n",
      "FUTURE #2 complete. Time used: 667 seconds\n",
      "[==================================================] 892060/892060 pixels  843s /    17s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 875600/892060 pixels  843s /    17s\n",
      "FUTURE #3 complete. Time used: 864 seconds\n",
      "[==================================================] 892060/892060 pixels  845s /    17s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 886400/892060 pixels\n",
      "FUTURE #4 complete. Time used: 868 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 888800/892060 pixels\n",
      "FUTURE #5 complete. Time used: 873 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 874 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2920, 3650, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [2920, 3650, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [2920, 3650, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 54 mins 39.8 secs.\n",
      "\n",
      "\n",
      "------- processing patch 6 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 3650, 1222, 4380]\n",
      "submit a job to the worker for sub box 1: [1222, 3650, 2444, 4380]\n",
      "submit a job to the worker for sub box 2: [2444, 3650, 3666, 4380]\n",
      "submit a job to the worker for sub box 3: [3666, 3650, 4888, 4380]\n",
      "submit a job to the worker for sub box 4: [4888, 3650, 6110, 4380]\n",
      "submit a job to the worker for sub box 5: [6110, 3650, 7331, 4380]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 3650, 2444, 4380] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 3650, 4888, 4380] * 55 ...\n",
      "reading coherence in [4888, 3650, 6110, 4380] * 55 ...\n",
      "reading coherence in [6110, 3650, 7331, 4380] * 55 ...\n",
      "reading coherence in [0, 3650, 1222, 4380] * 55 ...\n",
      "reading coherence in [2444, 3650, 3666, 4380] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [4888, 3650, 6110, 4380] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [2444, 3650, 3666, 4380] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [3666, 3650, 4888, 4380] * 55 ...\n",
      "reading unwrapPhase in [6110, 3650, 7331, 4380] * 55 ...\n",
      "reading unwrapPhase in [1222, 3650, 2444, 4380] * 55 ...\n",
      "reading unwrapPhase in [0, 3650, 1222, 4380] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 743193 out of 891330 (83.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 319789 out of 892060 (35.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 319789/319789 pixels  331s /   589s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=================>      36%                       ] 325600/892060 pixels  332s /   590s\n",
      "FUTURE #1 complete. Time used: 352 seconds\n",
      "[==================================================] 743193/743193 pixels  708s /   135s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 84% =============>        ] 751400/892060 pixels  709s /   135s\n",
      "FUTURE #2 complete. Time used: 729 seconds\n",
      "[==================================================] 892060/892060 pixels  805s /    16s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 887400/892060 pixels\n",
      "FUTURE #3 complete. Time used: 827 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "[==================================================] 890200/892060 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 884600/892060 pixels\n",
      "FUTURE #4 complete. Time used: 829 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 886600/892060 pixels\n",
      "FUTURE #5 complete. Time used: 831 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 835 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 3650, 4380, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [3650, 4380, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [3650, 4380, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 68 mins 41.4 secs.\n",
      "\n",
      "\n",
      "------- processing patch 7 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4380, 1222, 5110]\n",
      "submit a job to the worker for sub box 1: [1222, 4380, 2444, 5110]\n",
      "submit a job to the worker for sub box 2: [2444, 4380, 3666, 5110]\n",
      "submit a job to the worker for sub box 3: [3666, 4380, 4888, 5110]\n",
      "submit a job to the worker for sub box 4: [4888, 4380, 6110, 5110]\n",
      "submit a job to the worker for sub box 5: [6110, 4380, 7331, 5110]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 4380, 1222, 5110] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 4380, 7331, 5110] * 55 ...\n",
      "reading coherence in [1222, 4380, 2444, 5110] * 55 ...\n",
      "reading coherence in [4888, 4380, 6110, 5110] * 55 ...\n",
      "reading coherence in [3666, 4380, 4888, 5110] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 4380, 3666, 5110] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [1222, 4380, 2444, 5110] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [2444, 4380, 3666, 5110] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [6110, 4380, 7331, 5110] * 55 ...\n",
      "reading unwrapPhase in [0, 4380, 1222, 5110] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [4888, 4380, 6110, 5110] * 55 ...\n",
      "reading unwrapPhase in [3666, 4380, 4888, 5110] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 796168 out of 892060 (89.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 227155 out of 892060 (25.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 439167 out of 892060 (49.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 241415 out of 891330 (27.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 467544 out of 892060 (52.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 227155/227155 pixels  238s /    12s\n",
      "[============>           26%                       ] 230800/892060 pixels  239s /   680sconverting LOS phase unit from radian to meter\n",
      "[======================= 95% ===================>  ] 228400/241415 pixels  238s /    12s\n",
      "FUTURE #1 complete. Time used: 258 seconds\n",
      "[==================================================] 241415/241415 pixels  249s /   240s\n",
      "[======================= 51%                       ] 240600/467544 pixels  250s /   240sconverting LOS phase unit from radian to meter\n",
      "[==============>         30%                       ] 241400/796168 pixels  250s /   585s\n",
      "FUTURE #2 complete. Time used: 269 seconds\n",
      "[==================================================] 439167/439167 pixels  395s /   337s\n",
      "[======================= 92% =================>    ] 431200/467544 pixels  395s /    34sconverting LOS phase unit from radian to meter\n",
      "[======================= 92% =================>    ] 431400/467544 pixels  395s /    34s\n",
      "FUTURE #3 complete. Time used: 415 seconds\n",
      "[==================================================] 467544/467544 pixels  418s /   370s\n",
      "[======================= 53%                       ] 475000/892060 pixels  418s /   371sconverting LOS phase unit from radian to meter\n",
      "[======================= 53%                       ] 475200/892060 pixels  418s /   371s\n",
      "FUTURE #4 complete. Time used: 437 seconds\n",
      "[==================================================] 796168/796168 pixels  580s /    50s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 92% =================>    ] 817400/892060 pixels  580s /    50s\n",
      "FUTURE #5 complete. Time used: 599 seconds\n",
      "[==================================================] 892060/892060 pixels  608s /    12s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 632 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4380, 5110, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4380, 5110, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4380, 5110, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 79 mins 21.1 secs.\n",
      "\n",
      "\n",
      "------- processing patch 8 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 655\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 5110, 1222, 5765]\n",
      "submit a job to the worker for sub box 1: [1222, 5110, 2444, 5765]\n",
      "submit a job to the worker for sub box 2: [2444, 5110, 3666, 5765]\n",
      "submit a job to the worker for sub box 3: [3666, 5110, 4888, 5765]\n",
      "submit a job to the worker for sub box 4: [4888, 5110, 6110, 5765]\n",
      "submit a job to the worker for sub box 5: [6110, 5110, 7331, 5765]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 5110, 7331, 5765] * 55 ...\n",
      "reading coherence in [0, 5110, 1222, 5765] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 5110, 3666, 5765] * 55 ...\n",
      "reading coherence in [3666, 5110, 4888, 5765] * 55 ...\n",
      "reading coherence in [4888, 5110, 6110, 5765] * 55 ...\n",
      "reading coherence in [1222, 5110, 2444, 5765] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 8\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 8\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 8\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 8\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 8\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 8\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 8\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 8 / 9\n",
      "reading unwrapPhase in [4888, 5110, 6110, 5765] * 55 ...\n",
      "reading unwrapPhase in [1222, 5110, 2444, 5765] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [3666, 5110, 4888, 5765] * 55 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 9\n",
      "reading unwrapPhase in [6110, 5110, 7331, 5765] * 55 ...\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [2444, 5110, 3666, 5765] * 55 ...\n",
      "reading unwrapPhase in [0, 5110, 1222, 5765] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 0 out of 800410 (0.0%)\n",
      "number of pixels to invert: 76721 out of 800410 (9.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 368576 out of 800410 (46.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 800410 (0.0%)\n",
      "\n",
      "FUTURE #1 complete. Time used: 19 seconds\n",
      "number of pixels to invert: 0 out of 799755 (0.0%)\n",
      "number of pixels to invert: 86986 out of 800410 (10.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]\n",
      "FUTURE #2 complete. Time used: 19 seconds\n",
      "[>                                                 ]\n",
      "FUTURE #3 complete. Time used: 20 seconds\n",
      "[==================================================] 76721/76721 pixels    52s /   198s\n",
      "[======================= 86% ==============>       ] 75200/86986 pixels   52s /     8sconverting LOS phase unit from radian to meter\n",
      "[=========>              21%                       ] 76000/368576 pixels   52s /   199s\n",
      "FUTURE #4 complete. Time used: 72 seconds\n",
      "[==================================================] 86986/86986 pixels    58s /   185s\n",
      "converting LOS phase unit from radian to meter\n",
      "[===========>            24%                       ] 88400/368576 pixels   58s /   185s\n",
      "FUTURE #5 complete. Time used: 78 seconds\n",
      "[==================================================] 368576/368576 pixels  158s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 179 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 5110, 5765, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [5110, 5765, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [5110, 5765, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 82 mins 28.4 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (1591, 3088)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 55\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 82 mins 28.4 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/maskTempCoh.h5\n",
      "time used: 00 mins 2.9 secs.\n",
      "number of reliable pixels: 24121573\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 11/11  128s /    12s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 02 mins 23.5 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 1442]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 1442]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 1442]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 1442]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 1442]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 1442]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 143872 out of 1762124 (8.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 420779 out of 1760682 (23.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1137440 out of 1762124 (64.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 934524 out of 1762124 (53.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 463127 out of 1762124 (26.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1090225 out of 1762124 (61.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 143872/143872   71s /   405ss\n",
      "[=====>                  12%                       ] 140000/1137440   71s /   525s\n",
      "FUTURE #1 complete. Time used: 78 seconds\n",
      "[==================================================] 420779/420779   189s /   337s\n",
      "[======================= 89% ===============>      ] 414000/463127  189s /    23ss\n",
      "FUTURE #2 complete. Time used: 196 seconds\n",
      "[==================================================] 463127/463127   205s /   295s\n",
      "[=====================>  43%                       ] 474000/1090225  205s /   272s\n",
      "FUTURE #3 complete. Time used: 212 seconds\n",
      "[==================================================] 934524/934524   322s /    66s\n",
      "[======================= 83% =============>        ] 946000/1137440  323s /    66s\n",
      "FUTURE #4 complete. Time used: 329 seconds\n",
      "[==================================================] 1090225/1090225  346s /    22s\n",
      "[======================= 94% ==================>   ] 1072000/1137440  347s /    22s\n",
      "FUTURE #5 complete. Time used: 353 seconds\n",
      "[==================================================] 1137440/1137440  354s /     7s\n",
      "\n",
      "FUTURE #6 complete. Time used: 363 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1442, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1442, 1222, 2884]\n",
      "submit a job to the worker for sub box 1: [1222, 1442, 2444, 2884]\n",
      "submit a job to the worker for sub box 2: [2444, 1442, 3666, 2884]\n",
      "submit a job to the worker for sub box 3: [3666, 1442, 4888, 2884]\n",
      "submit a job to the worker for sub box 4: [4888, 1442, 6110, 2884]\n",
      "submit a job to the worker for sub box 5: [6110, 1442, 7331, 2884]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762123 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1702141 out of 1762124 (96.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1207332 out of 1762124 (68.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 931632 out of 1760682 (52.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 931632/931632   362s /   321s\n",
      "[======================= 53%                       ] 938000/1762124  362s /   321s\n",
      "FUTURE #1 complete. Time used: 368 seconds\n",
      "[==================================================] 1207332/1207332  454s /   194s\n",
      "[======================= 70% ======>               ] 1230000/1762124  454s /   194s\n",
      "FUTURE #2 complete. Time used: 461 seconds\n",
      "[==================================================] 1702141/1702141  583s /    24s\n",
      "[======================= 97% ===================>  ] 1714000/1762124  583s /    18s\n",
      "FUTURE #3 complete. Time used: 590 seconds\n",
      "[==================================================] 1762124/1762124  593s /    12s\n",
      "[==================================================] 1750000/1762124\n",
      "FUTURE #4 complete. Time used: 602 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1758000/1762123\n",
      "FUTURE #5 complete. Time used: 604 seconds\n",
      "[==================================================] 1762123/1762123 \n",
      "\n",
      "FUTURE #6 complete. Time used: 605 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1442, 2884, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2884, 1222, 4326]\n",
      "submit a job to the worker for sub box 1: [1222, 2884, 2444, 4326]\n",
      "submit a job to the worker for sub box 2: [2444, 2884, 3666, 4326]\n",
      "submit a job to the worker for sub box 3: [3666, 2884, 4888, 4326]\n",
      "submit a job to the worker for sub box 4: [4888, 2884, 6110, 4326]\n",
      "submit a job to the worker for sub box 5: [6110, 2884, 7331, 4326]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 769361 out of 1762124 (43.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1346017 out of 1760682 (76.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 769361/769361   300s /   398s\n",
      "[=====================>  43%                       ] 754000/1762124  301s /   399s\n",
      "FUTURE #1 complete. Time used: 307 seconds\n",
      "[==================================================] 1346017/1346017  492s /   155s\n",
      "[======================= 76% =========>            ] 1336000/1762124  492s /   155s\n",
      "FUTURE #2 complete. Time used: 498 seconds\n",
      "[==================================================] 1762124/1762124  604s /    12s\n",
      "[==================================================] 1750000/1762124\n",
      "FUTURE #3 complete. Time used: 612 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1750000/1762124\n",
      "FUTURE #4 complete. Time used: 614 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #5 complete. Time used: 616 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #6 complete. Time used: 618 seconds\n",
      "close dask client\n",
      "2023-07-07 12:35:27,348 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/worker.py\", line 1237, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/utils_comm.py\", line 413, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/core.py\", line 1365, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/core.py\", line 1124, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 241, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48316 remote=tcp://127.0.0.1:34679>: Stream is closed\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2884, 4326, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1439\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4326, 1222, 5765]\n",
      "submit a job to the worker for sub box 1: [1222, 4326, 2444, 5765]\n",
      "submit a job to the worker for sub box 2: [2444, 4326, 3666, 5765]\n",
      "submit a job to the worker for sub box 3: [3666, 4326, 4888, 5765]\n",
      "submit a job to the worker for sub box 4: [4888, 4326, 6110, 5765]\n",
      "submit a job to the worker for sub box 5: [6110, 4326, 7331, 5765]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 505155 out of 1758458 (28.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1326624 out of 1758458 (75.4%)\n",
      "number of pixels to invert: 938877 out of 1758458 (53.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 300080 out of 1757019 (17.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 334321 out of 1758458 (19.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 533532 out of 1758458 (30.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 300080/300080  114s /    15ss\n",
      "[===============>        32%                       ] 300000/938877  115s /   244ss\n",
      "FUTURE #1 complete. Time used: 121 seconds\n",
      "[==================================================] 334321/334321   128s /   385s\n",
      "[======================= 63% ===>                  ] 334000/533532  129s /    75ss\n",
      "FUTURE #2 complete. Time used: 135 seconds\n",
      "[==================================================] 505155/505155   172s /   282s\n",
      "[==================>     38%                       ] 504000/1326624  173s /   283s\n",
      "FUTURE #3 complete. Time used: 179 seconds\n",
      "[==================================================] 533532/533532   182s /   262s\n",
      "[======================= 58% >                     ] 544000/938877  182s /   132s\n",
      "FUTURE #4 complete. Time used: 188 seconds\n",
      "[==================================================] 938877/938877   254s /   103s\n",
      "\n",
      "FUTURE #5 complete. Time used: 260 seconds\n",
      "[==================================================] 1326624/1326624  309s /     6s\n",
      "\n",
      "FUTURE #6 complete. Time used: 318 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4326, 5765, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4326, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4326, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 32 mins 26.2 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 11/11  119s /    11s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 02 mins 12.1 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 11/11   74s /     7s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20210722 - 0.0004\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0011)\n",
      "20210803 - 0.0012\n",
      "save date(s) to file: exclude_date.txt\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20210722\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5765, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20210722\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5765, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20210722\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5765, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20210722\n",
      "time used: 00 mins 57.7 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: ['20210803']\n",
      "--------------------------------------------------\n",
      "dates from input file: 11\n",
      "['20210604', '20210616', '20210628', '20210710', '20210722', '20210803', '20210815', '20210827', '20210908', '20210920', '20211014']\n",
      "--------------------------------------------------\n",
      "dates used to estimate the time function: 10\n",
      "['20210604', '20210616', '20210628', '20210710', '20210722', '20210815', '20210827', '20210908', '20210920', '20211014']\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5\n",
      "split along y dimension (5765) into 2 boxes\n",
      "    with each box up to 2883 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 2 --------------\n",
      "box width:  7331\n",
      "box length: 2883\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13311078 out of 21135273 (63.0%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 2883, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 2883, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 2883, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 2883, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 2883, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 2 --------------\n",
      "box width:  7331\n",
      "box length: 2882\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13108829 out of 21127942 (62.0%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [2883, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [2883, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [2883, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [2883, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [2883, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5.\n",
      "time used: 00 mins 24.7 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7331, 5765)\n",
      "subset coverage in y/x: (0, 0, 7331, 5765)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7331/5765\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.26, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 03 mins 50.7 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 141 mins 2.5 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "mintpy_multiyear(orbit_list, ['2021'], clip=True, mintpy=True, clean_clip=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mintpy]",
   "language": "python",
   "name": "conda-env-mintpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
