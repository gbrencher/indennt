{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f7bb06e-6e63-4d64-b7d6-8ccb6c97757b",
   "metadata": {},
   "source": [
    "# MintPy for signal maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c766f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import mintpy\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ed07a6-5cd1-428e-8e7b-aa8eebec1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_list = ['AT137']\n",
    "year_list = ['2017', '2018', '2019', '2020', '2021']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910045f-42cf-4bf6-8c42-abda85c05b03",
   "metadata": {},
   "source": [
    "## clip files to common extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ec0ec07-2bfd-4a78-b90a-df7ea38c24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_overlap(file_list: List[Union[str, Path]]) -> List[float]:\n",
    "    \"\"\"Get the common overlap of  a list of GeoTIFF files\n",
    "    \n",
    "    Arg:\n",
    "        file_list: a list of GeoTIFF files\n",
    "    \n",
    "    Returns:\n",
    "         [ulx, uly, lrx, lry], the upper-left x, upper-left y, lower-right x, and lower-right y\n",
    "         corner coordinates of the common overlap\n",
    "    \"\"\"\n",
    "    \n",
    "    corners = [gdal.Info(str(dem), format='json')['cornerCoordinates'] for dem in file_list]\n",
    "\n",
    "    ulx = max(corner['upperLeft'][0] for corner in corners)\n",
    "    uly = min(corner['upperLeft'][1] for corner in corners)\n",
    "    lrx = min(corner['lowerRight'][0] for corner in corners)\n",
    "    lry = max(corner['lowerRight'][1] for corner in corners)\n",
    "    return [ulx, uly, lrx, lry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8aeb241-e1b8-404d-b156-11177471a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_hyp3_products_to_common_overlap(data_path: Union[str, Path], overlap: List[float]) -> None:\n",
    "    \"\"\"Clip all GeoTIFF files to their common overlap\n",
    "    \n",
    "    Args:\n",
    "        data_dir:\n",
    "            directory containing the GeoTIFF files to clip\n",
    "        overlap:\n",
    "            a list of the upper-left x, upper-left y, lower-right-x, and lower-tight y\n",
    "            corner coordinates of the common overlap\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    \n",
    "    files_for_mintpy = ['_water_mask.tif', '_corr.tif', '_unw_phase_MuRP.tif', '_dem.tif', '_lv_theta.tif', '_lv_phi.tif']\n",
    "\n",
    "    for extension in files_for_mintpy:\n",
    "        print(f'working on {extension}') \n",
    "        for file in data_path.rglob(f'*{extension}'):\n",
    "\n",
    "            dst_file = file.parent / f'{file.stem}_clipped{file.suffix}'\n",
    "\n",
    "            gdal.Translate(destName=str(dst_file), srcDS=str(file), projWin=overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dc256-88c0-4ac9-88aa-4ee420ca1e1d",
   "metadata": {},
   "source": [
    "## Mintpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033276cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write to MintPy config file\n",
    "def write_config_file(out_file, CONFIG_TXT, mode='a'): \n",
    "    \"\"\"Write configuration files for MintPy to process products\"\"\"\n",
    "    if not os.path.isfile(out_file) or mode == 'w':\n",
    "        with open(out_file, \"w\") as fid:\n",
    "            fid.write(CONFIG_TXT)\n",
    "        print('write configuration to file: {}'.format(out_file))\n",
    "    else:\n",
    "        with open(out_file, \"a\") as fid:\n",
    "            fid.write(\"\\n\" + CONFIG_TXT)\n",
    "        print('add the following to file: \\n{}'.format(CONFIG_TXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42499563-1225-4427-8863-4ef390300f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clip files and run mintpy for multiple years \n",
    "def mintpy_multiyear(orbit_list, year_list, clip=True, mintpy=True, clean_clip=True):\n",
    "    # hardcoded paths for now \n",
    "    home_path_d = '/mnt/d/indennt'\n",
    "    home_path = '/mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data'\n",
    "    for orbit in orbit_list:\n",
    "        for year in year_list:\n",
    "            print(f'working on {orbit}, {year}')\n",
    "            data_path = f'{home_path_d}/hyp3_app/{orbit}/{year}'\n",
    "            mintpy_path = f'{home_path}/signal_mintpy/{orbit}/mintpy_{year}_MuRP'\n",
    "            mintpy_path_d = f'{home_path_d}/mintpy_app/{orbit}/'\n",
    "\n",
    "            if clip==True:\n",
    "                # identify and crop to common overlap\n",
    "                print('identifying common overlap')\n",
    "                dem_files = Path(data_path).glob('*/*_dem.tif')\n",
    "                overlap = get_common_overlap(dem_files)\n",
    "                print('clipping to common overlap')\n",
    "                clip_hyp3_products_to_common_overlap(Path(data_path), overlap)\n",
    "\n",
    "            # make output dir for mintpy\n",
    "            if not os.path.exists(mintpy_path):\n",
    "                os.mkdir(mintpy_path)\n",
    "\n",
    "            # write config file for mintpy\n",
    "            CONFIG_TXT = f'''# vim: set filetype=cfg:\n",
    "            ##----------------------------- hyp3 ---------------------##\n",
    "            mintpy.load.processor        = hyp3\n",
    "            ##---------interferogram datasets:\n",
    "            mintpy.load.unwFile          = {data_path}/*/*{year}*unw_phase_MuRP_clipped.tif\n",
    "            mintpy.load.corFile          = {data_path}/*/*{year}*corr_clipped.tif\n",
    "            ##---------geometry datasets:\n",
    "            mintpy.load.demFile          = {data_path}/*/*{year}*dem_clipped.tif\n",
    "            mintpy.load.incAngleFile     = {data_path}/*/*{year}*lv_theta_clipped.tif\n",
    "            mintpy.load.waterMaskFile    = {data_path}/*/*{year}*water_mask_clipped.tif\n",
    "\n",
    "            mintpy.deramp                = linear\n",
    "            mintpy.reference.lalo        = auto\n",
    "            mintpy.troposphericDelay.method  = no\n",
    "\n",
    "            mintpy.compute.cluster    = local\n",
    "            mintpy.compute.numWorker  = 6\n",
    "            '''\n",
    "\n",
    "            os.chdir(mintpy_path)\n",
    "            config_file = f'{mintpy_path}/{year}_Sen{orbit}.txt'\n",
    "            write_config_file(config_file, CONFIG_TXT, mode='w')\n",
    "\n",
    "            if mintpy==True:\n",
    "                # run mintpy\n",
    "                print('starting mintpy')\n",
    "                !smallbaselineApp.py --dir {mintpy_path} {config_file}\n",
    "                print('moving outputs to drive')\n",
    "                !cp -r $mintpy_path $mintpy_path_d && rm -R $mintpy_path\n",
    "\n",
    "            if clean_clip==True:\n",
    "                # remove clipped files\n",
    "                print('removing clipped files')\n",
    "                clipped_files = f'{data_path}/*/*_clipped.tif'\n",
    "                !rm {clipped_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf39b43-8dac-40e1-b054-406c9e8706a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on AT137, 2017\n",
      "identifying common overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/2017_SenAT137.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-07-07 17:20:19.119714--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: 2017_SenAT137\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/2017_SenAT137.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*unw_phase_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy 2017_SenAT137.txt    to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg to inputs   directory for backup.\n",
      "copy 2017_SenAT137.txt    to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/2017_SenAT137.txt --project 2017_SenAT137\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*unw_phase_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3_app/AT137/2017/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3_app/AT137/2017/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3_app/AT137/2017/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5763, 7327) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5763, 7327) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5763, 7327) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5763, 7327) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*unw_phase_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*corr_clipped.tif\n",
      "number of unwrapPhase     : 45\n",
      "number of coherence       : 45\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (45, 5763, 7327) with compression = None\n",
      "[==================================================] 20170929_20171011  245s /     5s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (45, 5763, 7327) with compression = None\n",
      "[==================================================] 20170929_20171011  240s /     4s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (45, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (45,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (45,)\n",
      "add extra metadata: {'PROJECT_NAME': '2017_SenAT137', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 09 mins 17.5 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file 2017_SenAT137.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file 2017_SenAT137.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 45/45   47s /     0s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 10\n",
      "number of interferograms: 45\n",
      "shift all perp baseline by 19.02423095703125 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 45\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 201.27 m\n",
      "max temporal      baseline: 120.0 days\n",
      "showing coherence\n",
      "data range: [0.5309866, 0.8892115]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 45/45   44s /     0s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/maskConnComp.h5\n",
      "time used: 00 mins 46.9 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   41s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/avgSpatialCoh.h5\n",
      "time used: 00 mins 51.7 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   35s /     5s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (4083, 6772)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5\n",
      "{'REF_Y': '4083', 'REF_X': '6772', 'REF_LAT': '4724260.0', 'REF_LON': '769940.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   37s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/avgPhaseVelocity.h5\n",
      "time used: 00 mins 47.8 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 45\n",
      "number of triplets: 120\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (250, 7327), 24 blocks in total\n",
      "reference pixel in y/x: (4083, 6772) from dataset: unwrapPhase\n",
      "[==================================================] line 5750 / 5763  131s /     5s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/numTriNonzeroIntAmbiguity.png\n",
      "time used: 02 mins 21.0 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (4083, 6772) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 45\n",
      "number of acquisitions  : 10\n",
      "number of lines   : 5763\n",
      "number of columns : 7327\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5763 lines into 6 patches for processing\n",
      "    with each patch up to 970 lines\n",
      "\n",
      "------- processing patch 1 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 970]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 970]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 970]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 970]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 970]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7327, 970]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 0, 6110, 970] * 45 ...\n",
      "reading coherence in [0, 0, 1222, 970] * 45 ...\n",
      "reading coherence in [6110, 0, 7327, 970] * 45 ...\n",
      "reading coherence in [1222, 0, 2444, 970] * 45 ...\n",
      "reading coherence in [2444, 0, 3666, 970] * 45 ...\n",
      "reading coherence in [3666, 0, 4888, 970] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 0, 7327, 970] * 45 ...\n",
      "reading unwrapPhase in [2444, 0, 3666, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 0, 4888, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 0, 2444, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 0, 6110, 970] * 45 ...\n",
      "reading unwrapPhase in [0, 0, 1222, 970] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 206160 out of 1180490 (17.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 0 out of 1185340 (0.0%)\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "\n",
      "FUTURE #1 complete. Time used: 14 seconds\n",
      "[>                                                 ]number of pixels to invert: 20627 out of 1185340 (1.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 514086 out of 1185340 (43.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 358305 out of 1185340 (30.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 562969 out of 1185340 (47.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 20627/20627 pixels     9s /   234s\n",
      "[==>                      6%                       ] 22000/358305 pixels    9s /   153sconverting LOS phase unit from radian to meter\n",
      "[=>                       4%                       ] 22000/514086 pixels    9s /   238s\n",
      "FUTURE #2 complete. Time used: 25 seconds\n",
      "[==================================================] 206160/206160 pixels   74s /   126s\n",
      "[======================= 58% >                     ] 208200/358305 pixels   74s /    53sconverting LOS phase unit from radian to meter\n",
      "[===================>    40%                       ] 205000/514086 pixels   74s /   111s\n",
      "FUTURE #3 complete. Time used: 89 seconds\n",
      "[==================================================] 358305/358305 pixels  115s /    51s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 64% ===>                  ] 357600/562969 pixels  115s /    64s\n",
      "FUTURE #4 complete. Time used: 130 seconds\n",
      "[==================================================] 514086/514086 pixels  159s /    13s\n",
      "[======================= 92% =================>    ] 519400/562969 pixels  159s /    13sconverting LOS phase unit from radian to meter\n",
      "[======================= 92% =================>    ] 519800/562969 pixels  159s /    13s\n",
      "FUTURE #5 complete. Time used: 174 seconds\n",
      "[==================================================] 562969/562969 pixels  166s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 183 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 970, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 970, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 970, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 03 mins 9.2 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 970, 1222, 1940]\n",
      "submit a job to the worker for sub box 1: [1222, 970, 2444, 1940]\n",
      "submit a job to the worker for sub box 2: [2444, 970, 3666, 1940]\n",
      "submit a job to the worker for sub box 3: [3666, 970, 4888, 1940]\n",
      "submit a job to the worker for sub box 4: [4888, 970, 6110, 1940]\n",
      "submit a job to the worker for sub box 5: [6110, 970, 7327, 1940]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 970, 2444, 1940] * 45 ...\n",
      "reading coherence in [6110, 970, 7327, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 970, 6110, 1940] * 45 ...\n",
      "reading coherence in [2444, 970, 3666, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 970, 4888, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 970, 1222, 1940] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 970, 6110, 1940] * 45 ...\n",
      "reading unwrapPhase in [0, 970, 1222, 1940] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 970, 2444, 1940] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 970, 7327, 1940] * 45 ...\n",
      "reading unwrapPhase in [3666, 970, 4888, 1940] * 45 ...\n",
      "reading unwrapPhase in [2444, 970, 3666, 1940] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 488950 out of 1180490 (41.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1183743 out of 1185340 (99.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 608465 out of 1185340 (51.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1053734 out of 1185340 (88.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 488950/488950 pixels   245s /   300s\n",
      "converting LOS phase unit from radian to meter\n",
      "[===================>    41%                       ] 483800/1183743 pixels  246s /   354s\n",
      "FUTURE #1 complete. Time used: 261 seconds\n",
      "[==================================================] 608465/608465 pixels   301s /   227s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 52%                       ] 618000/1185340 pixels  301s /   278s\n",
      "FUTURE #2 complete. Time used: 316 seconds\n",
      "[==================================================] 1053734/1053734 pixels  471s /    40s\n",
      "[======================= 92% =================>    ] 1089200/1183743 pixels  471s /    41sconverting LOS phase unit from radian to meter\n",
      "[======================= 92% =================>    ] 1089400/1183743 pixels  471s /    41s\n",
      "FUTURE #3 complete. Time used: 487 seconds\n",
      "[==================================================] 1185340/1185340 pixels  500s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1175000/1183743 pixels\n",
      "FUTURE #4 complete. Time used: 518 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1177400/1183743 pixels\n",
      "FUTURE #5 complete. Time used: 519 seconds\n",
      "[==================================================] 1183743/1183743 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 520 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 970, 1940, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [970, 1940, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [970, 1940, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 11 mins 53.3 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1940, 1222, 2910]\n",
      "submit a job to the worker for sub box 1: [1222, 1940, 2444, 2910]\n",
      "submit a job to the worker for sub box 2: [2444, 1940, 3666, 2910]\n",
      "submit a job to the worker for sub box 3: [3666, 1940, 4888, 2910]\n",
      "submit a job to the worker for sub box 4: [4888, 1940, 6110, 2910]\n",
      "submit a job to the worker for sub box 5: [6110, 1940, 7327, 2910]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 1940, 4888, 2910] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 1940, 3666, 2910] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 1940, 6110, 2910] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 1940, 1222, 2910] * 45 ...\n",
      "reading coherence in [1222, 1940, 2444, 2910] * 45 ...\n",
      "reading coherence in [6110, 1940, 7327, 2910] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 1940, 2444, 2910] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 1940, 1222, 2910] * 45 ...\n",
      "reading unwrapPhase in [4888, 1940, 6110, 2910] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 1940, 4888, 2910] * 45 ...\n",
      "reading unwrapPhase in [6110, 1940, 7327, 2910] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 1940, 3666, 2910] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 767701 out of 1185340 (64.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 672725 out of 1180490 (57.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1126954 out of 1185340 (95.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 672725/672725 pixels   351s /   276s\n",
      "[======================= 56%                       ] 666800/1185340 pixels  351s /   276sconverting LOS phase unit from radian to meter\n",
      "[======================= 56%                       ] 660400/1185340 pixels  351s /   276s\n",
      "FUTURE #1 complete. Time used: 368 seconds\n",
      "[==================================================] 767701/767701 pixels   393s /   185s\n",
      "[======================= 65% ===>                  ] 773800/1185340 pixels  393s /   211sconverting LOS phase unit from radian to meter\n",
      "[======================= 65% ===>                  ] 774000/1185340 pixels  393s /   211s\n",
      "FUTURE #2 complete. Time used: 410 seconds\n",
      "[==================================================] 1126954/1126954 pixels  619s /    39s\n",
      "[======================= 93% =================>    ] 1103200/1185340 pixels  619s /    46sconverting LOS phase unit from radian to meter\n",
      "[======================= 94% ==================>   ] 1117600/1185340 pixels  619s /    39s\n",
      "FUTURE #3 complete. Time used: 636 seconds\n",
      "[==================================================] 1185340/1185340 pixels  646s /    19s\n",
      "[==================================================] 1168200/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #4 complete. Time used: 663 seconds\n",
      "[==================================================] 1185340/1185340 pixels  653s /    13s\n",
      "[==================================================] 1170000/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #5 complete. Time used: 672 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 677 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1940, 2910, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [1940, 2910, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [1940, 2910, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 23 mins 15.1 secs.\n",
      "\n",
      "\n",
      "------- processing patch 4 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2910, 1222, 3880]\n",
      "submit a job to the worker for sub box 1: [1222, 2910, 2444, 3880]\n",
      "submit a job to the worker for sub box 2: [2444, 2910, 3666, 3880]\n",
      "submit a job to the worker for sub box 3: [3666, 2910, 4888, 3880]\n",
      "submit a job to the worker for sub box 4: [4888, 2910, 6110, 3880]\n",
      "submit a job to the worker for sub box 5: [6110, 2910, 7327, 3880]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 2910, 1222, 3880] * 45 ...\n",
      "reading coherence in [4888, 2910, 6110, 3880] * 45 ...\n",
      "reading coherence in [1222, 2910, 2444, 3880] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 2910, 7327, 3880] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 2910, 4888, 3880] * 45 ...\n",
      "reading coherence in [2444, 2910, 3666, 3880] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 2910, 1222, 3880] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 2910, 2444, 3880] * 45 ...\n",
      "reading unwrapPhase in [6110, 2910, 7327, 3880] * 45 ...\n",
      "reading unwrapPhase in [2444, 2910, 3666, 3880] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 2910, 4888, 3880] * 45 ...\n",
      "reading unwrapPhase in [4888, 2910, 6110, 3880] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 570072 out of 1185340 (48.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 863309 out of 1180490 (73.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 570072/570072 pixels  475s /   256ss\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 65% ===>                  ] 564800/863309 pixels  475s /   256ss\n",
      "FUTURE #1 complete. Time used: 493 seconds\n",
      "[==================================================] 863309/863309 pixels   692s /   243s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 73% =======>              ] 868400/1185340 pixels  692s /   256s\n",
      "FUTURE #2 complete. Time used: 710 seconds\n",
      "[==================================================] 1185340/1185340 pixels  878s /    17s\n",
      "[==================================================] 1174200/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1171800/1185340 pixels\n",
      "FUTURE #3 complete. Time used: 899 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "[==================================================] 1178600/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1181000/1185340 pixels\n",
      "FUTURE #4 complete. Time used: 903 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "[==================================================] 1183400/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #5 complete. Time used: 906 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 907 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2910, 3880, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [2910, 3880, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [2910, 3880, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 38 mins 28.0 secs.\n",
      "\n",
      "\n",
      "------- processing patch 5 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 3880, 1222, 4850]\n",
      "submit a job to the worker for sub box 1: [1222, 3880, 2444, 4850]\n",
      "submit a job to the worker for sub box 2: [2444, 3880, 3666, 4850]\n",
      "submit a job to the worker for sub box 3: [3666, 3880, 4888, 4850]\n",
      "submit a job to the worker for sub box 4: [4888, 3880, 6110, 4850]\n",
      "submit a job to the worker for sub box 5: [6110, 3880, 7327, 4850]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 3880, 1222, 4850] * 45 ...\n",
      "reading coherence in [2444, 3880, 3666, 4850] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 3880, 4888, 4850] * 45 ...\n",
      "reading coherence in [4888, 3880, 6110, 4850] * 45 ...\n",
      "reading coherence in [6110, 3880, 7327, 4850] * 45 ...\n",
      "reading coherence in [1222, 3880, 2444, 4850] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 3880, 6110, 4850] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 3880, 3666, 4850] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 3880, 2444, 4850] * 45 ...\n",
      "reading unwrapPhase in [6110, 3880, 7327, 4850] * 45 ...\n",
      "reading unwrapPhase in [0, 3880, 1222, 4850] * 45 ...\n",
      "reading unwrapPhase in [3666, 3880, 4888, 4850] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 365938 out of 1185340 (30.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 760932 out of 1180490 (64.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1074964 out of 1185340 (90.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1049174 out of 1185340 (88.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 365938/365938 pixels  309s /   349ss\n",
      "[==============>         30%                       ] 360400/1185340 pixels  309s /   722sconverting LOS phase unit from radian to meter\n",
      "[======================= 47%                       ] 359600/760932 pixels  309s /   349ss\n",
      "FUTURE #1 complete. Time used: 328 seconds\n",
      "[==================================================] 760932/760932 pixels   587s /   240s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 71% =======>              ] 760400/1074964 pixels  588s /   240s\n",
      "FUTURE #2 complete. Time used: 606 seconds\n",
      "[==================================================] 1049174/1049174 pixels  690s /    94s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 88% ===============>      ] 1044000/1185340 pixels  690s /    94s\n",
      "FUTURE #3 complete. Time used: 708 seconds\n",
      "[==================================================] 1074964/1074964 pixels  698s /    69s\n",
      "[======================= 91% =================>    ] 1075600/1185340 pixels  698s /    69sconverting LOS phase unit from radian to meter\n",
      "[======================= 91% =================>    ] 1075800/1185340 pixels  698s /    69s\n",
      "FUTURE #4 complete. Time used: 717 seconds\n",
      "[==================================================] 1185340/1185340 pixels  721s /    14s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1182000/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 743 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 744 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 3880, 4850, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [3880, 4850, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [3880, 4850, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 50 mins 57.4 secs.\n",
      "\n",
      "\n",
      "------- processing patch 6 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 913\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4850, 1222, 5763]\n",
      "submit a job to the worker for sub box 1: [1222, 4850, 2444, 5763]\n",
      "submit a job to the worker for sub box 2: [2444, 4850, 3666, 5763]\n",
      "submit a job to the worker for sub box 3: [3666, 4850, 4888, 5763]\n",
      "submit a job to the worker for sub box 4: [4888, 4850, 6110, 5763]\n",
      "submit a job to the worker for sub box 5: [6110, 4850, 7327, 5763]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 4850, 4888, 5763] * 45 ...\n",
      "reading coherence in [2444, 4850, 3666, 5763] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 4850, 6110, 5763] * 45 ...\n",
      "reading coherence in [1222, 4850, 2444, 5763] * 45 ...\n",
      "reading coherence in [0, 4850, 1222, 5763] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 4850, 7327, 5763] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 11 / 12\n",
      "reading unwrapPhase in [6110, 4850, 7327, 5763] * 45 ...\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "reading unwrapPhase in [4888, 4850, 6110, 5763] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 4850, 3666, 5763] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 4850, 1222, 5763] * 45 ...\n",
      "reading unwrapPhase in [3666, 4850, 4888, 5763] * 45 ...\n",
      "reading unwrapPhase in [1222, 4850, 2444, 5763] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 0 out of 1111121 (0.0%)\n",
      "number of pixels to invert: 2840 out of 1115686 (0.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "\n",
      "FUTURE #1 complete. Time used: 13 seconds\n",
      "[===>                     7%                       ] 200/2840 pixels    0s /     1snumber of pixels to invert: 1600 out of 1115686 (0.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 159221 out of 1115686 (14.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 298181 out of 1115686 (26.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[======>                 14%                       ] 400/2840 pixels    0s /     1snumber of pixels to invert: 686152 out of 1115686 (61.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 1600/1600 pixels    0s /     0s\n",
      "[>                                                 ]converting LOS phase unit from radian to meter\n",
      "[>                                                 ] 1800/2840 pixels    0s /     0s\n",
      "FUTURE #2 complete. Time used: 14 seconds\n",
      "[==================================================] 2840/2840 pixels    0s /     0s\n",
      "[>                                                 ]converting LOS phase unit from radian to meter\n",
      "[>                                                 ]\n",
      "FUTURE #3 complete. Time used: 14 seconds\n",
      "[==================================================] 159221/159221 pixels   59s /   210s\n",
      "[======================= 53%                       ] 158200/298181 pixels   59s /    52sconverting LOS phase unit from radian to meter\n",
      "[==========>             22%                       ] 153200/686152 pixels   59s /   211s\n",
      "FUTURE #4 complete. Time used: 73 seconds\n",
      "[==================================================] 298181/298181 pixels  102s /   141s\n",
      "converting LOS phase unit from radian to meter\n",
      "[====================>   42%                       ] 290200/686152 pixels  102s /   141s\n",
      "FUTURE #5 complete. Time used: 116 seconds\n",
      "[==================================================] 686152/686152 pixels  186s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 203 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4850, 5763, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4850, 5763, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4850, 5763, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 54 mins 25.2 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (4083, 6772)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 45\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 54 mins 25.2 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/maskTempCoh.h5\n",
      "time used: 00 mins 2.0 secs.\n",
      "number of reliable pixels: 20864045\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  61s /     6s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 7.4 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7327\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 1441]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 1441]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 1441]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 1441]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 1441]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7327, 1441]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1084700 out of 1760902 (61.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1133107 out of 1760902 (64.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 459019 out of 1760902 (26.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 409851 out of 1753697 (23.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 140605 out of 1760902 (8.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 928904 out of 1760902 (52.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 140605/140605   25s /    55ss\n",
      "[=====>                  13%                       ] 142000/1084700   25s /   170s\n",
      "FUTURE #1 complete. Time used: 28 seconds\n",
      "[==================================================] 409851/409851   71s /     6ss\n",
      "[======================= 92% =================>    ] 424000/459019   72s /     6ss\n",
      "FUTURE #2 complete. Time used: 75 seconds\n",
      "[==================================================] 459019/459019    78s /   108s\n",
      "[====================>   42%                       ] 458000/1084700   79s /   109s\n",
      "FUTURE #3 complete. Time used: 82 seconds\n",
      "[==================================================] 928904/928904   160s /    30s\n",
      "[======================= 85% =============>        ] 958000/1133107  160s /    28s\n",
      "FUTURE #4 complete. Time used: 163 seconds\n",
      "[==================================================] 1084700/1084700  174s /     9s\n",
      "[======================= 96% ===================>  ] 1084000/1133107  174s /     7s\n",
      "FUTURE #5 complete. Time used: 177 seconds\n",
      "[==================================================] 1133107/1133107  177s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 182 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1441, 0, 7327]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1441, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1441, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7327\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1441, 1222, 2882]\n",
      "submit a job to the worker for sub box 1: [1222, 1441, 2444, 2882]\n",
      "submit a job to the worker for sub box 2: [2444, 1441, 3666, 2882]\n",
      "submit a job to the worker for sub box 3: [3666, 1441, 4888, 2882]\n",
      "submit a job to the worker for sub box 4: [4888, 1441, 6110, 2882]\n",
      "submit a job to the worker for sub box 5: [6110, 1441, 7327, 2882]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1202940 out of 1760902 (68.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 918295 out of 1753697 (52.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1700919 out of 1760902 (96.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 918295/918295   202s /   186s\n",
      "[======================= 53%                       ] 904000/1700919  202s /   179s\n",
      "FUTURE #1 complete. Time used: 206 seconds\n",
      "[==================================================] 1202940/1202940  267s /   120s\n",
      "[======================= 70% ======>               ] 1198000/1700919  268s /   115s\n",
      "FUTURE #2 complete. Time used: 271 seconds\n",
      "[==================================================] 1700919/1700919  351s /    14s\n",
      "[======================= 98% ====================> ] 1720000/1760902  351s /     7s\n",
      "FUTURE #3 complete. Time used: 354 seconds\n",
      "[==================================================] 1760902/1760902  356s /    11s\n",
      "[======================= 97% ===================>  ] 1714000/1760902  356s /    11s\n",
      "FUTURE #4 complete. Time used: 359 seconds\n",
      "[==================================================] 1760902/1760902  358s /     7s\n",
      "[==================================================] 1738000/1760902\n",
      "FUTURE #5 complete. Time used: 362 seconds\n",
      "[==================================================] 1760902/1760902 \n",
      "\n",
      "FUTURE #6 complete. Time used: 364 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1441, 2882, 0, 7327]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1441, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1441, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7327\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2882, 1222, 4323]\n",
      "submit a job to the worker for sub box 1: [1222, 2882, 2444, 4323]\n",
      "submit a job to the worker for sub box 2: [2444, 2882, 3666, 4323]\n",
      "submit a job to the worker for sub box 3: [3666, 2882, 4888, 4323]\n",
      "submit a job to the worker for sub box 4: [4888, 2882, 6110, 4323]\n",
      "submit a job to the worker for sub box 5: [6110, 2882, 7327, 4323]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 764034 out of 1760902 (43.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1334003 out of 1753697 (76.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 764034/764034   180s /   248s\n",
      "[====================>   42%                       ] 742000/1760902  180s /   248s\n",
      "FUTURE #1 complete. Time used: 184 seconds\n",
      "[==================================================] 1334003/1334003  299s /    99s\n",
      "[======================= 76% =========>            ] 1334000/1760902  299s /    94s\n",
      "FUTURE #2 complete. Time used: 303 seconds\n",
      "[==================================================] 1760902/1760902  378s /     7s\n",
      "[======================= 98% ====================> ] 1726000/1760902  378s /     7s\n",
      "FUTURE #3 complete. Time used: 382 seconds\n",
      "[==================================================] 1760902/1760902  381s /     7s\n",
      "[==================================================] 1756000/1760902\n",
      "FUTURE #4 complete. Time used: 388 seconds\n",
      "[==================================================] 1760902/1760902 \n",
      "[==================================================] 1754000/1760902\n",
      "FUTURE #5 complete. Time used: 389 seconds\n",
      "[==================================================] 1760902/1760902 \n",
      "\n",
      "FUTURE #6 complete. Time used: 390 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2882, 4323, 0, 7327]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2882, 4323, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2882, 4323, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7327\n",
      "box length: 1440\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4323, 1222, 5763]\n",
      "submit a job to the worker for sub box 1: [1222, 4323, 2444, 5763]\n",
      "submit a job to the worker for sub box 2: [2444, 4323, 3666, 5763]\n",
      "submit a job to the worker for sub box 3: [3666, 4323, 4888, 5763]\n",
      "submit a job to the worker for sub box 4: [4888, 4323, 6110, 5763]\n",
      "submit a job to the worker for sub box 5: [6110, 4323, 7327, 5763]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 530143 out of 1759680 (30.1%)\n",
      "number of pixels to invert: 501580 out of 1759680 (28.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 331096 out of 1759680 (18.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 296173 out of 1752480 (16.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1324101 out of 1759680 (75.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 935485 out of 1759680 (53.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 296173/296173   56s /    46ss\n",
      "[======================= 59% =>                    ] 298000/501580   57s /    39s\n",
      "FUTURE #1 complete. Time used: 61 seconds\n",
      "[==================================================] 331096/331096    63s /   191s\n",
      "[=================>      35%                       ] 330000/935485   64s /   119s\n",
      "FUTURE #2 complete. Time used: 68 seconds\n",
      "[==================================================] 501580/501580    91s /   149s\n",
      "[==================>     38%                       ] 502000/1324101   91s /   149s\n",
      "FUTURE #3 complete. Time used: 96 seconds\n",
      "[==================================================] 530143/530143    97s /   140s\n",
      "[======================= 57%                       ] 536000/935485   98s /    73s\n",
      "FUTURE #4 complete. Time used: 102 seconds\n",
      "[==================================================] 935485/935485   153s /    68s\n",
      "[======================= 70% ======>               ] 922000/1324101  153s /    65s\n",
      "FUTURE #5 complete. Time used: 158 seconds\n",
      "[==================================================] 1324101/1324101  187s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 194 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4323, 5763, 0, 7327]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4323, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4323, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 19 mins 9.6 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  59s /     6s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 6.9 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 10/10  38s /     4s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20170731 - 0.0059\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0151)\n",
      "None.\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20170731\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5763, 0, 7327)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20170731\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5763, 0, 7327)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20170731\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5763, 0, 7327)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20170731\n",
      "time used: 00 mins 44.1 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: []\n",
      "--------------------------------------------------\n",
      "dates from input file: 10\n",
      "['20170613', '20170625', '20170707', '20170731', '20170812', '20170824', '20170905', '20170917', '20170929', '20171011']\n",
      "--------------------------------------------------\n",
      "using all dates to calculate the time function\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5\n",
      "split along y dimension (5763) into 2 boxes\n",
      "    with each box up to 2882 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 2 --------------\n",
      "box width:  7327\n",
      "box length: 2882\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13261046 out of 21116414 (62.8%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 2 --------------\n",
      "box width:  7327\n",
      "box length: 2881\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13060224 out of 21109087 (61.9%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5.\n",
      "time used: 00 mins 18.7 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7327, 5763)\n",
      "subset coverage in y/x: (0, 0, 7327, 5763)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7327/5763\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.26, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 02 mins 32.9 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_uncorrected\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 96 mins 39.5 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "working on AT137, 2018\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/2018_SenAT137.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-07-07 19:34:47.545272--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: 2018_SenAT137\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/2018_SenAT137.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*unw_phase_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy 2018_SenAT137.txt    to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg to inputs   directory for backup.\n",
      "copy 2018_SenAT137.txt    to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/2018_SenAT137.txt --project 2018_SenAT137\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*unw_phase_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3_app/AT137/2018/S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9/S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3_app/AT137/2018/S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9/S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3_app/AT137/2018/S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9/S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5767, 7331) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5767, 7331) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5767, 7331) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5767, 7331) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*unw_phase_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*corr_clipped.tif\n",
      "number of unwrapPhase     : 40\n",
      "number of coherence       : 40\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (40, 5767, 7331) with compression = None\n",
      "[==================================================] 20180924_20181006  217s /     4s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (40, 5767, 7331) with compression = None\n",
      "[==================================================] 20180924_20181006  204s /     4s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (40, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (40,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (40,)\n",
      "add extra metadata: {'PROJECT_NAME': '2018_SenAT137', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 08 mins 13.8 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file 2018_SenAT137.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file 2018_SenAT137.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 40/40   43s /     0s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 10\n",
      "number of interferograms: 40\n",
      "shift all perp baseline by 45.84169006347656 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 40\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 193.61 m\n",
      "max temporal      baseline: 96.0 days\n",
      "showing coherence\n",
      "data range: [0.6391925, 0.93341994]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 40/40   46s /     0s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/maskConnComp.h5\n",
      "time used: 00 mins 49.2 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5767/5767   31s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/avgSpatialCoh.h5\n",
      "time used: 00 mins 40.2 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5767/5767   32s /     6s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (1176, 5758)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5\n",
      "{'REF_Y': '1176', 'REF_X': '5758', 'REF_LAT': '4840620.0', 'REF_LON': '729300.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5767/5767   36s /     7s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/avgPhaseVelocity.h5\n",
      "time used: 00 mins 46.6 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 40\n",
      "number of triplets: 90\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (320, 7331), 19 blocks in total\n",
      "reference pixel in y/x: (1176, 5758) from dataset: unwrapPhase\n",
      "[==================================================] line 5760 / 5767  102s /     5s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/numTriNonzeroIntAmbiguity.png\n",
      "time used: 01 mins 48.0 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (1176, 5758) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 40\n",
      "number of acquisitions  : 10\n",
      "number of lines   : 5767\n",
      "number of columns : 7331\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (10, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5767 lines into 6 patches for processing\n",
      "    with each patch up to 970 lines\n",
      "\n",
      "------- processing patch 1 out of 6 --------------\n",
      "box width:  7331\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 970]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 970]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 970]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 970]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 970]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 970]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 0, 3666, 970] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 0, 1222, 970] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 0, 6110, 970] * 40 ...\n",
      "reading coherence in [1222, 0, 2444, 970] * 40 ...\n",
      "reading coherence in [6110, 0, 7331, 970] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 0, 4888, 970] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 0, 2444, 970] * 40 ...\n",
      "reading unwrapPhase in [2444, 0, 3666, 970] * 40 ...\n",
      "reading unwrapPhase in [4888, 0, 6110, 970] * 40 ...\n",
      "reading unwrapPhase in [0, 0, 1222, 970] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 0, 7331, 970] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 0, 4888, 970] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 205622 out of 1184370 (17.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 353261 out of 1185340 (29.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]number of pixels to invert: 557852 out of 1185340 (47.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 19618 out of 1185340 (1.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 509686 out of 1185340 (43.0%)\n",
      "number of pixels to invert: 0 out of 1185340 (0.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[=>                       3%                       ] 600/19618 pixels    0s /     6s\n",
      "FUTURE #1 complete. Time used: 13 seconds\n",
      "[==================================================] 19618/19618 pixels     7s /   178s\n",
      "[==>                      6%                       ] 20800/353261 pixels    7s /   121sconverting LOS phase unit from radian to meter\n",
      "[=>                       4%                       ] 20200/557852 pixels    7s /   185s\n",
      "FUTURE #2 complete. Time used: 21 seconds\n",
      "[==================================================] 205622/205622 pixels   76s /   114s\n",
      "[=================>      37%                       ] 206600/557852 pixels   76s /   130sconverting LOS phase unit from radian to meter\n",
      "[=================>      37%                       ] 206800/557852 pixels   76s /   130s\n",
      "FUTURE #3 complete. Time used: 90 seconds\n",
      "[==================================================] 353261/353261 pixels  117s /    69s\n",
      "[======================= 69% =====>                ] 350600/509686 pixels  117s /    52sconverting LOS phase unit from radian to meter\n",
      "[======================= 69% =====>                ] 350800/509686 pixels  117s /    52s\n",
      "FUTURE #4 complete. Time used: 131 seconds\n",
      "[==================================================] 509686/509686 pixels  159s /    13s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 92% =================>    ] 512400/557852 pixels  159s /    13s\n",
      "FUTURE #5 complete. Time used: 172 seconds\n",
      "[==================================================] 557852/557852 pixels  168s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 183 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 970, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 970, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 970, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 03 mins 7.9 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 6 --------------\n",
      "box width:  7331\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 970, 1222, 1940]\n",
      "submit a job to the worker for sub box 1: [1222, 970, 2444, 1940]\n",
      "submit a job to the worker for sub box 2: [2444, 970, 3666, 1940]\n",
      "submit a job to the worker for sub box 3: [3666, 970, 4888, 1940]\n",
      "submit a job to the worker for sub box 4: [4888, 970, 6110, 1940]\n",
      "submit a job to the worker for sub box 5: [6110, 970, 7331, 1940]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 970, 1222, 1940] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 970, 4888, 1940] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 970, 7331, 1940] * 40 ...\n",
      "reading coherence in [2444, 970, 3666, 1940] * 40 ...\n",
      "reading coherence in [4888, 970, 6110, 1940] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 970, 2444, 1940] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 970, 3666, 1940] * 40 ...\n",
      "reading unwrapPhase in [1222, 970, 2444, 1940] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 970, 6110, 1940] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 970, 4888, 1940] * 40 ...\n",
      "reading unwrapPhase in [6110, 970, 7331, 1940] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 970, 1222, 1940] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 489853 out of 1184370 (41.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 602815 out of 1185340 (50.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1049118 out of 1185340 (88.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1183898 out of 1185340 (99.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 489853/489853 pixels   230s /   332s\n",
      "[===================>    41%                       ] 487600/1185340 pixels  230s /   332sconverting LOS phase unit from radian to meter\n",
      "[======================= 47%                       ] 489200/1049118 pixels  231s /   260s\n",
      "FUTURE #1 complete. Time used: 244 seconds\n",
      "[==================================================] 602815/602815 pixels   270s /   204s\n",
      "[======================= 50%                       ] 587200/1185340 pixels  270s /   270sconverting LOS phase unit from radian to meter\n",
      "[======================= 50%                       ] 587400/1185340 pixels  271s /   271s\n",
      "FUTURE #2 complete. Time used: 284 seconds\n",
      "[==================================================] 1049118/1049118 pixels  426s /    63s\n",
      "[======================= 89% ===============>      ] 1053200/1183898 pixels  426s /    52sconverting LOS phase unit from radian to meter\n",
      "[======================= 88% ===============>      ] 1048600/1185340 pixels  426s /    58s\n",
      "FUTURE #3 complete. Time used: 440 seconds\n",
      "[==================================================] 1183898/1183898 pixels  463s /     9s\n",
      "[==================================================] 1176400/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 1162200/1185340 pixels  464s /     9s\n",
      "FUTURE #4 complete. Time used: 477 seconds\n",
      "[==================================================] 1185340/1185340 pixels  465s /     9s\n",
      "[==================================================] 1170600/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1170800/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 480 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 484 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 970, 1940, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [970, 1940, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [970, 1940, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 11 mins 15.9 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 6 --------------\n",
      "box width:  7331\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1940, 1222, 2910]\n",
      "submit a job to the worker for sub box 1: [1222, 1940, 2444, 2910]\n",
      "submit a job to the worker for sub box 2: [2444, 1940, 3666, 2910]\n",
      "submit a job to the worker for sub box 3: [3666, 1940, 4888, 2910]\n",
      "submit a job to the worker for sub box 4: [4888, 1940, 6110, 2910]\n",
      "submit a job to the worker for sub box 5: [6110, 1940, 7331, 2910]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 1940, 6110, 2910] * 40 ...\n",
      "reading coherence in [3666, 1940, 4888, 2910] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 1940, 1222, 2910] * 40 ...\n",
      "reading coherence in [6110, 1940, 7331, 2910] * 40 ...\n",
      "reading coherence in [1222, 1940, 2444, 2910] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 1940, 3666, 2910] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 1940, 3666, 2910] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 1940, 4888, 2910] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 1940, 2444, 2910] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 1940, 6110, 2910] * 40 ...\n",
      "reading unwrapPhase in [0, 1940, 1222, 2910] * 40 ...\n",
      "reading unwrapPhase in [6110, 1940, 7331, 2910] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 764874 out of 1185340 (64.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 673782 out of 1184370 (56.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1126798 out of 1185340 (95.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 673782/673782 pixels   308s /   232s\n",
      "[======================= 86% ==============>       ] 660400/764874 pixels  308s /    50sconverting LOS phase unit from radian to meter\n",
      "[======================= 57%                       ] 673800/1185340 pixels  308s /   232s\n",
      "FUTURE #1 complete. Time used: 324 seconds\n",
      "[==================================================] 764874/764874 pixels   348s /   187s\n",
      "[======================= 66% ====>                 ] 779600/1185340 pixels  348s /   179sconverting LOS phase unit from radian to meter\n",
      "[======================= 65% ===>                  ] 772600/1185340 pixels  348s /   187s\n",
      "FUTURE #2 complete. Time used: 364 seconds\n",
      "[==================================================] 566914/566914 pixels   263s /   284s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 64% ===>                  ] 555200/864675 pixels  263s /   147ss\n",
      "FUTURE #1 complete. Time used: 277 seconds\n",
      "[==================================================] 1185340/1185340 pixels  487s /     9s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 1156200/1185340 pixels  487s /     9s\n",
      "FUTURE #3 complete. Time used: 501 seconds\n",
      "[==================================================] 1185340/1185340 pixels  489s /     9s\n",
      "[======================= 98% ====================> ] 1161800/1185340 pixels  489s /     9sconverting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 1162000/1185340 pixels  489s /     9s\n",
      "FUTURE #4 complete. Time used: 503 seconds\n",
      "[==================================================] 1185340/1185340 pixels  490s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1179200/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 508 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 509 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2910, 3880, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [2910, 3880, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [2910, 3880, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 28 mins 17.2 secs.\n",
      "\n",
      "\n",
      "------- processing patch 5 out of 6 --------------\n",
      "box width:  7331\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 3880, 1222, 4850]\n",
      "submit a job to the worker for sub box 1: [1222, 3880, 2444, 4850]\n",
      "submit a job to the worker for sub box 2: [2444, 3880, 3666, 4850]\n",
      "submit a job to the worker for sub box 3: [3666, 3880, 4888, 4850]\n",
      "submit a job to the worker for sub box 4: [4888, 3880, 6110, 4850]\n",
      "submit a job to the worker for sub box 5: [6110, 3880, 7331, 4850]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 3880, 3666, 4850] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 3880, 2444, 4850] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 3880, 6110, 4850] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 3880, 1222, 4850] * 40 ...\n",
      "reading coherence in [3666, 3880, 4888, 4850] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 3880, 7331, 4850] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 3880, 6110, 4850] * 40 ...\n",
      "reading unwrapPhase in [2444, 3880, 3666, 4850] * 40 ...\n",
      "reading unwrapPhase in [0, 3880, 1222, 4850] * 40 ...\n",
      "reading unwrapPhase in [1222, 3880, 2444, 4850] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 3880, 4888, 4850] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 3880, 7331, 4850] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 363007 out of 1185340 (30.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1051061 out of 1185340 (88.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 764449 out of 1184370 (64.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1078107 out of 1185340 (91.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 363007/363007 pixelss  171s /   333s \n",
      "[===============>        31%                       ] 362200/1185340 pixels  171s /   382sconverting LOS phase unit from radian to meter\n",
      "[==============>         30%                       ] 359400/1185340 pixels  171s /   400s\n",
      "FUTURE #1 complete. Time used: 186 seconds\n",
      "[==================================================] 1051061/1051061 pixels  431s /    13s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 1043400/1078107 pixels  431s /    13s\n",
      "FUTURE #3 complete. Time used: 446 seconds\n",
      "[==================================================] 1078107/1078107 pixels  442s /    43s\n",
      "[======================= 92% =================>    ] 1091200/1185340 pixels  442s /    38sconverting LOS phase unit from radian to meter\n",
      "[======================= 91% =================>    ] 1076400/1185340 pixels  442s /    43s\n",
      "FUTURE #4 complete. Time used: 457 seconds\n",
      "[==================================================] 1185340/1185340 pixels  466s /     9s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1169000/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 481 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 485 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 3880, 4850, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [3880, 4850, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [3880, 4850, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 36 mins 27.5 secs.\n",
      "\n",
      "\n",
      "------- processing patch 6 out of 6 --------------\n",
      "box width:  7331\n",
      "box length: 917\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4850, 1222, 5767]\n",
      "submit a job to the worker for sub box 1: [1222, 4850, 2444, 5767]\n",
      "submit a job to the worker for sub box 2: [2444, 4850, 3666, 5767]\n",
      "submit a job to the worker for sub box 3: [3666, 4850, 4888, 5767]\n",
      "submit a job to the worker for sub box 4: [4888, 4850, 6110, 5767]\n",
      "submit a job to the worker for sub box 5: [6110, 4850, 7331, 5767]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 4850, 7331, 5767] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 4850, 2444, 5767] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 4850, 1222, 5767] * 40 ...\n",
      "reading coherence in [2444, 4850, 3666, 5767] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 4850, 4888, 5767] * 40 ...\n",
      "reading coherence in [4888, 4850, 6110, 5767] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 4850, 7331, 5767] * 40 ...\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 4850, 3666, 5767] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 4850, 4888, 5767] * 40 ...\n",
      "reading unwrapPhase in [0, 4850, 1222, 5767] * 40 ...\n",
      "reading unwrapPhase in [1222, 4850, 2444, 5767] * 40 ...\n",
      "reading unwrapPhase in [4888, 4850, 6110, 5767] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 0 out of 1119657 (0.0%)\n",
      "number of pixels to invert: 1847 out of 1120574 (0.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 157432 out of 1120574 (14.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "\n",
      "FUTURE #1 complete. Time used: 13 seconds\n",
      "number of pixels to invert: 301435 out of 1120574 (26.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 689159 out of 1120574 (61.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[===============>        32%                       ] 600/1847 pixels    0s /     0snumber of pixels to invert: 3266 out of 1120574 (0.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 1847/1847 pixels    0s /     0s\n",
      "[===============>        31%                       ] 1000/3266 pixels    0s /     0sconverting LOS phase unit from radian to meter\n",
      "[>                                                 ]\n",
      "FUTURE #2 complete. Time used: 13 seconds\n",
      "[==================================================] 3266/3266 pixels    1s /     0s3s\n",
      "converting LOS phase unit from radian to meter\n",
      "[>                                                 ] 3600/157432 pixels    1s /    66s\n",
      "FUTURE #3 complete. Time used: 14 seconds\n",
      "[==================================================] 157432/157432 pixels   48s /    46s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 51%                       ] 153600/301435 pixels   48s /    46s\n",
      "FUTURE #4 complete. Time used: 61 seconds\n",
      "[==================================================] 301435/301435 pixels   85s /   118s\n",
      "converting LOS phase unit from radian to meter\n",
      "[====================>   42%                       ] 290200/689159 pixels   85s /   118s\n",
      "FUTURE #5 complete. Time used: 98 seconds\n",
      "[==================================================] 689159/689159 pixels  170s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 185 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4850, 5767, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4850, 5767, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4850, 5767, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 39 mins 37.3 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (1176, 5758)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 40\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 39 mins 37.4 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/maskTempCoh.h5\n",
      "time used: 00 mins 1.4 secs.\n",
      "number of reliable pixels: 24099877\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  54s /     6s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 1.8 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 1442]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 1442]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 1442]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 1442]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 1442]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 1442]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 412982 out of 1760682 (23.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 927368 out of 1762124 (52.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 457173 out of 1762124 (25.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1131733 out of 1762124 (64.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 139306 out of 1762124 (7.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1082861 out of 1762124 (61.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 139306/139306   37s /    73ss\n",
      "[=====>                  13%                       ] 146000/1131733   38s /   256s\n",
      "FUTURE #1 complete. Time used: 42 seconds\n",
      "[==================================================] 412982/412982    87s /   149s\n",
      "[===================>    39%                       ] 422000/1082861   88s /   138s\n",
      "FUTURE #2 complete. Time used: 92 seconds\n",
      "[==================================================] 457173/457173    93s /   140s\n",
      "[====================>   42%                       ] 458000/1082861   94s /   130s\n",
      "FUTURE #3 complete. Time used: 98 seconds\n",
      "[==================================================] 927368/927368   163s /    31s\n",
      "[======================= 87% ===============>      ] 940000/1082861  163s /    24s\n",
      "FUTURE #4 complete. Time used: 167 seconds\n",
      "[==================================================] 1082861/1082861  180s /     5s\n",
      "[======================= 97% ===================>  ] 1096000/1131733  181s /     5s\n",
      "FUTURE #5 complete. Time used: 185 seconds\n",
      "[==================================================] 1131733/1131733  182s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 188 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1442, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1442, 1222, 2884]\n",
      "submit a job to the worker for sub box 1: [1222, 1442, 2444, 2884]\n",
      "submit a job to the worker for sub box 2: [2444, 1442, 3666, 2884]\n",
      "submit a job to the worker for sub box 3: [3666, 1442, 4888, 2884]\n",
      "submit a job to the worker for sub box 4: [4888, 1442, 6110, 2884]\n",
      "submit a job to the worker for sub box 5: [6110, 1442, 7331, 2884]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1201129 out of 1762124 (68.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1702141 out of 1762124 (96.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 923535 out of 1760682 (52.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 923535/923535   208s /   192s\n",
      "[======================= 78% ==========>           ] 938000/1201129  209s /    59s\n",
      "FUTURE #1 complete. Time used: 213 seconds\n",
      "[==================================================] 1201129/1201129  259s /   133s\n",
      "[======================= 67% =====>                ] 1172000/1762124  259s /   127s\n",
      "FUTURE #2 complete. Time used: 263 seconds\n",
      "[==================================================] 1702141/1702141  344s /    18s\n",
      "[======================= 96% ===================>  ] 1690000/1762124  344s /    14s\n",
      "FUTURE #3 complete. Time used: 348 seconds\n",
      "[==================================================] 1762124/1762124  352s /     7s\n",
      "[==================================================] 1748000/1762124\n",
      "FUTURE #4 complete. Time used: 357 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #5 complete. Time used: 359 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #6 complete. Time used: 360 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1442, 2884, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2884, 1222, 4326]\n",
      "submit a job to the worker for sub box 1: [1222, 2884, 2444, 4326]\n",
      "submit a job to the worker for sub box 2: [2444, 2884, 3666, 4326]\n",
      "submit a job to the worker for sub box 3: [3666, 2884, 4888, 4326]\n",
      "submit a job to the worker for sub box 4: [4888, 2884, 6110, 4326]\n",
      "submit a job to the worker for sub box 5: [6110, 2884, 7331, 4326]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1339638 out of 1760682 (76.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 761716 out of 1762124 (43.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 761716/761716   197s /   251s\n",
      "[=====================>  44%                       ] 778000/1762124  198s /   252s\n",
      "FUTURE #1 complete. Time used: 202 seconds\n",
      "[==================================================] 1339638/1339638  306s /    96s\n",
      "[======================= 76% =========>            ] 1334000/1762124  306s /    96s\n",
      "FUTURE #2 complete. Time used: 311 seconds\n",
      "[==================================================] 1762124/1762124  378s /     7s\n",
      "[======================= 98% ====================> ] 1730000/1762124  379s /     7s\n",
      "FUTURE #3 complete. Time used: 383 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1738000/1762124  380s /     7s\n",
      "FUTURE #4 complete. Time used: 385 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1756000/1762124\n",
      "FUTURE #5 complete. Time used: 388 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #6 complete. Time used: 388 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2884, 4326, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4326, 1222, 5767]\n",
      "submit a job to the worker for sub box 1: [1222, 4326, 2444, 5767]\n",
      "submit a job to the worker for sub box 2: [2444, 4326, 3666, 5767]\n",
      "submit a job to the worker for sub box 3: [3666, 4326, 4888, 5767]\n",
      "submit a job to the worker for sub box 4: [4888, 4326, 6110, 5767]\n",
      "submit a job to the worker for sub box 5: [6110, 4326, 7331, 5767]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 329005 out of 1760902 (18.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 299007 out of 1759461 (17.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1326530 out of 1760902 (75.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 503311 out of 1760902 (28.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 937841 out of 1760902 (53.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 532592 out of 1760902 (30.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 299007/299007   69s /   148ss\n",
      "[==========>             22%                       ] 298000/1326530   70s /   249s\n",
      "FUTURE #1 complete. Time used: 74 seconds\n",
      "[==================================================] 329005/329005   76s /   142ss\n",
      "[=================>      35%                       ] 330000/937841   77s /   143ss\n",
      "FUTURE #2 complete. Time used: 81 seconds\n",
      "[==================================================] 503311/503311  104s /     6ss\n",
      "[======================= 94% ==================>   ] 500000/532592  104s /     6ss\n",
      "FUTURE #3 complete. Time used: 109 seconds\n",
      "[==================================================] 532592/532592   110s /   165s\n",
      "[======================= 57%                       ] 534000/937841  110s /    83s\n",
      "FUTURE #4 complete. Time used: 114 seconds\n",
      "[==================================================] 937841/937841   158s /    67s\n",
      "[======================= 70% ======>               ] 930000/1326530  158s /    68s\n",
      "FUTURE #5 complete. Time used: 162 seconds\n",
      "[==================================================] 1326530/1326530  195s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 201 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4326, 5767, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4326, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4326, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 19 mins 20.9 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  62s /     6s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 10.2 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 10/10  38s /     4s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20180608 - 0.0039\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0156)\n",
      "20180726 - 0.0173\n",
      "save date(s) to file: exclude_date.txt\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20180608\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries.h5\n",
      "input refDate is the same as the existing REF_DATE.\n",
      "Nothing to be done.\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp.h5\n",
      "input refDate is the same as the existing REF_DATE.\n",
      "Nothing to be done.\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5\n",
      "input refDate is the same as the existing REF_DATE.\n",
      "Nothing to be done.\n",
      "time used: 00 mins 3.3 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: ['20180726']\n",
      "--------------------------------------------------\n",
      "dates from input file: 10\n",
      "['20180608', '20180702', '20180714', '20180726', '20180807', '20180819', '20180831', '20180912', '20180924', '20181006']\n",
      "--------------------------------------------------\n",
      "dates used to estimate the time function: 9\n",
      "['20180608', '20180702', '20180714', '20180807', '20180819', '20180831', '20180912', '20180924', '20181006']\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5\n",
      "split along y dimension (5767) into 2 boxes\n",
      "    with each box up to 2884 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 2 --------------\n",
      "box width:  7331\n",
      "box length: 2884\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13264601 out of 21142604 (62.7%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 2 --------------\n",
      "box width:  7331\n",
      "box length: 2883\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13078136 out of 21135273 (61.9%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [2884, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [2884, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [2884, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [2884, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [2884, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5.\n",
      "time used: 00 mins 19.4 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7331, 5767)\n",
      "subset coverage in y/x: (0, 0, 7331, 5767)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7331/5767\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.25, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 02 mins 25.0 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_uncorrected\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 79 mins 15.1 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "working on AT137, 2019\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/2019_SenAT137.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-07-07 21:52:25.929305--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: 2019_SenAT137\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/2019_SenAT137.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*unw_phase_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy 2019_SenAT137.txt    to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg to inputs   directory for backup.\n",
      "copy 2019_SenAT137.txt    to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/2019_SenAT137.txt --project 2019_SenAT137\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*unw_phase_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3_app/AT137/2019/S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D/S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3_app/AT137/2019/S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D/S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3_app/AT137/2019/S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D/S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5767, 7331) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5767, 7331) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5767, 7331) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5767, 7331) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*unw_phase_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*corr_clipped.tif\n",
      "number of unwrapPhase     : 66\n",
      "number of coherence       : 66\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (66, 5767, 7331) with compression = None\n",
      "[==================================================] 20191001_20191013  383s /     7s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (66, 5767, 7331) with compression = None\n",
      "[==================================================] 20191001_20191013  379s /     7s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (66, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (66,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (66,)\n",
      "add extra metadata: {'PROJECT_NAME': '2019_SenAT137', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 14 mins 15.1 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file 2019_SenAT137.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file 2019_SenAT137.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 66/66   73s /     1s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 12\n",
      "number of interferograms: 66\n",
      "shift all perp baseline by -12.236592292785645 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 66\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 228.22 m\n",
      "max temporal      baseline: 132.0 days\n",
      "showing coherence\n",
      "data range: [0.51316994, 0.8840532]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 66/66   76s /     1s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/maskConnComp.h5\n",
      "time used: 01 mins 19.3 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5767/5767 1254s /   155s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/avgSpatialCoh.h5\n",
      "time used: 21 mins 4.2 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5767/5767   57s /     7s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (5205, 1643)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5\n",
      "{'REF_Y': '5205', 'REF_X': '1643', 'REF_LAT': '4679460.0', 'REF_LON': '564700.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5767/5767   66s /     8s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/avgPhaseVelocity.h5\n",
      "time used: 01 mins 17.8 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 66\n",
      "number of triplets: 220\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (140, 7331), 42 blocks in total\n",
      "reference pixel in y/x: (5205, 1643) from dataset: unwrapPhase\n",
      "[==================================================] line 5740 / 5767  216s /     4s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/numTriNonzeroIntAmbiguity.png\n",
      "time used: 03 mins 43.6 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (5205, 1643) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 66\n",
      "number of acquisitions  : 12\n",
      "number of lines   : 5767\n",
      "number of columns : 7331\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (12,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (12,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (12, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5767 lines into 9 patches for processing\n",
      "    with each patch up to 650 lines\n",
      "\n",
      "------- processing patch 1 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 650\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 650]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 650]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 650]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 650]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 650]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 650]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 0, 6110, 650] * 66 ...\n",
      "reading coherence in [1222, 0, 2444, 650] * 66 ...\n",
      "reading coherence in [0, 0, 1222, 650] * 66 ...\n",
      "reading coherence in [3666, 0, 4888, 650] * 66 ...\n",
      "reading coherence in [2444, 0, 3666, 650] * 66 ...\n",
      "reading coherence in [6110, 0, 7331, 650] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [4888, 0, 6110, 650] * 66 ...\n",
      "reading unwrapPhase in [6110, 0, 7331, 650] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [0, 0, 1222, 650] * 66 ...\n",
      "reading unwrapPhase in [2444, 0, 3666, 650] * 66 ...\n",
      "reading unwrapPhase in [1222, 0, 2444, 650] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [3666, 0, 4888, 650] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "use input reference value\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 86909 out of 793650 (11.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 0 out of 794300 (0.0%)\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]number of pixels to invert: 0 out of 794300 (0.0%)\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]number of pixels to invert: 19786 out of 794300 (2.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "\n",
      "FUTURE #1 complete. Time used: 13 seconds\n",
      "[>                                                 ]number of pixels to invert: 166246 out of 794300 (20.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "\n",
      "FUTURE #2 complete. Time used: 13 seconds\n",
      "[>                                                 ]number of pixels to invert: 128547 out of 794300 (16.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 19786/19786 pixels    6s /    20ss\n",
      "[=====>                  12%                       ] 19800/166246 pixels    6s /    44sconverting LOS phase unit from radian to meter\n",
      "[=======>                16%                       ] 20000/128547 pixels    5s /    31s\n",
      "FUTURE #3 complete. Time used: 19 seconds\n",
      "[==================================================] 86909/86909 pixels    22s /    22s\n",
      "[======================= 64% ===>                  ] 82800/128547 pixels   22s /    12sconverting LOS phase unit from radian to meter\n",
      "[======================= 65% ===>                  ] 83200/128547 pixels   22s /    12s\n",
      "FUTURE #4 complete. Time used: 36 seconds\n",
      "[==================================================] 128547/128547 pixels   33s /    10s\n",
      "[======================= 78% ==========>           ] 129000/166246 pixels   33s /     9sconverting LOS phase unit from radian to meter\n",
      "[======================= 78% ==========>           ] 129200/166246 pixels   33s /     9s\n",
      "FUTURE #5 complete. Time used: 47 seconds\n",
      "[==================================================] 166246/166246 pixels   41s /     0s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 55 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 0, 650, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 650, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 650, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 01 mins 0.6 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 650\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 650, 1222, 1300]\n",
      "submit a job to the worker for sub box 1: [1222, 650, 2444, 1300]\n",
      "submit a job to the worker for sub box 2: [2444, 650, 3666, 1300]\n",
      "submit a job to the worker for sub box 3: [3666, 650, 4888, 1300]\n",
      "submit a job to the worker for sub box 4: [4888, 650, 6110, 1300]\n",
      "submit a job to the worker for sub box 5: [6110, 650, 7331, 1300]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 650, 2444, 1300] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 650, 1222, 1300] * 66 ...\n",
      "reading coherence in [2444, 650, 3666, 1300] * 66 ...\n",
      "reading coherence in [6110, 650, 7331, 1300] * 66 ...\n",
      "reading coherence in [4888, 650, 6110, 1300] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 650, 4888, 1300] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1222, 650, 2444, 1300] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [2444, 650, 3666, 1300] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [0, 650, 1222, 1300] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [4888, 650, 6110, 1300] * 66 ...\n",
      "reading unwrapPhase in [6110, 650, 7331, 1300] * 66 ...\n",
      "reading unwrapPhase in [3666, 650, 4888, 1300] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 25518 out of 794300 (3.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 261515 out of 793650 (33.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 286799 out of 794300 (36.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                        2%                       ] 600/25518 pixels    0s /    11snumber of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 736736 out of 794300 (92.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 784183 out of 794300 (98.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 25518/25518 pixels    14s /   127s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=>                       3%                       ] 25200/784183 pixels   14s /   456s\n",
      "FUTURE #1 complete. Time used: 29 seconds\n",
      "[==================================================] 261515/261515 pixels  110s /   214s\n",
      "converting LOS phase unit from radian to meter\n",
      "[================>       34%                       ] 252600/736736 pixels  110s /   215s\n",
      "FUTURE #2 complete. Time used: 126 seconds\n",
      "[==================================================] 286799/286799 pixels  125s /   196s\n",
      "[===================>    39%                       ] 307600/794300 pixels  125s /   196sconverting LOS phase unit from radian to meter\n",
      "[===================>    41%                       ] 301200/736736 pixels  125s /   180s\n",
      "FUTURE #3 complete. Time used: 141 seconds\n",
      "[==================================================] 351455/351455 pixels  168s /   223s\n",
      "[=====================>  45%                       ] 360000/794300 pixels  169s /   206sconverting LOS phase unit from radian to meter\n",
      "[=====================>  44%                       ] 353400/794300 pixels  169s /   215s\n",
      "FUTURE #1 complete. Time used: 183 seconds\n",
      "[==================================================] 586268/586268 pixels  281s /    99s\n",
      "[======================= 72% =======>              ] 575000/794300 pixels  281s /   109sconverting LOS phase unit from radian to meter\n",
      "[======================= 75% =========>            ] 597800/792040 pixels  281s /    93s\n",
      "FUTURE #2 complete. Time used: 296 seconds\n",
      "[==================================================] 792040/792040 pixels  339s /    14s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 794300/794300 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 779600/794300 pixels  339s /     6s\n",
      "FUTURE #3 complete. Time used: 354 seconds\n",
      "[======================= 96% ===================>  ] 761400/794300 pixels  339s /    14s\n",
      "FUTURE #4 complete. Time used: 354 seconds\n",
      "[==================================================] 794300/794300 pixels  344s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #5 complete. Time used: 359 seconds\n",
      "[==================================================] 794300/794300 pixels  346s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 364 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 1300, 1950, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [1300, 1950, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [1300, 1950, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 12 mins 6.3 secs.\n",
      "\n",
      "\n",
      "------- processing patch 4 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 650\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1950, 1222, 2600]\n",
      "submit a job to the worker for sub box 1: [1222, 1950, 2444, 2600]\n",
      "submit a job to the worker for sub box 2: [2444, 1950, 3666, 2600]\n",
      "submit a job to the worker for sub box 3: [3666, 1950, 4888, 2600]\n",
      "submit a job to the worker for sub box 4: [4888, 1950, 6110, 2600]\n",
      "submit a job to the worker for sub box 5: [6110, 1950, 7331, 2600]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 1950, 1222, 2600] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 1950, 2444, 2600] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 1950, 7331, 2600] * 66 ...\n",
      "reading coherence in [3666, 1950, 4888, 2600] * 66 ...\n",
      "reading coherence in [4888, 1950, 6110, 2600] * 66 ...\n",
      "reading coherence in [2444, 1950, 3666, 2600] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1222, 1950, 2444, 2600] * 66 ...\n",
      "reading unwrapPhase in [0, 1950, 1222, 2600] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [6110, 1950, 7331, 2600] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [2444, 1950, 3666, 2600] * 66 ...\n",
      "reading unwrapPhase in [3666, 1950, 4888, 2600] * 66 ...\n",
      "reading unwrapPhase in [4888, 1950, 6110, 2600] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 431913 out of 793650 (54.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 532953 out of 794300 (67.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 736577 out of 794300 (92.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 431913/431913 pixels  222s /   197s\n",
      "[======================= 59% =>                    ] 431400/736577 pixels  222s /   154sconverting LOS phase unit from radian to meter\n",
      "[======================= 54%                       ] 432200/794300 pixels  222s /   189s\n",
      "FUTURE #1 complete. Time used: 240 seconds\n",
      "[==================================================] 532953/532953 pixels  261s /   123s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 68% =====>                ] 542400/794300 pixels  261s /   123s\n",
      "FUTURE #2 complete. Time used: 279 seconds\n",
      "[==================================================] 736577/736577 pixels  321s /    24s\n",
      "[======================= 91% =================>    ] 722000/794300 pixels  321s /    31sconverting LOS phase unit from radian to meter\n",
      "[======================= 93% =================>    ] 735000/794300 pixels  321s /    24s\n",
      "FUTURE #3 complete. Time used: 340 seconds\n",
      "[==================================================] 794300/794300 pixels  345s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 781000/794300 pixels  345s /     7s\n",
      "FUTURE #4 complete. Time used: 363 seconds\n",
      "[==================================================] 794300/794300 pixels  346s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 790000/794300 pixels\n",
      "FUTURE #5 complete. Time used: 367 seconds\n",
      "[==================================================] 794300/794300 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 368 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 1950, 2600, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [1950, 2600, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [1950, 2600, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 18 mins 20.3 secs.\n",
      "\n",
      "\n",
      "------- processing patch 5 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 650\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2600, 1222, 3250]\n",
      "submit a job to the worker for sub box 1: [1222, 2600, 2444, 3250]\n",
      "submit a job to the worker for sub box 2: [2444, 2600, 3666, 3250]\n",
      "submit a job to the worker for sub box 3: [3666, 2600, 4888, 3250]\n",
      "submit a job to the worker for sub box 4: [4888, 2600, 6110, 3250]\n",
      "submit a job to the worker for sub box 5: [6110, 2600, 7331, 3250]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 2600, 2444, 3250] * 66 ...\n",
      "reading coherence in [6110, 2600, 7331, 3250] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 2600, 1222, 3250] * 66 ...\n",
      "reading coherence in [2444, 2600, 3666, 3250] * 66 ...\n",
      "reading coherence in [4888, 2600, 6110, 3250] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 2600, 4888, 3250] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1222, 2600, 2444, 3250] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [6110, 2600, 7331, 3250] * 66 ...\n",
      "reading unwrapPhase in [0, 2600, 1222, 3250] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [4888, 2600, 6110, 3250] * 66 ...\n",
      "reading unwrapPhase in [2444, 2600, 3666, 3250] * 66 ...\n",
      "reading unwrapPhase in [3666, 2600, 4888, 3250] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 514734 out of 793650 (64.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 443835 out of 794300 (55.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 602874/602874 pixels  288s /    96s\n",
      "[======================= 76% =========>            ] 600600/794300 pixels  288s /    91sconverting LOS phase unit from radian to meter\n",
      "[======================= 75% =========>            ] 598200/794300 pixels  288s /    96s\n",
      "FUTURE #2 complete. Time used: 304 seconds\n",
      "[==================================================] 794300/794300 pixels  338s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 778000/794300 pixels  338s /     6s\n",
      "FUTURE #3 complete. Time used: 354 seconds\n",
      "[==================================================] 794300/794300 pixels  342s /     6s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 782600/794300 pixels\n",
      "FUTURE #4 complete. Time used: 358 seconds\n",
      "[==================================================] 794300/794300 pixels \n",
      "[==================================================] 788000/794300 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 788200/794300 pixels\n",
      "FUTURE #5 complete. Time used: 360 seconds\n",
      "[==================================================] 794300/794300 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 361 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 3250, 3900, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [3250, 3900, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [3250, 3900, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 30 mins 35.9 secs.\n",
      "\n",
      "\n",
      "------- processing patch 7 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 650\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 3900, 1222, 4550]\n",
      "submit a job to the worker for sub box 1: [1222, 3900, 2444, 4550]\n",
      "submit a job to the worker for sub box 2: [2444, 3900, 3666, 4550]\n",
      "submit a job to the worker for sub box 3: [3666, 3900, 4888, 4550]\n",
      "submit a job to the worker for sub box 4: [4888, 3900, 6110, 4550]\n",
      "submit a job to the worker for sub box 5: [6110, 3900, 7331, 4550]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 3900, 3666, 4550] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 3900, 2444, 4550] * 66 ...\n",
      "reading coherence in [0, 3900, 1222, 4550] * 66 ...\n",
      "reading coherence in [4888, 3900, 6110, 4550] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 3900, 7331, 4550] * 66 ...\n",
      "reading coherence in [3666, 3900, 4888, 4550] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1222, 3900, 2444, 4550] * 66 ...\n",
      "reading unwrapPhase in [4888, 3900, 6110, 4550] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [6110, 3900, 7331, 4550] * 66 ...\n",
      "reading unwrapPhase in [2444, 3900, 3666, 4550] * 66 ...\n",
      "reading unwrapPhase in [0, 3900, 1222, 4550] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [3666, 3900, 4888, 4550] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 257449 out of 794300 (32.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 678245 out of 793650 (85.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 257449/257449 pixels  136s /   276s\n",
      "converting LOS phase unit from radian to meter\n",
      "[===============>        32%                       ] 255800/794300 pixels  136s /   289s\n",
      "FUTURE #1 complete. Time used: 152 seconds\n",
      "[======================= 85% =============>        ] 579000/678245 pixels  280s /    49s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 66915/66915 pixels    17s /    53ss\n",
      "converting LOS phase unit from radian to meter\n",
      "[===========>            25%                       ] 64400/261383 pixels   17s /    53s\n",
      "FUTURE #5 complete. Time used: 31 seconds\n",
      "[==================================================] 261383/261383 pixels   63s /     1s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 77 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 5200, 5767, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [5200, 5767, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [5200, 5767, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 42 mins 38.8 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (5205, 1643)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 66\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 42 mins 38.9 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/maskTempCoh.h5\n",
      "time used: 00 mins 1.8 secs.\n",
      "number of reliable pixels: 20085173\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (12,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (12,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (12, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 12/12   95s /     8s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 43.2 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (12,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (12,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (12, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (12,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (12,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (12, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 1442]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 1442]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 1442]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 1442]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 1442]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 1442]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 138746 out of 1762124 (7.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 456299 out of 1762124 (25.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 411769 out of 1760682 (23.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 927136 out of 1762124 (52.6%)\n",
      "number of pixels to invert: 1130151 out of 1762124 (64.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1082572 out of 1762124 (61.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 138746/138746   29s /    69ss\n",
      "[=====>                  12%                       ] 138000/1130151   30s /   220s\n",
      "FUTURE #1 complete. Time used: 34 seconds\n",
      "[==================================================] 411769/411769    80s /   130s\n",
      "[==================>     38%                       ] 412000/1082572   80s /   131s\n",
      "FUTURE #2 complete. Time used: 84 seconds\n",
      "[==================================================] 456299/456299    87s /   116s\n",
      "[=====================>  43%                       ] 464000/1082572   88s /   116s\n",
      "FUTURE #3 complete. Time used: 92 seconds\n",
      "[==================================================] 927136/927136   143s /    25s\n",
      "[======================= 85% =============>        ] 924000/1082572  143s /    25s\n",
      "FUTURE #4 complete. Time used: 147 seconds\n",
      "[==================================================] 1082572/1082572  161s /     6s\n",
      "[======================= 97% ===================>  ] 1092000/1130151  161s /     5s\n",
      "FUTURE #5 complete. Time used: 165 seconds\n",
      "[==================================================] 1130151/1130151  163s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 169 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1442, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1442, 1222, 2884]\n",
      "submit a job to the worker for sub box 1: [1222, 1442, 2444, 2884]\n",
      "submit a job to the worker for sub box 2: [2444, 1442, 3666, 2884]\n",
      "submit a job to the worker for sub box 3: [3666, 1442, 4888, 2884]\n",
      "submit a job to the worker for sub box 4: [4888, 1442, 6110, 2884]\n",
      "submit a job to the worker for sub box 5: [6110, 1442, 7331, 2884]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1202088 out of 1762124 (68.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1702141 out of 1762124 (96.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 922433 out of 1760682 (52.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 922433/922433   202s /   179s\n",
      "[======================= 52%                       ] 910000/1762124  202s /   187s\n",
      "FUTURE #1 complete. Time used: 207 seconds\n",
      "[==================================================] 1202088/1202088  251s /   123s\n",
      "[======================= 68% =====>                ] 1192000/1762124  251s /   118s\n",
      "FUTURE #2 complete. Time used: 255 seconds\n",
      "[==================================================] 1702141/1702141  328s /    10s\n",
      "[======================= 95% ===================>  ] 1678000/1762124  329s /    17s\n",
      "FUTURE #3 complete. Time used: 333 seconds\n",
      "[==================================================] 1762124/1762124  335s /    10s\n",
      "\n",
      "FUTURE #4 complete. Time used: 340 seconds\n",
      "[==================================================] 1762124/1762124  336s /     6s\n",
      "[======================= 98% ====================> ] 1728000/1762124  336s /     6s\n",
      "FUTURE #5 complete. Time used: 341 seconds\n",
      "[==================================================] 1762124/1762124  337s /     6s\n",
      "\n",
      "FUTURE #6 complete. Time used: 345 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1442, 2884, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2884, 1222, 4326]\n",
      "submit a job to the worker for sub box 1: [1222, 2884, 2444, 4326]\n",
      "submit a job to the worker for sub box 2: [2444, 2884, 3666, 4326]\n",
      "submit a job to the worker for sub box 3: [3666, 2884, 4888, 4326]\n",
      "submit a job to the worker for sub box 4: [4888, 2884, 6110, 4326]\n",
      "submit a job to the worker for sub box 5: [6110, 2884, 7331, 4326]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 762927 out of 1762124 (43.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1338702 out of 1760682 (76.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 762927/762927   166s /   125s\n",
      "[======================= 57%                       ] 764000/1338702  167s /   126s\n",
      "FUTURE #1 complete. Time used: 171 seconds\n",
      "[==================================================] 1338702/1338702  272s /    76s\n",
      "[======================= 78% ==========>           ] 1374000/1762124  273s /    77s\n",
      "FUTURE #2 complete. Time used: 277 seconds\n",
      "[==================================================] 1762124/1762124  328s /     6s\n",
      "[======================= 98% ====================> ] 1728000/1762124  329s /     6s\n",
      "FUTURE #3 complete. Time used: 333 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1754000/1762124  329s /     6s\n",
      "FUTURE #4 complete. Time used: 333 seconds\n",
      "[==================================================] 1762124/1762124  329s /     6s\n",
      "[==================================================] 1740000/1762124\n",
      "FUTURE #5 complete. Time used: 334 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #6 complete. Time used: 337 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2884, 4326, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4326, 1222, 5767]\n",
      "submit a job to the worker for sub box 1: [1222, 4326, 2444, 5767]\n",
      "submit a job to the worker for sub box 2: [2444, 4326, 3666, 5767]\n",
      "submit a job to the worker for sub box 3: [3666, 4326, 4888, 5767]\n",
      "submit a job to the worker for sub box 4: [4888, 4326, 6110, 5767]\n",
      "submit a job to the worker for sub box 5: [6110, 4326, 7331, 5767]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 938155 out of 1760902 (53.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1326655 out of 1760902 (75.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 329751 out of 1760902 (18.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 503386 out of 1760902 (28.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 532711 out of 1760902 (30.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 298867 out of 1759461 (17.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 298867/298867   69s /   154ss\n",
      "[===========>            23%                       ] 310000/1326655   69s /   232s\n",
      "FUTURE #1 complete. Time used: 73 seconds\n",
      "[==================================================] 329751/329751   74s /    45ss\n",
      "[======================= 63% ===>                  ] 334000/532711   74s /    43ss\n",
      "FUTURE #2 complete. Time used: 78 seconds\n",
      "[==================================================] 503386/503386   99s /     5ss\n",
      "[======================= 95% ===================>  ] 508000/532711   99s /     5ss\n",
      "FUTURE #3 complete. Time used: 103 seconds\n",
      "[==================================================] 532711/532711   102s /   154s\n",
      "\n",
      "FUTURE #4 complete. Time used: 107 seconds\n",
      "[==================================================] 938155/938155   151s /    50s\n",
      "[======================= 75% =========>            ] 998000/1326655  151s /    50s\n",
      "FUTURE #5 complete. Time used: 155 seconds\n",
      "[==================================================] 1326655/1326655  178s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 185 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4326, 5767, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 4326, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 4326, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 17 mins 38.8 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (12,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (12,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (12, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 12/12   85s /     7s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 34.0 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 12/12   51s /     4s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20191013 - 0.0063\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0183)\n",
      "None.\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20191013\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 12, 0, 5767, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20191013\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 12, 0, 5767, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20191013\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 12, 0, 5767, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20191013\n",
      "time used: 00 mins 50.4 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: []\n",
      "--------------------------------------------------\n",
      "dates from input file: 12\n",
      "['20190603', '20190615', '20190627', '20190709', '20190721', '20190802', '20190814', '20190826', '20190907', '20190919', '20191001', '20191013']\n",
      "--------------------------------------------------\n",
      "using all dates to calculate the time function\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5\n",
      "split along y dimension (5767) into 3 boxes\n",
      "    with each box up to 1923 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 3 --------------\n",
      "box width:  7331\n",
      "box length: 1923\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 7205454 out of 14097513 (51.1%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 1923, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 1923, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 1923, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 1923, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 1923, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 3 --------------\n",
      "box width:  7331\n",
      "box length: 1923\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 12166810 out of 14097513 (86.3%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [1923, 3846, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [1923, 3846, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [1923, 3846, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [1923, 3846, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [1923, 3846, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "\n",
      "------- processing patch 3 out of 3 --------------\n",
      "box width:  7331\n",
      "box length: 1921\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 6967094 out of 14082851 (49.5%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [3846, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [3846, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [3846, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [3846, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [3846, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5.\n",
      "time used: 00 mins 22.6 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7331, 5767)\n",
      "subset coverage in y/x: (0, 0, 7331, 5767)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7331/5767\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.25, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 03 mins 20.1 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_uncorrected\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 114 mins 4.2 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "working on AT137, 2020\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/2020_SenAT137.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-07-08 00:30:06.748562--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: 2020_SenAT137\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/2020_SenAT137.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*unw_phase_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy 2020_SenAT137.txt    to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg to inputs   directory for backup.\n",
      "copy 2020_SenAT137.txt    to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/2020_SenAT137.txt --project 2020_SenAT137\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*unw_phase_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3_app/AT137/2020/S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0/S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3_app/AT137/2020/S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0/S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3_app/AT137/2020/S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0/S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5765, 7329) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5765, 7329) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5765, 7329) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5765, 7329) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*unw_phase_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*corr_clipped.tif\n",
      "number of unwrapPhase     : 45\n",
      "number of coherence       : 45\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (45, 5765, 7329) with compression = None\n",
      "[==================================================] 20200925_20201007  246s /     5s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (45, 5765, 7329) with compression = None\n",
      "[==================================================] 20200925_20201007  252s /     5s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (45, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (45,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (45,)\n",
      "add extra metadata: {'PROJECT_NAME': '2020_SenAT137', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 09 mins 34.2 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file 2020_SenAT137.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file 2020_SenAT137.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5765, 7329)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 45/45   50s /     1s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 10\n",
      "number of interferograms: 45\n",
      "shift all perp baseline by -36.851009368896484 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 45\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 227.57 m\n",
      "max temporal      baseline: 120.0 days\n",
      "showing coherence\n",
      "data range: [0.622384, 0.9394732]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 45/45   47s /     0s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5765, 7329)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/maskConnComp.h5\n",
      "time used: 00 mins 50.1 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   41s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5765, 7329)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/avgSpatialCoh.h5\n",
      "time used: 00 mins 49.7 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   37s /     6s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (4436, 1579)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5\n",
      "{'REF_Y': '4436', 'REF_X': '1579', 'REF_LAT': '4710140.0', 'REF_LON': '562220.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   43s /     7s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5765, 7329)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/avgPhaseVelocity.h5\n",
      "time used: 00 mins 53.6 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 45\n",
      "number of triplets: 120\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (250, 7329), 24 blocks in total\n",
      "reference pixel in y/x: (4436, 1579) from dataset: unwrapPhase\n",
      "[==================================================] line 5750 / 5765  127s /     5s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5765, 7329)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/numTriNonzeroIntAmbiguity.png\n",
      "time used: 02 mins 14.6 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (4436, 1579) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 45\n",
      "number of acquisitions  : 10\n",
      "number of lines   : 5765\n",
      "number of columns : 7329\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (10, 5765, 7329)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5765 lines into 6 patches for processing\n",
      "    with each patch up to 970 lines\n",
      "\n",
      "------- processing patch 1 out of 6 --------------\n",
      "box width:  7329\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 970]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 970]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 970]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 970]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 970]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7329, 970]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 0, 6110, 970] * 45 ...\n",
      "reading coherence in [6110, 0, 7329, 970] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 0, 1222, 970] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 0, 4888, 970] * 45 ...\n",
      "reading coherence in [2444, 0, 3666, 970] * 45 ...\n",
      "reading coherence in [1222, 0, 2444, 970] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 0, 4888, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 0, 2444, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 0, 6110, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 0, 7329, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 0, 3666, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 0, 1222, 970] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 0 out of 1185340 (0.0%)\n",
      "number of pixels to invert: 205248 out of 1182430 (17.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "\n",
      "FUTURE #1 complete. Time used: 14 seconds\n",
      "[>                                                 ]number of pixels to invert: 20290 out of 1185340 (1.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 356234 out of 1185340 (30.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 560876 out of 1185340 (47.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 512342 out of 1185340 (43.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 20290/20290 pixels     7s /   122s\n",
      "[=>                       4%                       ] 20600/560876 pixels    7s /   186sconverting LOS phase unit from radian to meter\n",
      "[==>                      6%                       ] 20600/356234 pixels    7s /   124s\n",
      "FUTURE #2 complete. Time used: 22 seconds\n",
      "[==================================================] 205248/205248 pixels   79s /    57s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 58% >                     ] 206600/356234 pixels   79s /    57s\n",
      "FUTURE #3 complete. Time used: 93 seconds\n",
      "[==================================================] 356234/356234 pixels  122s /    68s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 64% ===>                  ] 358800/560876 pixels  122s /    68s\n",
      "FUTURE #4 complete. Time used: 137 seconds\n",
      "[==================================================] 512342/512342 pixels  164s /    16s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 91% =================>    ] 508800/560876 pixels  164s /    16s\n",
      "FUTURE #5 complete. Time used: 179 seconds\n",
      "[==================================================] 560876/560876 pixels  174s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 191 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 970, 0, 7329]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 970, 0, 7329]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 970, 0, 7329]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 03 mins 15.6 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 6 --------------\n",
      "box width:  7329\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 970, 1222, 1940]\n",
      "submit a job to the worker for sub box 1: [1222, 970, 2444, 1940]\n",
      "submit a job to the worker for sub box 2: [2444, 970, 3666, 1940]\n",
      "submit a job to the worker for sub box 3: [3666, 970, 4888, 1940]\n",
      "submit a job to the worker for sub box 4: [4888, 970, 6110, 1940]\n",
      "submit a job to the worker for sub box 5: [6110, 970, 7329, 1940]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 970, 2444, 1940] * 45 ...\n",
      "reading coherence in [4888, 970, 6110, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 970, 7329, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 970, 4888, 1940] * 45 ...\n",
      "reading coherence in [0, 970, 1222, 1940] * 45 ...\n",
      "reading coherence in [2444, 970, 3666, 1940] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 970, 2444, 1940] * 45 ...\n",
      "reading unwrapPhase in [3666, 970, 4888, 1940] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 970, 7329, 1940] * 45 ...\n",
      "reading unwrapPhase in [4888, 970, 6110, 1940] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 970, 3666, 1940] * 45 ...\n",
      "reading unwrapPhase in [0, 970, 1222, 1940] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 605815 out of 1185340 (51.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 488215 out of 1182430 (41.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 1183743 out of 1185340 (99.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1051077 out of 1185340 (88.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 488215/488215 pixels   227s /   327s\n",
      "[======================= 79% ===========>          ] 480200/605815 pixels  228s /    60sconverting LOS phase unit from radian to meter\n",
      "[===================>    41%                       ] 488400/1183743 pixels  227s /   328s\n",
      "FUTURE #1 complete. Time used: 243 seconds\n",
      "[==================================================] 605815/605815 pixels   277s /   266s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 52%                       ] 613200/1185340 pixels  277s /   256s\n",
      "FUTURE #2 complete. Time used: 293 seconds\n",
      "[==================================================] 1051077/1051077 pixels  431s /    53s\n",
      "[======================= 91% =================>    ] 1074000/1183743 pixels  431s /    42sconverting LOS phase unit from radian to meter\n",
      "[======================= 90% ================>     ] 1066200/1185340 pixels  431s /    47s\n",
      "FUTURE #3 complete. Time used: 447 seconds\n",
      "[==================================================] 1183743/1183743 pixels  466s /     9s\n",
      "[==================================================] 1177200/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 1161800/1185340 pixels  466s /     9s\n",
      "FUTURE #4 complete. Time used: 481 seconds\n",
      "[==================================================] 1185340/1185340 pixels  468s /     9s\n",
      "[==================================================] 1169600/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1170000/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 484 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 489 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 970, 1940, 0, 7329]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [970, 1940, 0, 7329]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [970, 1940, 0, 7329]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 11 mins 28.6 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 6 --------------\n",
      "box width:  7329\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1940, 1222, 2910]\n",
      "submit a job to the worker for sub box 1: [1222, 1940, 2444, 2910]\n",
      "submit a job to the worker for sub box 2: [2444, 1940, 3666, 2910]\n",
      "submit a job to the worker for sub box 3: [3666, 1940, 4888, 2910]\n",
      "submit a job to the worker for sub box 4: [4888, 1940, 6110, 2910]\n",
      "submit a job to the worker for sub box 5: [6110, 1940, 7329, 2910]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 1940, 2444, 2910] * 45 ...\n",
      "reading coherence in [0, 1940, 1222, 2910] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 1940, 7329, 2910] * 45 ...\n",
      "reading coherence in [3666, 1940, 4888, 2910] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 1940, 3666, 2910] * 45 ...\n",
      "reading coherence in [4888, 1940, 6110, 2910] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 1940, 7329, 2910] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 1940, 3666, 2910] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 1940, 2444, 2910] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 1940, 1222, 2910] * 45 ...\n",
      "reading unwrapPhase in [3666, 1940, 4888, 2910] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 1940, 6110, 2910] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 671927 out of 1182430 (56.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 767020 out of 1185340 (64.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1126954 out of 1185340 (95.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 671927/671927 pixels   309s /   206s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 56%                       ] 666800/1185340 pixels  309s /   243s\n",
      "FUTURE #1 complete. Time used: 326 seconds\n",
      "[==================================================] 767020/767020 pixels   350s /   157s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 69% =====>                ] 783000/1126954 pixels  350s /   157s\n",
      "FUTURE #2 complete. Time used: 367 seconds\n",
      "[==================================================] 1126954/1126954 pixels  466s /    24s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 95% ===================>  ] 1126600/1185340 pixels  466s /    24s\n",
      "FUTURE #3 complete. Time used: 483 seconds\n",
      "[==================================================] 1185340/1185340 pixels  481s /     9s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1175400/1185340 pixels\n",
      "FUTURE #4 complete. Time used: 500 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1176800/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 501 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 502 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1940, 2910, 0, 7329]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [1940, 2910, 0, 7329]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [1940, 2910, 0, 7329]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 19 mins 55.8 secs.\n",
      "\n",
      "\n",
      "------- processing patch 4 out of 6 --------------\n",
      "box width:  7329\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2910, 1222, 3880]\n",
      "submit a job to the worker for sub box 1: [1222, 2910, 2444, 3880]\n",
      "submit a job to the worker for sub box 2: [2444, 2910, 3666, 3880]\n",
      "submit a job to the worker for sub box 3: [3666, 2910, 4888, 3880]\n",
      "submit a job to the worker for sub box 4: [4888, 2910, 6110, 3880]\n",
      "submit a job to the worker for sub box 5: [6110, 2910, 7329, 3880]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 2910, 3666, 3880] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 2910, 1222, 3880] * 45 ...\n",
      "reading coherence in [4888, 2910, 6110, 3880] * 45 ...\n",
      "reading coherence in [6110, 2910, 7329, 3880] * 45 ...\n",
      "reading coherence in [3666, 2910, 4888, 3880] * 45 ...\n",
      "reading coherence in [1222, 2910, 2444, 3880] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 2910, 2444, 3880] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 2910, 6110, 3880] * 45 ...\n",
      "reading unwrapPhase in [6110, 2910, 7329, 3880] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 2910, 1222, 3880] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 2910, 3666, 3880] * 45 ...\n",
      "reading unwrapPhase in [3666, 2910, 4888, 3880] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 569262 out of 1185340 (48.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "number of pixels to invert: 862246 out of 1182430 (72.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 569262/569262 pixels   270s /   281s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 49%                       ] 578800/1185340 pixels  270s /   281s\n",
      "FUTURE #1 complete. Time used: 287 seconds\n",
      "[==================================================] 862246/862246 pixels   381s /   148s\n",
      "[======================= 72% =======>              ] 857400/1185340 pixels  381s /   148sconverting LOS phase unit from radian to meter\n",
      "[======================= 72% =======>              ] 857600/1185340 pixels  381s /   148s\n",
      "FUTURE #2 complete. Time used: 398 seconds\n",
      "[==================================================] 1185340/1185340 pixels  492s /    10s\n",
      "[======================= 98% ====================> ] 1165800/1185340 pixels  492s /    10sconverting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 1145000/1185340 pixels  492s /    15s\n",
      "FUTURE #3 complete. Time used: 509 seconds\n",
      "[==================================================] 1185340/1185340 pixels  494s /    15s\n",
      "[==================================================] 1171600/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1171800/1185340 pixels  494s /    15s\n",
      "FUTURE #4 complete. Time used: 511 seconds\n",
      "[==================================================] 1185340/1185340 pixels  498s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 1164000/1185340 pixels  498s /    10s\n",
      "FUTURE #5 complete. Time used: 515 seconds\n",
      "[==================================================] 1185340/1185340 pixels  499s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 521 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2910, 3880, 0, 7329]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [2910, 3880, 0, 7329]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [2910, 3880, 0, 7329]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 28 mins 42.1 secs.\n",
      "\n",
      "\n",
      "------- processing patch 5 out of 6 --------------\n",
      "box width:  7329\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 3880, 1222, 4850]\n",
      "submit a job to the worker for sub box 1: [1222, 3880, 2444, 4850]\n",
      "submit a job to the worker for sub box 2: [2444, 3880, 3666, 4850]\n",
      "submit a job to the worker for sub box 3: [3666, 3880, 4888, 4850]\n",
      "submit a job to the worker for sub box 4: [4888, 3880, 6110, 4850]\n",
      "submit a job to the worker for sub box 5: [6110, 3880, 7329, 4850]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 3880, 3666, 4850] * 45 ...\n",
      "reading coherence in [1222, 3880, 2444, 4850] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 3880, 6110, 4850] * 45 ...\n",
      "reading coherence in [0, 3880, 1222, 4850] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 3880, 7329, 4850] * 45 ...\n",
      "reading coherence in [3666, 3880, 4888, 4850] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 3880, 2444, 4850] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 3880, 3666, 4850] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 3880, 7329, 4850] * 45 ...\n",
      "reading unwrapPhase in [4888, 3880, 6110, 4850] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 3880, 4888, 4850] * 45 ...\n",
      "reading unwrapPhase in [0, 3880, 1222, 4850] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 365259 out of 1185340 (30.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]number of pixels to invert: 1185339 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 761156 out of 1182430 (64.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1050038 out of 1185340 (88.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 1076432 out of 1185340 (90.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 365259/365259 pixels  167s /   181ss\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 48%                       ] 367400/761156 pixels  167s /   181ss\n",
      "FUTURE #1 complete. Time used: 184 seconds\n",
      "[==================================================] 761156/761156 pixels   319s /   187s\n",
      "[======================= 63% ===>                  ] 745200/1185340 pixels  319s /   187sconverting LOS phase unit from radian to meter\n",
      "[======================= 71% =======>              ] 741600/1050038 pixels  319s /   130s\n",
      "FUTURE #2 complete. Time used: 336 seconds\n",
      "[==================================================] 1050038/1050038 pixels  421s /    17s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 89% ===============>      ] 1049800/1185340 pixels  422s /    52s\n",
      "FUTURE #3 complete. Time used: 438 seconds\n",
      "[==================================================] 1076432/1076432 pixels  433s /    37s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 92% =================>    ] 1092400/1185339 pixels  433s /    37s\n",
      "FUTURE #4 complete. Time used: 449 seconds\n",
      "[==================================================] 1185339/1185339 pixels  453s /     9s\n",
      "[==================================================] 1181000/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1181200/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 474 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 475 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 3880, 4850, 0, 7329]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [3880, 4850, 0, 7329]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [3880, 4850, 0, 7329]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 36 mins 41.7 secs.\n",
      "\n",
      "\n",
      "------- processing patch 6 out of 6 --------------\n",
      "box width:  7329\n",
      "box length: 915\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4850, 1222, 5765]\n",
      "submit a job to the worker for sub box 1: [1222, 4850, 2444, 5765]\n",
      "submit a job to the worker for sub box 2: [2444, 4850, 3666, 5765]\n",
      "submit a job to the worker for sub box 3: [3666, 4850, 4888, 5765]\n",
      "submit a job to the worker for sub box 4: [4888, 4850, 6110, 5765]\n",
      "submit a job to the worker for sub box 5: [6110, 4850, 7329, 5765]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 4850, 3666, 5765] * 45 ...\n",
      "reading coherence in [1222, 4850, 2444, 5765] * 45 ...\n",
      "reading coherence in [3666, 4850, 4888, 5765] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 4850, 6110, 5765] * 45 ...\n",
      "reading coherence in [0, 4850, 1222, 5765] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 4850, 7329, 5765] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 4850, 7329, 5765] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 11 / 12\n",
      "reading unwrapPhase in [2444, 4850, 3666, 5765] * 45 ...\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 4850, 4888, 5765] * 45 ...\n",
      "reading unwrapPhase in [1222, 4850, 2444, 5765] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 4850, 6110, 5765] * 45 ...\n",
      "reading unwrapPhase in [0, 4850, 1222, 5765] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 1689 out of 1118130 (0.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 1115385 (0.0%)\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "[=====>                  12%                       ] 200/1689 pixels    0s /     0s\n",
      "FUTURE #1 complete. Time used: 15 seconds\n",
      "number of pixels to invert: 299304 out of 1118130 (26.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 158810 out of 1118130 (14.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 2979 out of 1118130 (0.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[===========>            24%                       ] 400/1689 pixels    0s /     0sskip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[======================= 47%                       ] 800/1689 pixels    0s /     0snumber of pixels to invert: 687145 out of 1118130 (61.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 1689/1689 pixels    0s /     0s\n",
      "converting LOS phase unit from radian to meter\n",
      "[>                                                 ] 1200/2979 pixels    0s /     0s\n",
      "FUTURE #2 complete. Time used: 16 seconds\n",
      "[==================================================] 2979/2979 pixels    1s /     0s1s\n",
      "[>                        2%                       ] 2600/158810 pixels    1s /    55sconverting LOS phase unit from radian to meter\n",
      "[>                                                 ]\n",
      "FUTURE #3 complete. Time used: 16 seconds\n",
      "[==================================================] 158810/158810 pixels   45s /    40s\n",
      "[===========>            23%                       ] 157600/687145 pixels   44s /   150sconverting LOS phase unit from radian to meter\n",
      "[===========>            23%                       ] 157800/687145 pixels   44s /   150s\n",
      "FUTURE #4 complete. Time used: 60 seconds\n",
      "[==================================================] 299304/299304 pixels   79s /   100s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=====================>  44%                       ] 301000/687145 pixels   79s /   100s\n",
      "FUTURE #5 complete. Time used: 95 seconds\n",
      "[==================================================] 687145/687145 pixels  156s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 174 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4850, 5765, 0, 7329]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4850, 5765, 0, 7329]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4850, 5765, 0, 7329]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 39 mins 40.8 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (4436, 1579)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 45\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 39 mins 40.8 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5765, 7329)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/maskTempCoh.h5\n",
      "time used: 00 mins 1.6 secs.\n",
      "number of reliable pixels: 23572825\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5765, 7329)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  68s /     7s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 17.4 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5765, 7329)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5765, 7329)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7329\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 1442]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 1442]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 1442]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 1442]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 1442]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7329, 1442]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 410907 out of 1757798 (23.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 457172 out of 1762124 (25.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 139269 out of 1762124 (7.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1132767 out of 1762124 (64.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1083931 out of 1762124 (61.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 928138 out of 1762124 (52.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 139269/139269   34s /   197ss\n",
      "[=================>      35%                       ] 142000/410907   35s /    65s\n",
      "FUTURE #1 complete. Time used: 39 seconds\n",
      "[==================================================] 410907/410907    86s /   153s\n",
      "[=================>      37%                       ] 396000/1083931   86s /   147s\n",
      "FUTURE #2 complete. Time used: 90 seconds\n",
      "[==================================================] 457172/457172    93s /   140s\n",
      "[===================>    40%                       ] 452000/1132767   93s /   140s\n",
      "FUTURE #3 complete. Time used: 97 seconds\n",
      "[==================================================] 928138/928138   160s /    32s\n",
      "[======================= 83% =============>        ] 936000/1132767  161s /    33s\n",
      "FUTURE #4 complete. Time used: 165 seconds\n",
      "[==================================================] 1083931/1083931  183s /     3s\n",
      "[==================================================] 1128000/1132767\n",
      "FUTURE #5 complete. Time used: 188 seconds\n",
      "[==================================================] 1132767/1132767 \n",
      "\n",
      "FUTURE #6 complete. Time used: 189 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1442, 0, 7329]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1442, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1442, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7329\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1442, 1222, 2884]\n",
      "submit a job to the worker for sub box 1: [1222, 1442, 2444, 2884]\n",
      "submit a job to the worker for sub box 2: [2444, 1442, 3666, 2884]\n",
      "submit a job to the worker for sub box 3: [3666, 1442, 4888, 2884]\n",
      "submit a job to the worker for sub box 4: [4888, 1442, 6110, 2884]\n",
      "submit a job to the worker for sub box 5: [6110, 1442, 7329, 2884]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1202805 out of 1762124 (68.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1702141 out of 1762124 (96.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 920492 out of 1757798 (52.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 920492/920492   203s /   187s\n",
      "[======================= 52%                       ] 914000/1762124  204s /   188s\n",
      "FUTURE #1 complete. Time used: 208 seconds\n",
      "[==================================================] 1202805/1202805  260s /   116s\n",
      "[======================= 68% =====>                ] 1204000/1762124  260s /   122s\n",
      "FUTURE #2 complete. Time used: 264 seconds\n",
      "[==================================================] 1702141/1702141  338s /    14s\n",
      "[======================= 96% ===================>  ] 1686000/1762124  339s /    14s\n",
      "FUTURE #3 complete. Time used: 342 seconds\n",
      "[==================================================] 1762124/1762124  346s /     7s \n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1750000/1762124\n",
      "FUTURE #4 complete. Time used: 352 seconds\n",
      "[==================================================] 1752000/1762124\n",
      "FUTURE #5 complete. Time used: 352 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #6 complete. Time used: 353 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1442, 2884, 0, 7329]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1442, 2884, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1442, 2884, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7329\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2884, 1222, 4326]\n",
      "submit a job to the worker for sub box 1: [1222, 2884, 2444, 4326]\n",
      "submit a job to the worker for sub box 2: [2444, 2884, 3666, 4326]\n",
      "submit a job to the worker for sub box 3: [3666, 2884, 4888, 4326]\n",
      "submit a job to the worker for sub box 4: [4888, 2884, 6110, 4326]\n",
      "submit a job to the worker for sub box 5: [6110, 2884, 7329, 4326]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 763096 out of 1762124 (43.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1336752 out of 1757798 (76.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 763096/763096   175s /   126s\n",
      "[=====================>  44%                       ] 778000/1762124  175s /   223s\n",
      "FUTURE #1 complete. Time used: 179 seconds\n",
      "[==================================================] 1336752/1336752  280s /    88s\n",
      "[======================= 76% =========>            ] 1344000/1762124  280s /    88s\n",
      "FUTURE #2 complete. Time used: 284 seconds\n",
      "[==================================================] 1762124/1762124  345s /     7s\n",
      "\n",
      "FUTURE #3 complete. Time used: 352 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #4 complete. Time used: 353 seconds\n",
      "\n",
      "FUTURE #5 complete. Time used: 354 seconds\n",
      "\n",
      "FUTURE #6 complete. Time used: 354 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2884, 4326, 0, 7329]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2884, 4326, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2884, 4326, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7329\n",
      "box length: 1439\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4326, 1222, 5765]\n",
      "submit a job to the worker for sub box 1: [1222, 4326, 2444, 5765]\n",
      "submit a job to the worker for sub box 2: [2444, 4326, 3666, 5765]\n",
      "submit a job to the worker for sub box 3: [3666, 4326, 4888, 5765]\n",
      "submit a job to the worker for sub box 4: [4888, 4326, 6110, 5765]\n",
      "submit a job to the worker for sub box 5: [6110, 4326, 7329, 5765]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 295931 out of 1754141 (16.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 500732 out of 1758458 (28.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 330004 out of 1758458 (18.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 934916 out of 1758458 (53.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1323400 out of 1758458 (75.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 529770 out of 1758458 (30.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 295931/295931   69s /    48ss\n",
      "[===========>            23%                       ] 304000/1323400   69s /   233s\n",
      "FUTURE #1 complete. Time used: 73 seconds\n",
      "[==================================================] 330004/330004   75s /    44ss\n",
      "[===========>            25%                       ] 336000/1323400   76s /   228s\n",
      "FUTURE #2 complete. Time used: 80 seconds\n",
      "[==================================================] 500732/500732   101s /   159s\n",
      "[======================= 53%                       ] 500000/934916  101s /    90s\n",
      "FUTURE #3 complete. Time used: 105 seconds\n",
      "[==================================================] 529770/529770  104s /    82ss\n",
      "[===================>    40%                       ] 532000/1323400  104s /   157s\n",
      "FUTURE #4 complete. Time used: 109 seconds\n",
      "[==================================================] 934916/934916   154s /    57s\n",
      "[======================= 73% =======>              ] 964000/1323400  154s /    57s\n",
      "FUTURE #5 complete. Time used: 158 seconds\n",
      "[==================================================] 1323400/1323400  185s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 191 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4326, 5765, 0, 7329]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4326, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4326, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 18 mins 32.3 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5765, 7329)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  65s /     7s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 13.4 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 10/10  40s /     4s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20200820 - 0.0029\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0117)\n",
      "None.\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20200820\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5765, 0, 7329)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20200820\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5765, 0, 7329)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20200820\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5765, 0, 7329)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20200820\n",
      "time used: 00 mins 43.6 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: []\n",
      "--------------------------------------------------\n",
      "dates from input file: 10\n",
      "['20200609', '20200621', '20200715', '20200727', '20200808', '20200820', '20200901', '20200913', '20200925', '20201007']\n",
      "--------------------------------------------------\n",
      "using all dates to calculate the time function\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5\n",
      "split along y dimension (5765) into 2 boxes\n",
      "    with each box up to 2883 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 2 --------------\n",
      "box width:  7329\n",
      "box length: 2883\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13257636 out of 21129507 (62.7%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 2883, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 2883, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 2883, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 2883, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 2883, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 2 --------------\n",
      "box width:  7329\n",
      "box length: 2882\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13069456 out of 21122178 (61.9%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [2883, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [2883, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [2883, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [2883, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [2883, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5.\n",
      "time used: 00 mins 18.0 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7329, 5765)\n",
      "subset coverage in y/x: (0, 0, 7329, 5765)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7329/5765\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.26, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 02 mins 49.5 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_uncorrected\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 82 mins 11.3 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "working on AT137, 2021\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/2021_SenAT137.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-07-08 05:38:28.888996--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: 2021_SenAT137\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/2021_SenAT137.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*unw_phase_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy 2021_SenAT137.txt    to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg to inputs   directory for backup.\n",
      "copy 2021_SenAT137.txt    to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/2021_SenAT137.txt --project 2021_SenAT137\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*unw_phase_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3_app/AT137/2021/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3_app/AT137/2021/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3_app/AT137/2021/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5765, 7331) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5765, 7331) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5765, 7331) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5765, 7331) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*unw_phase_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*corr_clipped.tif\n",
      "number of unwrapPhase     : 55\n",
      "number of coherence       : 55\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (55, 5765, 7331) with compression = None\n",
      "[==================================================] 20210920_20211014  302s /     6s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (55, 5765, 7331) with compression = None\n",
      "[==================================================] 20210920_20211014  311s /     6s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (55, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (55,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (55,)\n",
      "add extra metadata: {'PROJECT_NAME': '2021_SenAT137', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 11 mins 37.6 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file 2021_SenAT137.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file 2021_SenAT137.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 55/55   59s /     1s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 11\n",
      "number of interferograms: 55\n",
      "shift all perp baseline by 106.92715454101562 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 55\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 210.00 m\n",
      "max temporal      baseline: 132.0 days\n",
      "showing coherence\n",
      "data range: [0.44810608, 0.909137]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 55/55   52s /     1s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/maskConnComp.h5\n",
      "time used: 00 mins 55.0 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   44s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/avgSpatialCoh.h5\n",
      "time used: 00 mins 52.3 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   45s /     6s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (4905, 3321)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5\n",
      "{'REF_Y': '4905', 'REF_X': '3321', 'REF_LAT': '4691380.0', 'REF_LON': '631820.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   53s /     7s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/avgPhaseVelocity.h5\n",
      "time used: 01 mins 3.7 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 55\n",
      "number of triplets: 165\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (190, 7331), 31 blocks in total\n",
      "reference pixel in y/x: (4905, 3321) from dataset: unwrapPhase\n",
      "[==================================================] line 5700 / 5765  161s /     4s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/numTriNonzeroIntAmbiguity.png\n",
      "time used: 02 mins 48.8 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (4905, 3321) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 55\n",
      "number of acquisitions  : 11\n",
      "number of lines   : 5765\n",
      "number of columns : 7331\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5765 lines into 8 patches for processing\n",
      "    with each patch up to 730 lines\n",
      "\n",
      "------- processing patch 1 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 730]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 730]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 730]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 730]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 730]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 730]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 0, 6110, 730] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 0, 3666, 730] * 55 ...\n",
      "reading coherence in [1222, 0, 2444, 730] * 55 ...\n",
      "reading coherence in [0, 0, 1222, 730] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 0, 4888, 730] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 0, 7331, 730] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [0, 0, 1222, 730] * 55 ...\n",
      "reading unwrapPhase in [2444, 0, 3666, 730] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [3666, 0, 4888, 730] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [6110, 0, 7331, 730] * 55 ...\n",
      "reading unwrapPhase in [1222, 0, 2444, 730] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [4888, 0, 6110, 730] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 0 out of 892060 (0.0%)\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 74360 out of 892060 (8.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "\n",
      "FUTURE #1 complete. Time used: 13 seconds\n",
      "number of pixels to invert: 0 out of 892060 (0.0%)\n",
      "number of pixels to invert: 115551 out of 891330 (13.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 219071 out of 892060 (24.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]\n",
      "FUTURE #2 complete. Time used: 14 seconds\n",
      "number of pixels to invert: 267376 out of 892060 (30.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 74360/74360 pixels    20s /    10s\n",
      "[======================= 66% ====>                 ] 76600/115551 pixels   20s /    10sconverting LOS phase unit from radian to meter\n",
      "[======================= 66% ====>                 ] 76800/115551 pixels   20s /    10s\n",
      "FUTURE #3 complete. Time used: 34 seconds\n",
      "[==================================================] 115551/115551 pixels   30s /    30s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 51%                       ] 110800/219071 pixels   30s /    28s\n",
      "FUTURE #4 complete. Time used: 44 seconds\n",
      "[==================================================] 219071/219071 pixels   61s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 85% =============>        ] 227000/267376 pixels   61s /    10s\n",
      "FUTURE #5 complete. Time used: 75 seconds\n",
      "[==================================================] 267376/267376 pixels   71s /     1s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 86 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 730, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 730, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 730, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 01 mins 31.1 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 730, 1222, 1460]\n",
      "submit a job to the worker for sub box 1: [1222, 730, 2444, 1460]\n",
      "submit a job to the worker for sub box 2: [2444, 730, 3666, 1460]\n",
      "submit a job to the worker for sub box 3: [3666, 730, 4888, 1460]\n",
      "submit a job to the worker for sub box 4: [4888, 730, 6110, 1460]\n",
      "submit a job to the worker for sub box 5: [6110, 730, 7331, 1460]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 730, 3666, 1460] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 730, 2444, 1460] * 55 ...\n",
      "reading coherence in [6110, 730, 7331, 1460] * 55 ...\n",
      "reading coherence in [3666, 730, 4888, 1460] * 55 ...\n",
      "reading coherence in [0, 730, 1222, 1460] * 55 ...\n",
      "reading coherence in [4888, 730, 6110, 1460] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [1222, 730, 2444, 1460] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [2444, 730, 3666, 1460] * 55 ...\n",
      "reading unwrapPhase in [4888, 730, 6110, 1460] * 55 ...\n",
      "reading unwrapPhase in [3666, 730, 4888, 1460] * 55 ...\n",
      "reading unwrapPhase in [0, 730, 1222, 1460] * 55 ...\n",
      "reading unwrapPhase in [6110, 730, 7331, 1460] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 161096 out of 892060 (18.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 312553 out of 891330 (35.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 484896 out of 892060 (54.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 880418 out of 892060 (98.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 161096/161096 pixels   59s /   271s\n",
      "[========>               18%                       ] 160600/892060 pixels   59s /   271sconverting LOS phase unit from radian to meter\n",
      "[========>               18%                       ] 159800/892060 pixels   59s /   271s\n",
      "FUTURE #1 complete. Time used: 76 seconds\n",
      "[==================================================] 312553/312553 pixels  119s /   221s\n",
      "[=================>      35%                       ] 310200/880418 pixels  119s /   221sconverting LOS phase unit from radian to meter\n",
      "[======================= 62% ==>                   ] 300600/484896 pixels  119s /    73s\n",
      "FUTURE #2 complete. Time used: 136 seconds\n",
      "[==================================================] 484896/484896 pixels  182s /   137s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 57%                       ] 497800/880418 pixels  182s /   137s\n",
      "FUTURE #3 complete. Time used: 199 seconds\n",
      "[==================================================] 880418/880418 pixels  291s /     5s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 883200/892060 pixels\n",
      "FUTURE #4 complete. Time used: 310 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 884600/892060 pixels\n",
      "FUTURE #5 complete. Time used: 310 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 312 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 730, 1460, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [730, 1460, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [730, 1460, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 06 mins 48.4 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1460, 1222, 2190]\n",
      "submit a job to the worker for sub box 1: [1222, 1460, 2444, 2190]\n",
      "submit a job to the worker for sub box 2: [2444, 1460, 3666, 2190]\n",
      "submit a job to the worker for sub box 3: [3666, 1460, 4888, 2190]\n",
      "submit a job to the worker for sub box 4: [4888, 1460, 6110, 2190]\n",
      "submit a job to the worker for sub box 5: [6110, 1460, 7331, 2190]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 1460, 4888, 2190] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 1460, 3666, 2190] * 55 ...\n",
      "reading coherence in [6110, 1460, 7331, 2190] * 55 ...\n",
      "reading coherence in [4888, 1460, 6110, 2190] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 1460, 2444, 2190] * 55 ...\n",
      "reading coherence in [0, 1460, 1222, 2190] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "[==================================================] 659419/659419 pixels  284s /    80s\n",
      "[======================= 74% ========>             ] 664000/892060 pixels  284s /   100sconverting LOS phase unit from radian to meter\n",
      "[======================= 74% ========>             ] 664200/892060 pixels  285s /   100s\n",
      "FUTURE #2 complete. Time used: 300 seconds\n",
      "[==================================================] 870274/870274 pixels  355s /    11s\n",
      "[======================= 96% ===================>  ] 857000/892060 pixels  355s /    14sconverting LOS phase unit from radian to meter\n",
      "[======================= 96% ===================>  ] 857200/892060 pixels  355s /    14s\n",
      "FUTURE #3 complete. Time used: 372 seconds\n",
      "[==================================================] 892060/892060 pixels  362s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 879400/892060 pixels\n",
      "FUTURE #4 complete. Time used: 379 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "[==================================================] 887600/892060 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 887800/892060 pixels\n",
      "FUTURE #5 complete. Time used: 381 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 381 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2190, 2920, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [2190, 2920, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [2190, 2920, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 19 mins 27.3 secs.\n",
      "\n",
      "\n",
      "------- processing patch 5 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2920, 1222, 3650]\n",
      "submit a job to the worker for sub box 1: [1222, 2920, 2444, 3650]\n",
      "submit a job to the worker for sub box 2: [2444, 2920, 3666, 3650]\n",
      "submit a job to the worker for sub box 3: [3666, 2920, 4888, 3650]\n",
      "submit a job to the worker for sub box 4: [4888, 2920, 6110, 3650]\n",
      "submit a job to the worker for sub box 5: [6110, 2920, 7331, 3650]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 2920, 1222, 3650] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 2920, 3666, 3650] * 55 ...\n",
      "reading coherence in [1222, 2920, 2444, 3650] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 2920, 6110, 3650] * 55 ...\n",
      "reading coherence in [6110, 2920, 7331, 3650] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 2920, 4888, 3650] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [1222, 2920, 2444, 3650] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [0, 2920, 1222, 3650] * 55 ...\n",
      "reading unwrapPhase in [4888, 2920, 6110, 3650] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [6110, 2920, 7331, 3650] * 55 ...\n",
      "reading unwrapPhase in [2444, 2920, 3666, 3650] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [3666, 2920, 4888, 3650] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 444904 out of 892060 (49.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 633133 out of 891330 (71.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 444904/444904 pixels  218s /    89s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 50%                       ] 441800/892060 pixels  218s /   218s\n",
      "FUTURE #1 complete. Time used: 233 seconds\n",
      "[==================================================] 633133/633133 pixels  281s /   120s\n",
      "[======================= 70% ======>               ] 624200/892060 pixels  281s /   120sconverting LOS phase unit from radian to meter\n",
      "[======================= 70% ======>               ] 625200/892060 pixels  281s /   120s\n",
      "FUTURE #2 complete. Time used: 296 seconds\n",
      "[==================================================] 743193/743193 pixels  309s /    58s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 84% =============>        ] 748200/892060 pixels  309s /    58s\n",
      "FUTURE #2 complete. Time used: 326 seconds\n",
      "[==================================================] 892060/892060 pixels  347s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 885800/892060 pixels  347s /     7s\n",
      "FUTURE #3 complete. Time used: 364 seconds\n",
      "[==================================================] 892060/892060 pixels  348s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 891600/892060 pixels\n",
      "FUTURE #4 complete. Time used: 366 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #5 complete. Time used: 366 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 368 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 3650, 4380, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [3650, 4380, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [3650, 4380, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 32 mins 23.3 secs.\n",
      "\n",
      "\n",
      "------- processing patch 7 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4380, 1222, 5110]\n",
      "submit a job to the worker for sub box 1: [1222, 4380, 2444, 5110]\n",
      "submit a job to the worker for sub box 2: [2444, 4380, 3666, 5110]\n",
      "submit a job to the worker for sub box 3: [3666, 4380, 4888, 5110]\n",
      "submit a job to the worker for sub box 4: [4888, 4380, 6110, 5110]\n",
      "submit a job to the worker for sub box 5: [6110, 4380, 7331, 5110]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 4380, 6110, 5110] * 55 ...\n",
      "reading coherence in [2444, 4380, 3666, 5110] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 4380, 4888, 5110] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 4380, 1222, 5110] * 55 ...\n",
      "reading coherence in [6110, 4380, 7331, 5110] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 4380, 2444, 5110] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [4888, 4380, 6110, 5110] * 55 ...\n",
      "reading unwrapPhase in [6110, 4380, 7331, 5110] * 55 ...\n",
      "reading unwrapPhase in [1222, 4380, 2444, 5110] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [0, 4380, 1222, 5110] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [3666, 4380, 4888, 5110] * 55 ...\n",
      "reading unwrapPhase in [2444, 4380, 3666, 5110] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 241415 out of 891330 (27.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 439161 out of 892060 (49.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 227155 out of 892060 (25.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "[>                                                 ]estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 796167 out of 892060 (89.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 467544 out of 892060 (52.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[=>                       4%                       ] 18600/467544 pixels   11s /   278s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 439161/439161 pixels  189s /   149s\n",
      "[======================= 49%                       ] 439800/892060 pixels  189s /   197sconverting LOS phase unit from radian to meter\n",
      "[======================= 56%                       ] 448800/796167 pixels  190s /   149s\n",
      "FUTURE #3 complete. Time used: 205 seconds\n",
      "[==================================================] 467544/467544 pixels  198s /   138s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 52%                       ] 464400/892060 pixels  198s /   183s\n",
      "FUTURE #4 complete. Time used: 214 seconds\n",
      "[==================================================] 796167/796167 pixels  265s /    39s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 87% ===============>      ] 776800/892060 pixels  265s /    39s\n",
      "FUTURE #5 complete. Time used: 281 seconds\n",
      "[==================================================] 892060/892060 pixels  287s /     5s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 305 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4380, 5110, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4380, 5110, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4380, 5110, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 37 mins 32.9 secs.\n",
      "\n",
      "\n",
      "------- processing patch 8 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 655\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 5110, 1222, 5765]\n",
      "submit a job to the worker for sub box 1: [1222, 5110, 2444, 5765]\n",
      "submit a job to the worker for sub box 2: [2444, 5110, 3666, 5765]\n",
      "submit a job to the worker for sub box 3: [3666, 5110, 4888, 5765]\n",
      "submit a job to the worker for sub box 4: [4888, 5110, 6110, 5765]\n",
      "submit a job to the worker for sub box 5: [6110, 5110, 7331, 5765]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 5110, 3666, 5765] * 55 ...\n",
      "reading coherence in [6110, 5110, 7331, 5765] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 5110, 2444, 5765] * 55 ...\n",
      "reading coherence in [0, 5110, 1222, 5765] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 5110, 4888, 5765] * 55 ...\n",
      "reading coherence in [4888, 5110, 6110, 5765] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 8\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 8\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 8\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 8\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 8\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 8\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 8\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "reading unwrapPhase in [4888, 5110, 6110, 5765] * 55 ...\n",
      "reading unwrapPhase in [1222, 5110, 2444, 5765] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 8\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [0, 5110, 1222, 5765] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [6110, 5110, 7331, 5765] * 55 ...\n",
      "reading unwrapPhase in [2444, 5110, 3666, 5765] * 55 ...\n",
      "reading unwrapPhase in [3666, 5110, 4888, 5765] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 0 out of 800410 (0.0%)\n",
      "number of pixels to invert: 0 out of 799755 (0.0%)\n",
      "number of pixels to invert: 76721 out of 800410 (9.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 86986 out of 800410 (10.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 368576 out of 800410 (46.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 800410 (0.0%)\n",
      "\n",
      "FUTURE #1 complete. Time used: 14 seconds\n",
      "[>                                                 ]\n",
      "FUTURE #2 complete. Time used: 14 seconds\n",
      "\n",
      "FUTURE #3 complete. Time used: 14 seconds\n",
      "[======================= 66% ====>                 ] 57200/86986 pixels   24s /    12ss"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 368576/368576 pixels   89s /     1s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 104 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 5110, 5765, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [5110, 5765, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [5110, 5765, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 39 mins 20.6 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (4905, 3321)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 55\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 39 mins 20.6 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/maskTempCoh.h5\n",
      "time used: 00 mins 1.4 secs.\n",
      "number of reliable pixels: 22693705\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 11/11   68s /     6s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 16.4 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 1442]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 1442]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 1442]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 1442]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 1442]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 1442]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 141076 out of 1762124 (8.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 413298 out of 1760682 (23.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1134222 out of 1762124 (64.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 929725 out of 1762124 (52.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1084909 out of 1762124 (61.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 459687 out of 1762124 (26.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 141076/141076   36s /    82ss\n",
      "[=====>                  13%                       ] 146000/1084909   36s /   247s\n",
      "FUTURE #1 complete. Time used: 41 seconds\n",
      "[==================================================] 413298/413298    71s /   116s\n",
      "[===================>    39%                       ] 418000/1084909   71s /   112s\n",
      "FUTURE #2 complete. Time used: 76 seconds\n",
      "[==================================================] 459687/459687    76s /   110s\n",
      "[======================= 49%                       ] 460000/929725   77s /    80ss\n",
      "FUTURE #3 complete. Time used: 82 seconds\n",
      "[==================================================] 929725/929725   134s /    18s\n",
      "[======================= 88% ===============>      ] 956000/1084909  134s /    18s\n",
      "FUTURE #4 complete. Time used: 139 seconds\n",
      "[==================================================] 1084909/1084909  151s /     6s\n",
      "[======================= 96% ===================>  ] 1090000/1134222  151s /     6s\n",
      "FUTURE #5 complete. Time used: 156 seconds\n",
      "[==================================================] 1134222/1134222  154s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 161 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1442, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1442, 1222, 2884]\n",
      "submit a job to the worker for sub box 1: [1222, 1442, 2444, 2884]\n",
      "submit a job to the worker for sub box 2: [2444, 1442, 3666, 2884]\n",
      "submit a job to the worker for sub box 3: [3666, 1442, 4888, 2884]\n",
      "submit a job to the worker for sub box 4: [4888, 1442, 6110, 2884]\n",
      "submit a job to the worker for sub box 5: [6110, 1442, 7331, 2884]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1702141 out of 1762124 (96.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1201345 out of 1762124 (68.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 923215 out of 1760682 (52.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 923215/923215   176s /   162s\n",
      "[======================= 52%                       ] 922000/1762124  176s /   163s\n",
      "FUTURE #1 complete. Time used: 181 seconds\n",
      "[==================================================] 1201345/1201345  213s /    83s\n",
      "[======================= 72% =======>              ] 1220000/1702141  213s /    83s\n",
      "FUTURE #2 complete. Time used: 218 seconds\n",
      "[==================================================] 1702141/1702141  287s /     8s\n",
      "[======================= 97% ===================>  ] 1714000/1762124  288s /     8s\n",
      "FUTURE #3 complete. Time used: 292 seconds\n",
      "[==================================================] 1762124/1762124  293s /     5s\n",
      "[==================================================] 1748000/1762124\n",
      "FUTURE #4 complete. Time used: 299 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1750000/1762124\n",
      "FUTURE #5 complete. Time used: 300 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #6 complete. Time used: 301 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1442, 2884, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2884, 1222, 4326]\n",
      "submit a job to the worker for sub box 1: [1222, 2884, 2444, 4326]\n",
      "submit a job to the worker for sub box 2: [2444, 2884, 3666, 4326]\n",
      "submit a job to the worker for sub box 3: [3666, 2884, 4888, 4326]\n",
      "submit a job to the worker for sub box 4: [4888, 2884, 6110, 4326]\n",
      "submit a job to the worker for sub box 5: [6110, 2884, 7331, 4326]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 761962 out of 1762124 (43.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1339512 out of 1760682 (76.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 761962/761962   147s /   195s\n",
      "[=====================>  43%                       ] 764000/1762124  147s /   195s\n",
      "FUTURE #1 complete. Time used: 152 seconds\n",
      "[==================================================] 1339512/1339512  232s /    73s\n",
      "[======================= 75% =========>            ] 1328000/1762124  233s /    77s\n",
      "FUTURE #2 complete. Time used: 237 seconds\n",
      "[==================================================] 1762124/1762124  299s /     6s\n",
      "[==================================================] 1750000/1762124\n",
      "FUTURE #3 complete. Time used: 305 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1760000/1762124\n",
      "FUTURE #4 complete. Time used: 306 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #5 complete. Time used: 306 seconds\n",
      "\n",
      "FUTURE #6 complete. Time used: 306 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2884, 4326, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1439\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4326, 1222, 5765]\n",
      "submit a job to the worker for sub box 1: [1222, 4326, 2444, 5765]\n",
      "submit a job to the worker for sub box 2: [2444, 4326, 3666, 5765]\n",
      "submit a job to the worker for sub box 3: [3666, 4326, 4888, 5765]\n",
      "submit a job to the worker for sub box 4: [4888, 4326, 6110, 5765]\n",
      "submit a job to the worker for sub box 5: [6110, 4326, 7331, 5765]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1324542 out of 1758458 (75.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 935662 out of 1758458 (53.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 328730 out of 1758458 (18.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 297015 out of 1757019 (16.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 501230 out of 1758458 (28.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 530599 out of 1758458 (30.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 297015/297015    46s /   165s\n",
      "[======================= 56%                       ] 296000/530599   46s /    36s\n",
      "FUTURE #1 complete. Time used: 50 seconds\n",
      "[==================================================] 328730/328730    53s /   170s\n",
      "[=================>      36%                       ] 334000/935662   54s /    96ss\n",
      "FUTURE #2 complete. Time used: 57 seconds\n",
      "[==================================================] 501230/501230    82s /   146s\n",
      "[=================>      37%                       ] 484000/1324542   82s /   140s\n",
      "FUTURE #3 complete. Time used: 86 seconds\n",
      "[==================================================] 530599/530599    86s /   136s\n",
      "[======================= 57%                       ] 532000/935662   87s /    65s\n",
      "FUTURE #4 complete. Time used: 90 seconds\n",
      "[==================================================] 935662/935662   134s /    63s\n",
      "[======================= 68% =====>                ] 902000/1324542  135s /    63s\n",
      "FUTURE #5 complete. Time used: 138 seconds\n",
      "[==================================================] 1324542/1324542  168s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 174 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4326, 5765, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4326, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4326, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 16 mins 5.1 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 11/11   72s /     7s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 20.7 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 11/11   47s /     4s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20211014 - 0.0047\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0198)\n",
      "None.\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20211014\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5765, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20211014\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5765, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20211014\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 11, 0, 5765, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20211014\n",
      "time used: 00 mins 48.9 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: []\n",
      "--------------------------------------------------\n",
      "dates from input file: 11\n",
      "['20210604', '20210616', '20210628', '20210710', '20210722', '20210803', '20210815', '20210827', '20210908', '20210920', '20211014']\n",
      "--------------------------------------------------\n",
      "using all dates to calculate the time function\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5\n",
      "split along y dimension (5765) into 3 boxes\n",
      "    with each box up to 1922 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 3 --------------\n",
      "box width:  7331\n",
      "box length: 1922\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 7215358 out of 14090182 (51.2%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 1922, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 1922, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 1922, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 1922, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 1922, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 3 --------------\n",
      "box width:  7331\n",
      "box length: 1922\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 12160377 out of 14090182 (86.3%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [1922, 3844, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [1922, 3844, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [1922, 3844, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [1922, 3844, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [1922, 3844, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "\n",
      "------- processing patch 3 out of 3 --------------\n",
      "box width:  7331\n",
      "box length: 1921\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 6968004 out of 14082851 (49.5%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [3844, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [3844, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [3844, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [3844, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [3844, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5.\n",
      "time used: 00 mins 18.7 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7331, 5765)\n",
      "subset coverage in y/x: (0, 0, 7331, 5765)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7331/5765\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.26, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 03 mins 0.3 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_uncorrected\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 83 mins 8.3 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "mintpy_multiyear(orbit_list, year_list, clip=True, mintpy=True, clean_clip=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mintpy]",
   "language": "python",
   "name": "conda-env-mintpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
