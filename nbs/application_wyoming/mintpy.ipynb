{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f7bb06e-6e63-4d64-b7d6-8ccb6c97757b",
   "metadata": {},
   "source": [
    "# MintPy for signal maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c766f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import mintpy\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52ed07a6-5cd1-428e-8e7b-aa8eebec1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_list = ['AT137']\n",
    "year_list = ['2017', '2018', '2019', '2020', '2021']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910045f-42cf-4bf6-8c42-abda85c05b03",
   "metadata": {},
   "source": [
    "## clip files to common extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ec0ec07-2bfd-4a78-b90a-df7ea38c24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_overlap(file_list: List[Union[str, Path]]) -> List[float]:\n",
    "    \"\"\"Get the common overlap of  a list of GeoTIFF files\n",
    "    \n",
    "    Arg:\n",
    "        file_list: a list of GeoTIFF files\n",
    "    \n",
    "    Returns:\n",
    "         [ulx, uly, lrx, lry], the upper-left x, upper-left y, lower-right x, and lower-right y\n",
    "         corner coordinates of the common overlap\n",
    "    \"\"\"\n",
    "    \n",
    "    corners = [gdal.Info(str(dem), format='json')['cornerCoordinates'] for dem in file_list]\n",
    "\n",
    "    ulx = max(corner['upperLeft'][0] for corner in corners)\n",
    "    uly = min(corner['upperLeft'][1] for corner in corners)\n",
    "    lrx = min(corner['lowerRight'][0] for corner in corners)\n",
    "    lry = max(corner['lowerRight'][1] for corner in corners)\n",
    "    return [ulx, uly, lrx, lry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8aeb241-e1b8-404d-b156-11177471a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_hyp3_products_to_common_overlap(data_path: Union[str, Path], overlap: List[float]) -> None:\n",
    "    \"\"\"Clip all GeoTIFF files to their common overlap\n",
    "    \n",
    "    Args:\n",
    "        data_dir:\n",
    "            directory containing the GeoTIFF files to clip\n",
    "        overlap:\n",
    "            a list of the upper-left x, upper-left y, lower-right-x, and lower-tight y\n",
    "            corner coordinates of the common overlap\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    \n",
    "    files_for_mintpy = ['_water_mask.tif', '_corr.tif', '_unw_phase_ERA5.tif', '_dem.tif', '_lv_theta.tif', '_lv_phi.tif']\n",
    "\n",
    "    for extension in files_for_mintpy:\n",
    "        print(f'working on {extension}') \n",
    "        for file in data_path.rglob(f'*{extension}'):\n",
    "\n",
    "            dst_file = file.parent / f'{file.stem}_clipped{file.suffix}'\n",
    "\n",
    "            gdal.Translate(destName=str(dst_file), srcDS=str(file), projWin=overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dc256-88c0-4ac9-88aa-4ee420ca1e1d",
   "metadata": {},
   "source": [
    "## Mintpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "033276cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write to MintPy config file\n",
    "def write_config_file(out_file, CONFIG_TXT, mode='a'): \n",
    "    \"\"\"Write configuration files for MintPy to process products\"\"\"\n",
    "    if not os.path.isfile(out_file) or mode == 'w':\n",
    "        with open(out_file, \"w\") as fid:\n",
    "            fid.write(CONFIG_TXT)\n",
    "        print('write configuration to file: {}'.format(out_file))\n",
    "    else:\n",
    "        with open(out_file, \"a\") as fid:\n",
    "            fid.write(\"\\n\" + CONFIG_TXT)\n",
    "        print('add the following to file: \\n{}'.format(CONFIG_TXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42499563-1225-4427-8863-4ef390300f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clip files and run mintpy for multiple years \n",
    "def mintpy_multiyear(orbit_list, year_list, clip=True, mintpy=True, clean_clip=True):\n",
    "    # hardcoded paths for now \n",
    "    home_path_d = '/mnt/d/indennt'\n",
    "    home_path = '/mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data'\n",
    "    for orbit in orbit_list:\n",
    "        for year in year_list:\n",
    "            print(f'working on {orbit}, {year}')\n",
    "            data_path = f'{home_path_d}/hyp3_app/{orbit}/{year}'\n",
    "            mintpy_path = f'{home_path}/signal_mintpy/{orbit}/mintpy_{year}_ERA5'\n",
    "            mintpy_path_d = f'{home_path_d}/mintpy_app/{orbit}/'\n",
    "\n",
    "            if clip==True:\n",
    "                # identify and crop to common overlap\n",
    "                print('identifying common overlap')\n",
    "                dem_files = Path(data_path).glob('*/*_dem.tif')\n",
    "                overlap = get_common_overlap(dem_files)\n",
    "                print('clipping to common overlap')\n",
    "                clip_hyp3_products_to_common_overlap(Path(data_path), overlap)\n",
    "\n",
    "            # make output dir for mintpy\n",
    "            if not os.path.exists(mintpy_path):\n",
    "                os.mkdir(mintpy_path)\n",
    "\n",
    "            # write config file for mintpy\n",
    "            CONFIG_TXT = f'''# vim: set filetype=cfg:\n",
    "            ##----------------------------- hyp3 ---------------------##\n",
    "            mintpy.load.processor        = hyp3\n",
    "            ##---------interferogram datasets:\n",
    "            mintpy.load.unwFile          = {data_path}/*/*{year}*unw_phase_ERA5_clipped.tif\n",
    "            mintpy.load.corFile          = {data_path}/*/*{year}*corr_clipped.tif\n",
    "            ##---------geometry datasets:\n",
    "            mintpy.load.demFile          = {data_path}/*/*{year}*dem_clipped.tif\n",
    "            mintpy.load.incAngleFile     = {data_path}/*/*{year}*lv_theta_clipped.tif\n",
    "            mintpy.load.waterMaskFile    = {data_path}/*/*{year}*water_mask_clipped.tif\n",
    "\n",
    "            mintpy.deramp                = linear\n",
    "            mintpy.reference.lalo        = auto\n",
    "            mintpy.troposphericDelay.method  = no\n",
    "\n",
    "            mintpy.compute.cluster    = local\n",
    "            mintpy.compute.numWorker  = 6\n",
    "            '''\n",
    "\n",
    "            os.chdir(mintpy_path)\n",
    "            config_file = f'{mintpy_path}/{year}_Sen{orbit}.txt'\n",
    "            write_config_file(config_file, CONFIG_TXT, mode='w')\n",
    "\n",
    "            if mintpy==True:\n",
    "                # run mintpy\n",
    "                print('starting mintpy')\n",
    "                !smallbaselineApp.py --dir {mintpy_path} {config_file}\n",
    "                print('moving outputs to drive')\n",
    "                !cp -r $mintpy_path $mintpy_path_d && rm -R $mintpy_path\n",
    "\n",
    "            if clean_clip==True:\n",
    "                # remove clipped files\n",
    "                print('removing clipped files')\n",
    "                clipped_files = f'{data_path}/*/*_clipped.tif'\n",
    "                !rm {clipped_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cf39b43-8dac-40e1-b054-406c9e8706a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on AT137, 2017\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase_ERA5.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/2017_SenAT137.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-07-09 18:49:19.770712--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: 2017_SenAT137\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/2017_SenAT137.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*unw_phase_ERA5_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy 2017_SenAT137.txt    to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg to inputs   directory for backup.\n",
      "copy 2017_SenAT137.txt    to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/2017_SenAT137.txt --project 2017_SenAT137\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*unw_phase_ERA5_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3_app/AT137/2017/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3_app/AT137/2017/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3_app/AT137/2017/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD/S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5763, 7327) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5763, 7327) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5763, 7327) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20170613T011036_20170625T011036_VVP012_INT40_G_ueF_0FFD_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5763, 7327) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*unw_phase_ERA5_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3_app/AT137/2017/*/*2017*corr_clipped.tif\n",
      "number of unwrapPhase     : 45\n",
      "number of coherence       : 45\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (45, 5763, 7327) with compression = None\n",
      "[==================================================] 20170929_20171011  285s /     5s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (45, 5763, 7327) with compression = None\n",
      "[==================================================] 20170929_20171011  272s /     5s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (45, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (45,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (45,)\n",
      "add extra metadata: {'PROJECT_NAME': '2017_SenAT137', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 10 mins 32.9 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file 2017_SenAT137.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file 2017_SenAT137.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 45/45   54s /     1s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 10\n",
      "number of interferograms: 45\n",
      "shift all perp baseline by 19.02423095703125 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 45\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 201.27 m\n",
      "max temporal      baseline: 120.0 days\n",
      "showing coherence\n",
      "data range: [0.5309866, 0.8892115]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 45/45   56s /     1s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/maskConnComp.h5\n",
      "time used: 00 mins 59.8 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   40s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/avgSpatialCoh.h5\n",
      "time used: 00 mins 49.4 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   45s /     7s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (4725, 2738)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5\n",
      "{'REF_Y': '4725', 'REF_X': '2738', 'REF_LAT': '4698580.0', 'REF_LON': '608580.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5763/5763   49s /     8s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/avgPhaseVelocity.h5\n",
      "time used: 00 mins 59.9 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 45\n",
      "number of triplets: 120\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (250, 7327), 24 blocks in total\n",
      "reference pixel in y/x: (4725, 2738) from dataset: unwrapPhase\n",
      "[==================================================] line 5750 / 5763  150s /     6s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/numTriNonzeroIntAmbiguity.png\n",
      "time used: 02 mins 38.2 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (4725, 2738) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 45\n",
      "number of acquisitions  : 10\n",
      "number of lines   : 5763\n",
      "number of columns : 7327\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5763 lines into 6 patches for processing\n",
      "    with each patch up to 970 lines\n",
      "\n",
      "------- processing patch 1 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 970]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 970]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 970]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 970]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 970]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7327, 970]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 0, 6110, 970] * 45 ...\n",
      "reading coherence in [2444, 0, 3666, 970] * 45 ...\n",
      "reading coherence in [3666, 0, 4888, 970] * 45 ...\n",
      "reading coherence in [6110, 0, 7327, 970] * 45 ...\n",
      "reading coherence in [0, 0, 1222, 970] * 45 ...\n",
      "reading coherence in [1222, 0, 2444, 970] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 0, 4888, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 0, 3666, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 0, 2444, 970] * 45 ...\n",
      "reading unwrapPhase in [0, 0, 1222, 970] * 45 ...\n",
      "reading unwrapPhase in [6110, 0, 7327, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 0, 6110, 970] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 0 out of 1185340 (0.0%)\n",
      "number of pixels to invert: 562969 out of 1185340 (47.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 207186 out of 1180490 (17.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 515149 out of 1185340 (43.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 360050 out of 1185340 (30.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 20834 out of 1185340 (1.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]\n",
      "FUTURE #1 complete. Time used: 16 seconds\n",
      "[==================================================] 20834/20834 pixels    13s /   212s\n",
      "[=>                       4%                       ] 20800/515149 pixels   13s /   327sconverting LOS phase unit from radian to meter\n",
      "[=>                       4%                       ] 21000/515149 pixels   13s /   329s\n",
      "FUTURE #2 complete. Time used: 30 seconds\n",
      "[==================================================] 207186/207186 pixels   85s /   117s\n",
      "[======================= 59% =>                    ] 212600/360050 pixels   85s /    59sconverting LOS phase unit from radian to meter\n",
      "[======================= 59% =>                    ] 212800/360050 pixels   85s /    59s\n",
      "FUTURE #3 complete. Time used: 101 seconds\n",
      "[==================================================] 360050/360050 pixels  135s /    55s\n",
      "[======================= 64% ===>                  ] 358400/562969 pixels  135s /    76sconverting LOS phase unit from radian to meter\n",
      "[======================= 71% =======>              ] 364800/515149 pixels  135s /    55s\n",
      "FUTURE #4 complete. Time used: 152 seconds\n",
      "[==================================================] 515149/515149 pixels  174s /    19s\n",
      "[======================= 90% ================>     ] 505600/562969 pixels  174s /    19sconverting LOS phase unit from radian to meter\n",
      "[======================= 90% ================>     ] 505800/562969 pixels  174s /    19s\n",
      "FUTURE #5 complete. Time used: 191 seconds\n",
      "[==================================================] 562969/562969 pixels  186s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 205 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 970, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 970, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 970, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 03 mins 31.2 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 970, 1222, 1940]\n",
      "submit a job to the worker for sub box 1: [1222, 970, 2444, 1940]\n",
      "submit a job to the worker for sub box 2: [2444, 970, 3666, 1940]\n",
      "submit a job to the worker for sub box 3: [3666, 970, 4888, 1940]\n",
      "submit a job to the worker for sub box 4: [4888, 970, 6110, 1940]\n",
      "submit a job to the worker for sub box 5: [6110, 970, 7327, 1940]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 970, 4888, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 970, 6110, 1940] * 45 ...\n",
      "reading coherence in [2444, 970, 3666, 1940] * 45 ...\n",
      "reading coherence in [6110, 970, 7327, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 970, 1222, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 970, 2444, 1940] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 970, 7327, 1940] * 45 ...\n",
      "reading unwrapPhase in [2444, 970, 3666, 1940] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 970, 1222, 1940] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 970, 4888, 1940] * 45 ...\n",
      "reading unwrapPhase in [4888, 970, 6110, 1940] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 970, 2444, 1940] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 490573 out of 1180490 (41.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 608468 out of 1185340 (51.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1053742 out of 1185340 (88.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1183743 out of 1185340 (99.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 490573/490573 pixels   267s /   369s\n",
      "[====================>   42%                       ] 501400/1183743 pixels  267s /   369sconverting LOS phase unit from radian to meter\n",
      "[======================= 47%                       ] 498600/1053742 pixels  267s /   301s\n",
      "FUTURE #1 complete. Time used: 284 seconds\n",
      "[==================================================] 608468/608468 pixels   316s /   292s\n",
      "[======================= 52%                       ] 610600/1183743 pixels  316s /   292sconverting LOS phase unit from radian to meter\n",
      "[======================= 52%                       ] 610800/1183743 pixels  316s /   292s\n",
      "FUTURE #2 complete. Time used: 333 seconds\n",
      "[==================================================] 1053742/1053742 pixels  484s /    53s\n",
      "[======================= 90% ================>     ] 1068000/1185340 pixels  484s /    53sconverting LOS phase unit from radian to meter\n",
      "[======================= 90% ================>     ] 1068200/1185340 pixels  484s /    53s\n",
      "FUTURE #3 complete. Time used: 501 seconds\n",
      "[==================================================] 1185340/1185340 pixels  523s /    10s\n",
      "[======================= 98% ====================> ] 1161400/1185340 pixels  523s /    10sconverting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 1161600/1185340 pixels  523s /    10s\n",
      "FUTURE #4 complete. Time used: 540 seconds\n",
      "[==================================================] 1183743/1183743 pixels  524s /    10s\n",
      "[======================= 98% ====================> ] 1166000/1185340 pixels  524s /    10sconverting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 1166200/1185340 pixels  524s /    10s\n",
      "FUTURE #5 complete. Time used: 541 seconds\n",
      "[==================================================] 1185340/1185340 pixels  525s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 546 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 970, 1940, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [970, 1940, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [970, 1940, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 12 mins 41.8 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1940, 1222, 2910]\n",
      "submit a job to the worker for sub box 1: [1222, 1940, 2444, 2910]\n",
      "submit a job to the worker for sub box 2: [2444, 1940, 3666, 2910]\n",
      "submit a job to the worker for sub box 3: [3666, 1940, 4888, 2910]\n",
      "submit a job to the worker for sub box 4: [4888, 1940, 6110, 2910]\n",
      "submit a job to the worker for sub box 5: [6110, 1940, 7327, 2910]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 1940, 7327, 2910] * 45 ...\n",
      "reading coherence in [4888, 1940, 6110, 2910] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 1940, 4888, 2910] * 45 ...\n",
      "reading coherence in [2444, 1940, 3666, 2910] * 45 ...\n",
      "reading coherence in [0, 1940, 1222, 2910] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 1940, 2444, 2910] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 1940, 1222, 2910] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 1940, 7327, 2910] * 45 ...\n",
      "reading unwrapPhase in [1222, 1940, 2444, 2910] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 1940, 4888, 2910] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 1940, 3666, 2910] * 45 ...\n",
      "reading unwrapPhase in [4888, 1940, 6110, 2910] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 767701 out of 1185340 (64.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 673905 out of 1180490 (57.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1126954 out of 1185340 (95.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 673905/673905 pixels   358s /   281s\n",
      "[======================= 56%                       ] 663400/1185340 pixels  358s /   281sconverting LOS phase unit from radian to meter\n",
      "[======================= 57%                       ] 672200/1185340 pixels  358s /   270s\n",
      "FUTURE #1 complete. Time used: 375 seconds\n",
      "[==================================================] 767701/767701 pixels   404s /   218s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 65% ===>                  ] 765800/1185340 pixels  404s /   218s\n",
      "FUTURE #2 complete. Time used: 422 seconds\n",
      "[==================================================] 1126954/1126954 pixels  550s /    28s\n",
      "[======================= 94% ==================>   ] 1119800/1185340 pixels  550s /    35sconverting LOS phase unit from radian to meter\n",
      "[======================= 96% ===================>  ] 1137800/1185340 pixels  550s /    22s\n",
      "FUTURE #3 complete. Time used: 567 seconds\n",
      "[==================================================] 1185340/1185340 pixels  576s /    11s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1168200/1185340 pixels\n",
      "FUTURE #4 complete. Time used: 593 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1183600/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 603 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 604 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1940, 2910, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [1940, 2910, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [1940, 2910, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 22 mins 50.7 secs.\n",
      "\n",
      "\n",
      "------- processing patch 4 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2910, 1222, 3880]\n",
      "submit a job to the worker for sub box 1: [1222, 2910, 2444, 3880]\n",
      "submit a job to the worker for sub box 2: [2444, 2910, 3666, 3880]\n",
      "submit a job to the worker for sub box 3: [3666, 2910, 4888, 3880]\n",
      "submit a job to the worker for sub box 4: [4888, 2910, 6110, 3880]\n",
      "submit a job to the worker for sub box 5: [6110, 2910, 7327, 3880]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 2910, 6110, 3880] * 45 ...\n",
      "reading coherence in [1222, 2910, 2444, 3880] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 2910, 3666, 3880] * 45 ...\n",
      "reading coherence in [6110, 2910, 7327, 3880] * 45 ...\n",
      "reading coherence in [3666, 2910, 4888, 3880] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 2910, 1222, 3880] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 2910, 3666, 3880] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 2910, 2444, 3880] * 45 ...\n",
      "reading unwrapPhase in [6110, 2910, 7327, 3880] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 2910, 1222, 3880] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 2910, 4888, 3880] * 45 ...\n",
      "reading unwrapPhase in [4888, 2910, 6110, 3880] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 570084 out of 1185340 (48.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "number of pixels to invert: 863309 out of 1180490 (73.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 570084/570084 pixels   516s /   559s\n",
      "[======================= 66% ====>                 ] 571400/863309 pixels  516s /   266sconverting LOS phase unit from radian to meter\n",
      "[======================= 48%                       ] 573400/1185340 pixels  516s /   559s\n",
      "FUTURE #1 complete. Time used: 537 seconds\n",
      "[==================================================] 863309/863309 pixels   738s /   273s\n",
      "[======================= 73% =======>              ] 866000/1185340 pixels  738s /   273sconverting LOS phase unit from radian to meter\n",
      "[======================= 74% ========>             ] 877000/1185340 pixels  738s /   259s\n",
      "FUTURE #2 complete. Time used: 759 seconds\n",
      "[==================================================] 1185340/1185340 pixels  929s /    18s\n",
      "[======================= 98% ====================> ] 1160000/1185340 pixels  930s /    18sconverting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 1160200/1185340 pixels  930s /    18s\n",
      "FUTURE #3 complete. Time used: 951 seconds\n",
      "[==================================================] 1185340/1185340 pixels  934s /    19s\n",
      "[==================================================] 1173800/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1174000/1185340 pixels\n",
      "FUTURE #4 complete. Time used: 960 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "[==================================================] 1176400/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1176600/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 961 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 965 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2910, 3880, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [2910, 3880, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [2910, 3880, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 39 mins 2.7 secs.\n",
      "\n",
      "\n",
      "------- processing patch 5 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 3880, 1222, 4850]\n",
      "submit a job to the worker for sub box 1: [1222, 3880, 2444, 4850]\n",
      "submit a job to the worker for sub box 2: [2444, 3880, 3666, 4850]\n",
      "submit a job to the worker for sub box 3: [3666, 3880, 4888, 4850]\n",
      "submit a job to the worker for sub box 4: [4888, 3880, 6110, 4850]\n",
      "submit a job to the worker for sub box 5: [6110, 3880, 7327, 4850]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 3880, 7327, 4850] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 3880, 6110, 4850] * 45 ...\n",
      "reading coherence in [0, 3880, 1222, 4850] * 45 ...\n",
      "reading coherence in [1222, 3880, 2444, 4850] * 45 ...\n",
      "reading coherence in [2444, 3880, 3666, 4850] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 3880, 4888, 4850] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 3880, 3666, 4850] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 3880, 4888, 4850] * 45 ...\n",
      "reading unwrapPhase in [1222, 3880, 2444, 4850] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 3880, 7327, 4850] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 3880, 1222, 4850] * 45 ...\n",
      "reading unwrapPhase in [4888, 3880, 6110, 4850] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 1074964 out of 1185340 (90.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 760934 out of 1180490 (64.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1049174 out of 1185340 (88.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 365938 out of 1185340 (30.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185339 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 365938/365938 pixels   306s /   715s\n",
      "[=================>      35%                       ] 366600/1049174 pixels  306s /   569sconverting LOS phase unit from radian to meter\n",
      "[=================>      35%                       ] 366800/1049174 pixels  306s /   569s\n",
      "FUTURE #1 complete. Time used: 326 seconds\n",
      "[==================================================] 760934/760934 pixels   640s /   344s\n",
      "[======================= 64% ===>                  ] 760200/1185340 pixels  640s /   360sconverting LOS phase unit from radian to meter\n",
      "[======================= 64% ===>                  ] 760400/1185340 pixels  640s /   360s\n",
      "FUTURE #2 complete. Time used: 660 seconds\n",
      "[==================================================] 1049174/1049174 pixels  812s /   110s\n",
      "[======================= 96% ===================>  ] 1036200/1074964 pixels  812s /    33sconverting LOS phase unit from radian to meter\n",
      "[======================= 96% ===================>  ] 1036400/1074964 pixels  812s /    33s\n",
      "FUTURE #3 complete. Time used: 832 seconds\n",
      "[==================================================] 1074964/1074964 pixels  834s /    82s\n",
      "[======================= 91% =================>    ] 1073200/1185340 pixels  834s /    82sconverting LOS phase unit from radian to meter\n",
      "[======================= 91% =================>    ] 1073400/1185340 pixels  835s /    82s\n",
      "FUTURE #4 complete. Time used: 855 seconds\n",
      "[==================================================] 1185339/1185339 pixels  880s /    17s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1178000/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 905 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 908 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 3880, 4850, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [3880, 4850, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [3880, 4850, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 54 mins 16.9 secs.\n",
      "\n",
      "\n",
      "------- processing patch 6 out of 6 --------------\n",
      "box width:  7327\n",
      "box length: 913\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4850, 1222, 5763]\n",
      "submit a job to the worker for sub box 1: [1222, 4850, 2444, 5763]\n",
      "submit a job to the worker for sub box 2: [2444, 4850, 3666, 5763]\n",
      "submit a job to the worker for sub box 3: [3666, 4850, 4888, 5763]\n",
      "submit a job to the worker for sub box 4: [4888, 4850, 6110, 5763]\n",
      "submit a job to the worker for sub box 5: [6110, 4850, 7327, 5763]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 4850, 7327, 5763] * 45 ...\n",
      "reading coherence in [0, 4850, 1222, 5763] * 45 ...\n",
      "reading coherence in [2444, 4850, 3666, 5763] * 45 ...\n",
      "reading coherence in [4888, 4850, 6110, 5763] * 45 ...\n",
      "reading coherence in [3666, 4850, 4888, 5763] * 45 ...\n",
      "reading coherence in [1222, 4850, 2444, 5763] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 11 / 12\n",
      "reading unwrapPhase in [1222, 4850, 2444, 5763] * 45 ...\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 4850, 4888, 5763] * 45 ...\n",
      "reading unwrapPhase in [2444, 4850, 3666, 5763] * 45 ...\n",
      "reading unwrapPhase in [4888, 4850, 6110, 5763] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 4850, 7327, 5763] * 45 ...\n",
      "reading unwrapPhase in [0, 4850, 1222, 5763] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 159221 out of 1115686 (14.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 686153 out of 1115686 (61.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1600 out of 1115686 (0.1%)\n",
      "number of pixels to invert: 0 out of 1111121 (0.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 2840 out of 1115686 (0.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 298181 out of 1115686 (26.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]\n",
      "FUTURE #1 complete. Time used: 18 seconds\n",
      "[==================================================] 1600/1600 pixels    1s /     1s\n",
      "[======================= 56%                       ] 1600/2840 pixels    1s /     1sconverting LOS phase unit from radian to meter\n",
      "[>                                                 ]\n",
      "FUTURE #2 complete. Time used: 20 seconds\n",
      "[==================================================] 2840/2840 pixels s    2s /   137s\n",
      "[>                                                 ]converting LOS phase unit from radian to meter\n",
      "[>                        2%                       ] 3000/159221 pixels    2s /   146s\n",
      "FUTURE #3 complete. Time used: 21 seconds\n",
      "[==================================================] 159221/159221 pixels   89s /   299s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 53%                       ] 158600/298181 pixels   89s /    79s\n",
      "FUTURE #4 complete. Time used: 107 seconds\n",
      "[==================================================] 298181/298181 pixels  155s /   198s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=====================>  44%                       ] 300400/686153 pixels  156s /   198s\n",
      "FUTURE #5 complete. Time used: 174 seconds\n",
      "[==================================================] 686153/686153 pixels  296s /     6s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 318 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4850, 5763, 0, 7327]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4850, 5763, 0, 7327]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4850, 5763, 0, 7327]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 59 mins 42.0 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (4725, 2738)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 45\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 59 mins 42.0 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5763, 7327)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/maskTempCoh.h5\n",
      "time used: 00 mins 1.8 secs.\n",
      "number of reliable pixels: 20719400\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  79s /     8s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 29.0 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7327\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 1441]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 1441]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 1441]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 1441]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 1441]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7327, 1441]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 464798 out of 1760902 (26.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 420074 out of 1753697 (24.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 144905 out of 1760902 (8.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1090711 out of 1760902 (61.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 935612 out of 1760902 (53.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1138531 out of 1760902 (64.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 144905/144905   58s /   331ss\n",
      "[=====>                  13%                       ] 144000/1138531   58s /   392s\n",
      "FUTURE #1 complete. Time used: 64 seconds\n",
      "[==================================================] 420074/420074   151s /   236s\n",
      "[=================>      37%                       ] 426000/1138531  151s /   258s\n",
      "FUTURE #2 complete. Time used: 157 seconds\n",
      "[==================================================] 464798/464798   160s /   241s\n",
      "[===================>    40%                       ] 460000/1138531  161s /   242s\n",
      "FUTURE #3 complete. Time used: 166 seconds\n",
      "[==================================================] 935612/935612   261s /    46s\n",
      "[======================= 85% =============>        ] 924000/1090711  262s /    46s\n",
      "FUTURE #4 complete. Time used: 267 seconds\n",
      "[==================================================] 1090711/1090711  289s /     8s\n",
      "[======================= 97% ===================>  ] 1106000/1138531  289s /     8s\n",
      "FUTURE #5 complete. Time used: 295 seconds\n",
      "[==================================================] 1138531/1138531  292s /     5s\n",
      "\n",
      "FUTURE #6 complete. Time used: 300 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1441, 0, 7327]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1441, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1441, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7327\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1441, 1222, 2882]\n",
      "submit a job to the worker for sub box 1: [1222, 1441, 2444, 2882]\n",
      "submit a job to the worker for sub box 2: [2444, 1441, 3666, 2882]\n",
      "submit a job to the worker for sub box 3: [3666, 1441, 4888, 2882]\n",
      "submit a job to the worker for sub box 4: [4888, 1441, 6110, 2882]\n",
      "submit a job to the worker for sub box 5: [6110, 1441, 7327, 2882]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1211812 out of 1760902 (68.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 929593 out of 1753697 (53.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1700919 out of 1760902 (96.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 929593/929593   375s /   319s\n",
      "[======================= 77% =========>            ] 934000/1211812  375s /   112s\n",
      "FUTURE #1 complete. Time used: 381 seconds\n",
      "[==================================================] 1211812/1211812  469s /   221s\n",
      "[======================= 70% ======>               ] 1188000/1700919  470s /   201s\n",
      "FUTURE #2 complete. Time used: 475 seconds\n",
      "[==================================================] 1760902/1760902  610s /    12s\n",
      "[==================================================] 1698000/1700919\n",
      "FUTURE #3 complete. Time used: 616 seconds\n",
      "[==================================================] 1700919/1700919  611s /    12s\n",
      "[==================================================] 1736000/1760902  613s /    12s\n",
      "FUTURE #4 complete. Time used: 618 seconds\n",
      "[==================================================] 1760902/1760902  613s /    12s\n",
      "[==================================================] 1758000/1760902\n",
      "FUTURE #5 complete. Time used: 623 seconds\n",
      "[==================================================] 1760902/1760902 \n",
      "\n",
      "FUTURE #6 complete. Time used: 624 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1441, 2882, 0, 7327]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1441, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1441, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7327\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2882, 1222, 4323]\n",
      "submit a job to the worker for sub box 1: [1222, 2882, 2444, 4323]\n",
      "submit a job to the worker for sub box 2: [2444, 2882, 3666, 4323]\n",
      "submit a job to the worker for sub box 3: [3666, 2882, 4888, 4323]\n",
      "submit a job to the worker for sub box 4: [4888, 2882, 6110, 4323]\n",
      "submit a job to the worker for sub box 5: [6110, 2882, 7327, 4323]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 774942 out of 1760902 (44.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1343184 out of 1753697 (76.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1760902 out of 1760902 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 774942/774942   162s /   207s\n",
      "[=====================>  44%                       ] 778000/1760902  163s /   207s\n",
      "FUTURE #1 complete. Time used: 168 seconds\n",
      "[==================================================] 1343184/1343184  279s /    88s\n",
      "[======================= 76% =========>            ] 1338000/1760902  279s /    88s\n",
      "FUTURE #2 complete. Time used: 285 seconds\n",
      "[==================================================] 1760902/1760902  358s /     7s\n",
      "[==================================================] 1744000/1760902  359s /     7s\n",
      "FUTURE #3 complete. Time used: 365 seconds\n",
      "[==================================================] 1760902/1760902  363s /     7s\n",
      "[==================================================] 1738000/1760902\n",
      "FUTURE #4 complete. Time used: 370 seconds\n",
      "[==================================================] 1760902/1760902 \n",
      "\n",
      "FUTURE #5 complete. Time used: 373 seconds\n",
      "[==================================================] 1760902/1760902 \n",
      "\n",
      "FUTURE #6 complete. Time used: 374 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2882, 4323, 0, 7327]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2882, 4323, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2882, 4323, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7327\n",
      "box length: 1440\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4323, 1222, 5763]\n",
      "submit a job to the worker for sub box 1: [1222, 4323, 2444, 5763]\n",
      "submit a job to the worker for sub box 2: [2444, 4323, 3666, 5763]\n",
      "submit a job to the worker for sub box 3: [3666, 4323, 4888, 5763]\n",
      "submit a job to the worker for sub box 4: [4888, 4323, 6110, 5763]\n",
      "submit a job to the worker for sub box 5: [6110, 4323, 7327, 5763]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1330147 out of 1759680 (75.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 303056 out of 1752480 (17.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 339753 out of 1759680 (19.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 536458 out of 1759680 (30.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 509428 out of 1759680 (29.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 942174 out of 1759680 (53.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 303056/303056   62s /     8ss\n",
      "[======================= 57%                       ] 308000/536458   63s /    47ss\n",
      "FUTURE #1 complete. Time used: 67 seconds\n",
      "[==================================================] 339753/339753    70s /   201s\n",
      "[=================>      36%                       ] 336000/942174   70s /   125s\n",
      "FUTURE #2 complete. Time used: 75 seconds\n",
      "[==================================================] 536458/536458   101s /   152s\n",
      "[==================================================] 502000/509428\n",
      "FUTURE #3 complete. Time used: 106 seconds\n",
      "[==================================================] 509428/509428  103s /    81ss\n",
      "\n",
      "FUTURE #4 complete. Time used: 108 seconds\n",
      "[==================================================] 942174/942174   166s /    61s\n",
      "[======================= 73% =======>              ] 974000/1330147  166s /    61s\n",
      "FUTURE #5 complete. Time used: 171 seconds\n",
      "[==================================================] 1330147/1330147  198s /     4s\n",
      "\n",
      "FUTURE #6 complete. Time used: 205 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4323, 5763, 0, 7327]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4323, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4323, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 25 mins 32.2 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5763, 7327)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  70s /     7s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 20.1 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 10/10  48s /     5s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20170929 - 0.0044\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0140)\n",
      "None.\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20170929\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5763, 0, 7327)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20170929\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5763, 0, 7327)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20170929\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5763, 0, 7327)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20170929\n",
      "time used: 00 mins 46.9 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: []\n",
      "--------------------------------------------------\n",
      "dates from input file: 10\n",
      "['20170613', '20170625', '20170707', '20170731', '20170812', '20170824', '20170905', '20170917', '20170929', '20171011']\n",
      "--------------------------------------------------\n",
      "using all dates to calculate the time function\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5763, 7327)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5\n",
      "split along y dimension (5763) into 2 boxes\n",
      "    with each box up to 2882 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 2 --------------\n",
      "box width:  7327\n",
      "box length: 2882\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13319661 out of 21116414 (63.1%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 2882, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 2 --------------\n",
      "box width:  7327\n",
      "box length: 2881\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13122751 out of 21109087 (62.2%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [2882, 5763, 0, 7327]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5.\n",
      "time used: 00 mins 18.8 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7327, 5763)\n",
      "subset coverage in y/x: (0, 0, 7327, 5763)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7327/5763\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.26, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 02 mins 45.2 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2017_ERA5\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 111 mins 40.2 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "working on AT137, 2018\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase_ERA5.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/2018_SenAT137.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-07-09 21:21:36.467216--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: 2018_SenAT137\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/2018_SenAT137.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*unw_phase_ERA5_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy 2018_SenAT137.txt    to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg to inputs   directory for backup.\n",
      "copy 2018_SenAT137.txt    to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/2018_SenAT137.txt --project 2018_SenAT137\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*unw_phase_ERA5_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3_app/AT137/2018/S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9/S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3_app/AT137/2018/S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9/S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3_app/AT137/2018/S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9/S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5767, 7331) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5767, 7331) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5767, 7331) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20180608T011042_20180702T011043_VVP024_INT40_G_ueF_EBD9_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5767, 7331) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*unw_phase_ERA5_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3_app/AT137/2018/*/*2018*corr_clipped.tif\n",
      "number of unwrapPhase     : 40\n",
      "number of coherence       : 40\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (40, 5767, 7331) with compression = None\n",
      "[==================================================] 20180924_20181006  255s /     5s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (40, 5767, 7331) with compression = None\n",
      "[==================================================] 20180924_20181006  247s /     5s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (40, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (40,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (40,)\n",
      "add extra metadata: {'PROJECT_NAME': '2018_SenAT137', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 09 mins 39.1 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file 2018_SenAT137.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file 2018_SenAT137.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 40/40   49s /     1s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 10\n",
      "number of interferograms: 40\n",
      "shift all perp baseline by 45.84169006347656 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 40\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 193.61 m\n",
      "max temporal      baseline: 96.0 days\n",
      "showing coherence\n",
      "data range: [0.6391925, 0.93341994]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 40/40   44s /     0s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/maskConnComp.h5\n",
      "time used: 00 mins 47.1 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5767/5767   33s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/avgSpatialCoh.h5\n",
      "time used: 00 mins 42.9 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5767/5767   35s /     7s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (2833, 4293)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5\n",
      "{'REF_Y': '2833', 'REF_X': '4293', 'REF_LAT': '4774340.0', 'REF_LON': '670700.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5767/5767   41s /     8s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/avgPhaseVelocity.h5\n",
      "time used: 00 mins 53.2 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 40\n",
      "number of triplets: 90\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (320, 7331), 19 blocks in total\n",
      "reference pixel in y/x: (2833, 4293) from dataset: unwrapPhase\n",
      "[==================================================] line 5760 / 5767  115s /     6s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/numTriNonzeroIntAmbiguity.png\n",
      "time used: 02 mins 2.2 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (2833, 4293) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 40\n",
      "number of acquisitions  : 10\n",
      "number of lines   : 5767\n",
      "number of columns : 7331\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (10, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5767 lines into 6 patches for processing\n",
      "    with each patch up to 970 lines\n",
      "\n",
      "------- processing patch 1 out of 6 --------------\n",
      "box width:  7331\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 970]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 970]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 970]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 970]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 970]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 970]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 0, 4888, 970] * 40 ...\n",
      "reading coherence in [2444, 0, 3666, 970] * 40 ...\n",
      "reading coherence in [6110, 0, 7331, 970] * 40 ...\n",
      "reading coherence in [0, 0, 1222, 970] * 40 ...\n",
      "reading coherence in [4888, 0, 6110, 970] * 40 ...\n",
      "reading coherence in [1222, 0, 2444, 970] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 0, 2444, 970] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 0, 4888, 970] * 40 ...\n",
      "reading unwrapPhase in [2444, 0, 3666, 970] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 0, 6110, 970] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 0, 7331, 970] * 40 ...\n",
      "reading unwrapPhase in [0, 0, 1222, 970] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 354992 out of 1185340 (29.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 19808 out of 1185340 (1.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 1185340 (0.0%)\n",
      "number of pixels to invert: 557852 out of 1185340 (47.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 206639 out of 1184370 (17.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 510755 out of 1185340 (43.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                        2%                       ] 400/19808 pixels    0s /    11s\n",
      "FUTURE #1 complete. Time used: 15 seconds\n",
      "[==================================================] 19808/19808 pixels     9s /   231s\n",
      "[=>                       4%                       ] 19400/510755 pixels    9s /   230sconverting LOS phase unit from radian to meter\n",
      "[=>                       4%                       ] 19600/510755 pixels    9s /   232s\n",
      "FUTURE #2 complete. Time used: 24 seconds\n",
      "[==================================================] 206639/206639 pixels   90s /   135s\n",
      "[======================= 58% >                     ] 206000/354992 pixels   90s /    65sconverting LOS phase unit from radian to meter\n",
      "[===================>    40%                       ] 206000/510755 pixels   90s /   135s\n",
      "FUTURE #3 complete. Time used: 105 seconds\n",
      "[==================================================] 354992/354992 pixels  135s /    60s\n",
      "[======================= 64% ===>                  ] 356200/557852 pixels  135s /    76sconverting LOS phase unit from radian to meter\n",
      "[======================= 69% =====>                ] 352400/510755 pixels  135s /    60s\n",
      "FUTURE #4 complete. Time used: 150 seconds\n",
      "[==================================================] 510755/510755 pixels  185s /    16s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 92% =================>    ] 513800/557852 pixels  185s /    16s\n",
      "FUTURE #5 complete. Time used: 200 seconds\n",
      "[==================================================] 557852/557852 pixels  193s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 210 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 970, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 970, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 970, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 03 mins 36.4 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 6 --------------\n",
      "box width:  7331\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 970, 1222, 1940]\n",
      "submit a job to the worker for sub box 1: [1222, 970, 2444, 1940]\n",
      "submit a job to the worker for sub box 2: [2444, 970, 3666, 1940]\n",
      "submit a job to the worker for sub box 3: [3666, 970, 4888, 1940]\n",
      "submit a job to the worker for sub box 4: [4888, 970, 6110, 1940]\n",
      "submit a job to the worker for sub box 5: [6110, 970, 7331, 1940]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 970, 3666, 1940] * 40 ...\n",
      "reading coherence in [6110, 970, 7331, 1940] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 970, 2444, 1940] * 40 ...\n",
      "reading coherence in [0, 970, 1222, 1940] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 970, 6110, 1940] * 40 ...\n",
      "reading coherence in [3666, 970, 4888, 1940] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 970, 1222, 1940] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 970, 7331, 1940] * 40 ...\n",
      "reading unwrapPhase in [1222, 970, 2444, 1940] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 970, 6110, 1940] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 970, 3666, 1940] * 40 ...\n",
      "reading unwrapPhase in [3666, 970, 4888, 1940] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 602822 out of 1185340 (50.9%)\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "number of pixels to invert: 1049118 out of 1185340 (88.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1183899 out of 1185340 (99.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 491474 out of 1184370 (41.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 491474/491474 pixels   257s /   290s\n",
      "[======================= 81% ===========>          ] 486600/602822 pixels  257s /    60ssconverting LOS phase unit from radian to meter\n",
      "[======================= 47%                       ] 490600/1049118 pixels  257s /   290s\n",
      "FUTURE #1 complete. Time used: 271 seconds\n",
      "[==================================================] 602822/602822 pixels   307s /   295s\n",
      "[======================= 52%                       ] 616000/1185340 pixels  307s /   283sconverting LOS phase unit from radian to meter\n",
      "[======================= 52%                       ] 613600/1185340 pixels  307s /   283s\n",
      "FUTURE #2 complete. Time used: 321 seconds\n",
      "[==================================================] 1049118/1049118 pixels  466s /    57s\n",
      "[======================= 89% ===============>      ] 1056400/1185340 pixels  466s /    57sconverting LOS phase unit from radian to meter\n",
      "[======================= 89% ===============>      ] 1052000/1185340 pixels  466s /    57s\n",
      "FUTURE #3 complete. Time used: 481 seconds\n",
      "[==================================================] 1185340/1185340 pixels  507s /    15s\n",
      "[==================================================] 1183000/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1183200/1185340 pixels  507s /    15s\n",
      "FUTURE #4 complete. Time used: 522 seconds\n",
      "[==================================================] 1185340/1185340 pixels  508s /    15s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 1152200/1183899 pixels  508s /    15s\n",
      "FUTURE #5 complete. Time used: 522 seconds\n",
      "[==================================================] 1183899/1183899 pixels  511s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 531 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 970, 1940, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [970, 1940, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [970, 1940, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 12 mins 31.6 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 6 --------------\n",
      "box width:  7331\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1940, 1222, 2910]\n",
      "submit a job to the worker for sub box 1: [1222, 1940, 2444, 2910]\n",
      "submit a job to the worker for sub box 2: [2444, 1940, 3666, 2910]\n",
      "submit a job to the worker for sub box 3: [3666, 1940, 4888, 2910]\n",
      "submit a job to the worker for sub box 4: [4888, 1940, 6110, 2910]\n",
      "submit a job to the worker for sub box 5: [6110, 1940, 7331, 2910]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 1940, 4888, 2910] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 1940, 1222, 2910] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 1940, 2444, 2910] * 40 ...\n",
      "reading coherence in [2444, 1940, 3666, 2910] * 40 ...\n",
      "reading coherence in [4888, 1940, 6110, 2910] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 1940, 7331, 2910] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 1940, 3666, 2910] * 40 ...\n",
      "reading unwrapPhase in [1222, 1940, 2444, 2910] * 40 ...\n",
      "reading unwrapPhase in [0, 1940, 1222, 2910] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 1940, 4888, 2910] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 1940, 7331, 2910] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 1940, 6110, 2910] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 764889 out of 1185340 (64.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1126798 out of 1185340 (95.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 674959 out of 1184370 (57.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 1185339 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 1126798/1126798 pixels  525s /    27s\n",
      "[======================= 94% ==================>   ] 1112200/1185339 pixels  525s /    33sconverting LOS phase unit from radian to meter\n",
      "[======================= 95% ===================>  ] 1129800/1185340 pixels  525s /    27s\n",
      "FUTURE #3 complete. Time used: 541 seconds\n",
      "[==================================================] 1185340/1185340 pixels  542s /    11s\n",
      "[======================= 98% ====================> ] 1161000/1185340 pixels  542s /    11sconverting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 1161200/1185340 pixels  542s /    11s\n",
      "FUTURE #4 complete. Time used: 558 seconds\n",
      "[==================================================] 1185339/1185339 pixels  545s /    11s\n",
      "[==================================================] 1180200/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1180400/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 564 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 566 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1940, 2910, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [1940, 2910, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [1940, 2910, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 22 mins 2.4 secs.\n",
      "\n",
      "\n",
      "------- processing patch 4 out of 6 --------------\n",
      "box width:  7331\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2910, 1222, 3880]\n",
      "submit a job to the worker for sub box 1: [1222, 2910, 2444, 3880]\n",
      "submit a job to the worker for sub box 2: [2444, 2910, 3666, 3880]\n",
      "submit a job to the worker for sub box 3: [3666, 2910, 4888, 3880]\n",
      "submit a job to the worker for sub box 4: [4888, 2910, 6110, 3880]\n",
      "submit a job to the worker for sub box 5: [6110, 2910, 7331, 3880]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 2910, 4888, 3880] * 40 ...\n",
      "reading coherence in [4888, 2910, 6110, 3880] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 2910, 1222, 3880] * 40 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 2910, 3666, 3880] * 40 ...\n",
      "reading coherence in [6110, 2910, 7331, 3880] * 40 ...\n",
      "reading coherence in [1222, 2910, 2444, 3880] * 40 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 2910, 2444, 3880] * 40 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 2910, 1222, 3880] * 40 ...\n",
      "reading unwrapPhase in [4888, 2910, 6110, 3880] * 40 ...\n",
      "reading unwrapPhase in [3666, 2910, 4888, 3880] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 2910, 7331, 3880] * 40 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 2910, 3666, 3880] * 40 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 566933 out of 1185340 (47.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 864675 out of 1184370 (73.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 566933/566933 pixels   294s /   318s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 48%                       ] 571000/1185340 pixels  294s /   318s\n",
      "FUTURE #1 complete. Time used: 309 seconds\n",
      "[==================================================] 363027/363027 pixels  191s /   206ss\n",
      "[===============>        31%                       ] 372000/1185340 pixels  191s /   425sconverting LOS phase unit from radian to meter\n",
      "[======================= 48%                       ] 367000/764449 pixels  191s /   207ss\n",
      "FUTURE #1 complete. Time used: 206 seconds\n",
      "[==================================================] 764449/764449 pixels   368s /   143s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 65% ===>                  ] 774000/1185340 pixels  368s /   198s\n",
      "FUTURE #2 complete. Time used: 384 seconds\n",
      "[==================================================] 1051061/1051061 pixels  476s /    52s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 90% ================>     ] 1061200/1185340 pixels  476s /    52s\n",
      "FUTURE #3 complete. Time used: 491 seconds\n",
      "[==================================================] 1078107/1078107 pixels  481s /    47s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 91% =================>    ] 1077000/1185340 pixels  481s /    47s\n",
      "FUTURE #4 complete. Time used: 497 seconds\n",
      "[======================= 92% =================>    ] 1086800/1185340 pixels  484s /    42s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 157432/157432 pixels   53s /    47s\n",
      "[======================= 53%                       ] 161000/301435 pixels   53s /    47sconverting LOS phase unit from radian to meter\n",
      "[======================= 53%                       ] 161200/301435 pixels   53s /    47s\n",
      "FUTURE #4 complete. Time used: 68 seconds\n",
      "[==================================================] 301435/301435 pixels   91s /   121s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=====================>  43%                       ] 297600/689159 pixels   91s /   121s\n",
      "FUTURE #5 complete. Time used: 106 seconds\n",
      "[==================================================] 689159/689159 pixels  179s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 196 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4850, 5767, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4850, 5767, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4850, 5767, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 43 mins 41.4 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (2833, 4293)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 40\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 43 mins 41.5 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/maskTempCoh.h5\n",
      "time used: 00 mins 1.8 secs.\n",
      "number of reliable pixels: 24037402\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  64s /     7s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 12.8 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 1442]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 1442]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 1442]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 1442]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 1442]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 1442]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 460370 out of 1762124 (26.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 931776 out of 1762124 (52.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 420451 out of 1760682 (23.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 141721 out of 1762124 (8.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1134636 out of 1762124 (64.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1087539 out of 1762124 (61.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 141721/141721   31s /   180ss\n",
      "[================>       34%                       ] 142000/420451   32s /    62ss\n",
      "FUTURE #1 complete. Time used: 36 seconds\n",
      "[==================================================] 420451/420451    82s /   129s\n",
      "[======================= 90% ================>     ] 414000/460370   83s /     9ss\n",
      "FUTURE #2 complete. Time used: 87 seconds\n",
      "[==================================================] 460370/460370   91s /    91ss\n",
      "[======================= 50%                       ] 470000/931776   91s /    91ss\n",
      "FUTURE #3 complete. Time used: 96 seconds\n",
      "[==================================================] 931776/931776   149s /    32s\n",
      "[======================= 87% ===============>      ] 946000/1087539  149s /    22s\n",
      "FUTURE #4 complete. Time used: 154 seconds\n",
      "[==================================================] 1087539/1087539  164s /     8s\n",
      "[======================= 96% ===================>  ] 1084000/1134636  165s /     6s\n",
      "FUTURE #5 complete. Time used: 169 seconds\n",
      "[==================================================] 1134636/1134636  168s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 174 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1442, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1442, 1222, 2884]\n",
      "submit a job to the worker for sub box 1: [1222, 1442, 2444, 2884]\n",
      "submit a job to the worker for sub box 2: [2444, 1442, 3666, 2884]\n",
      "submit a job to the worker for sub box 3: [3666, 1442, 4888, 2884]\n",
      "submit a job to the worker for sub box 4: [4888, 1442, 6110, 2884]\n",
      "submit a job to the worker for sub box 5: [6110, 1442, 7331, 2884]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1702141 out of 1762124 (96.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 932152 out of 1760682 (52.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1208001 out of 1762124 (68.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762123 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 932152/932152   200s /   163s\n",
      "[======================= 52%                       ] 920000/1762124  200s /   184s\n",
      "FUTURE #1 complete. Time used: 204 seconds\n",
      "[==================================================] 1208001/1208001  251s /   107s\n",
      "[======================= 70% ======>               ] 1232000/1762123  252s /   108s\n",
      "FUTURE #2 complete. Time used: 256 seconds\n",
      "[==================================================] 1702141/1702141  324s /    17s\n",
      "[======================= 97% ===================>  ] 1704000/1762124  324s /    10s\n",
      "FUTURE #3 complete. Time used: 328 seconds\n",
      "[==================================================] 1762123/1762123  329s /     6s\n",
      "[==================================================] 1752000/1762124\n",
      "FUTURE #4 complete. Time used: 334 seconds\n",
      "[==================================================] 1762124/1762124  331s /     6s\n",
      "[==================================================] 1736000/1762124\n",
      "FUTURE #5 complete. Time used: 335 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #6 complete. Time used: 338 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1442, 2884, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2884, 1222, 4326]\n",
      "submit a job to the worker for sub box 1: [1222, 2884, 2444, 4326]\n",
      "submit a job to the worker for sub box 2: [2444, 2884, 3666, 4326]\n",
      "submit a job to the worker for sub box 3: [3666, 2884, 4888, 4326]\n",
      "submit a job to the worker for sub box 4: [4888, 2884, 6110, 4326]\n",
      "submit a job to the worker for sub box 5: [6110, 2884, 7331, 4326]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 770140 out of 1762124 (43.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1346902 out of 1760682 (76.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 770140/770140   170s /   217s\n",
      "\n",
      "FUTURE #1 complete. Time used: 175 seconds\n",
      "[==================================================] 1346902/1346902  277s /    82s\n",
      "[======================= 77% =========>            ] 1364000/1762124  277s /    82s\n",
      "FUTURE #2 complete. Time used: 281 seconds\n",
      "[==================================================] 1762124/1762124  333s /     6s\n",
      "\n",
      "FUTURE #3 complete. Time used: 337 seconds\n",
      "[==================================================] 1762124/1762124  334s /     6s\n",
      "\n",
      "FUTURE #4 complete. Time used: 338 seconds\n",
      "[==================================================] 1762124/1762124  334s /     6s\n",
      "\n",
      "FUTURE #5 complete. Time used: 339 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #6 complete. Time used: 342 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2884, 4326, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4326, 1222, 5767]\n",
      "submit a job to the worker for sub box 1: [1222, 4326, 2444, 5767]\n",
      "submit a job to the worker for sub box 2: [2444, 4326, 3666, 5767]\n",
      "submit a job to the worker for sub box 3: [3666, 4326, 4888, 5767]\n",
      "submit a job to the worker for sub box 4: [4888, 4326, 6110, 5767]\n",
      "submit a job to the worker for sub box 5: [6110, 4326, 7331, 5767]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1329487 out of 1760902 (75.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 335241 out of 1760902 (19.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 941763 out of 1760902 (53.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 302691 out of 1759461 (17.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 507896 out of 1760902 (28.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 536361 out of 1760902 (30.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 302691/302691   71s /    45ss\n",
      "[===============>        33%                       ] 308000/941763   72s /   146s\n",
      "FUTURE #1 complete. Time used: 76 seconds\n",
      "[==================================================] 335241/335241   77s /   137ss\n",
      "[===========>            25%                       ] 334000/1329487   77s /   232s\n",
      "FUTURE #2 complete. Time used: 82 seconds\n",
      "[==================================================] 507896/507896   100s /   164s\n",
      "\n",
      "FUTURE #3 complete. Time used: 105 seconds\n",
      "[==================================================] 536361/536361  105s /    79ss\n",
      "[======================= 58% >                     ] 542000/941763  105s /    76ss\n",
      "FUTURE #4 complete. Time used: 110 seconds\n",
      "[==================================================] 941763/941763   151s /    61s\n",
      "\n",
      "FUTURE #5 complete. Time used: 155 seconds\n",
      "[==================================================] 1329487/1329487  183s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 189 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4326, 5767, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4326, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4326, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 17 mins 47.4 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  77s /     8s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 26.2 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 10/10  43s /     4s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20181006 - 0.0048\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0180)\n",
      "None.\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20181006\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5767, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20181006\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5767, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20181006\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5767, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20181006\n",
      "time used: 00 mins 47.4 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: []\n",
      "--------------------------------------------------\n",
      "dates from input file: 10\n",
      "['20180608', '20180702', '20180714', '20180726', '20180807', '20180819', '20180831', '20180912', '20180924', '20181006']\n",
      "--------------------------------------------------\n",
      "using all dates to calculate the time function\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5\n",
      "split along y dimension (5767) into 2 boxes\n",
      "    with each box up to 2884 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 2 --------------\n",
      "box width:  7331\n",
      "box length: 2884\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13305159 out of 21142604 (62.9%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 2 --------------\n",
      "box width:  7331\n",
      "box length: 2883\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13118977 out of 21135273 (62.1%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [2884, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [2884, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [2884, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [2884, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [2884, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5.\n",
      "time used: 00 mins 18.4 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7331, 5767)\n",
      "subset coverage in y/x: (0, 0, 7331, 5767)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7331/5767\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.25, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 02 mins 33.9 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2018_ERA5\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 85 mins 14.0 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "working on AT137, 2019\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase_ERA5.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/2019_SenAT137.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-07-09 23:48:43.101287--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: 2019_SenAT137\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/2019_SenAT137.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*unw_phase_ERA5_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy 2019_SenAT137.txt    to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg to inputs   directory for backup.\n",
      "copy 2019_SenAT137.txt    to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/2019_SenAT137.txt --project 2019_SenAT137\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*unw_phase_ERA5_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3_app/AT137/2019/S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D/S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3_app/AT137/2019/S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D/S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3_app/AT137/2019/S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D/S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5767, 7331) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5767, 7331) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5767, 7331) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20190603T011048_20190615T011048_VVP012_INT40_G_ueF_DE9D_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5767, 7331) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*unw_phase_ERA5_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3_app/AT137/2019/*/*2019*corr_clipped.tif\n",
      "number of unwrapPhase     : 66\n",
      "number of coherence       : 66\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (66, 5767, 7331) with compression = None\n",
      "[==================================================] 20191001_20191013  418s /     8s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (66, 5767, 7331) with compression = None\n",
      "[==================================================] 20191001_20191013  409s /     8s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (66, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (66,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (66,)\n",
      "add extra metadata: {'PROJECT_NAME': '2019_SenAT137', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 15 mins 16.6 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file 2019_SenAT137.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file 2019_SenAT137.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 66/66   78s /     1s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 12\n",
      "number of interferograms: 66\n",
      "shift all perp baseline by -12.236592292785645 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 66\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 228.22 m\n",
      "max temporal      baseline: 132.0 days\n",
      "showing coherence\n",
      "data range: [0.51316994, 0.8840532]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 66/66   71s /     1s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/maskConnComp.h5\n",
      "time used: 01 mins 14.7 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5767/5767   62s /     7s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/avgSpatialCoh.h5\n",
      "time used: 01 mins 13.5 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5767/5767   67s /     8s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (3871, 2487)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5\n",
      "{'REF_Y': '3871', 'REF_X': '2487', 'REF_LAT': '4732820.0', 'REF_LON': '598460.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5767/5767   76s /     9s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/avgPhaseVelocity.h5\n",
      "time used: 01 mins 28.5 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 66\n",
      "number of triplets: 220\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (140, 7331), 42 blocks in total\n",
      "reference pixel in y/x: (3871, 2487) from dataset: unwrapPhase\n",
      "[==================================================] line 5740 / 5767  261s /     5s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/numTriNonzeroIntAmbiguity.png\n",
      "time used: 04 mins 30.5 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (3871, 2487) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 66\n",
      "number of acquisitions  : 12\n",
      "number of lines   : 5767\n",
      "number of columns : 7331\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (12,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (12,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (12, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5767 lines into 9 patches for processing\n",
      "    with each patch up to 650 lines\n",
      "\n",
      "------- processing patch 1 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 650\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 650]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 650]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 650]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 650]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 650]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 650]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 0, 4888, 650] * 66 ...\n",
      "reading coherence in [2444, 0, 3666, 650] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 0, 6110, 650] * 66 ...\n",
      "reading coherence in [6110, 0, 7331, 650] * 66 ...\n",
      "reading coherence in [0, 0, 1222, 650] * 66 ...\n",
      "reading coherence in [1222, 0, 2444, 650] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [4888, 0, 6110, 650] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [0, 0, 1222, 650] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [3666, 0, 4888, 650] * 66 ...\n",
      "reading unwrapPhase in [2444, 0, 3666, 650] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1222, 0, 2444, 650] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [6110, 0, 7331, 650] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 0 out of 794300 (0.0%)\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 0 out of 794300 (0.0%)\n",
      "\n",
      "FUTURE #1 complete. Time used: 15 seconds\n",
      "number of pixels to invert: 20431 out of 794300 (2.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 166246 out of 794300 (20.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "\n",
      "FUTURE #2 complete. Time used: 15 seconds\n",
      "[>                                                 ]number of pixels to invert: 87405 out of 793650 (11.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 129609 out of 794300 (16.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 20431/20431 pixels    9s /    30ss\n",
      "converting LOS phase unit from radian to meter\n",
      "[=======>                16%                       ] 20400/129609 pixels    9s /    48s\n",
      "FUTURE #3 complete. Time used: 24 seconds\n",
      "[==================================================] 87405/87405 pixels    38s /    19s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 67% =====>                ] 86400/129609 pixels   38s /    19s\n",
      "FUTURE #4 complete. Time used: 54 seconds\n",
      "[==================================================] 129609/129609 pixels   55s /    15s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #5 complete. Time used: 70 seconds\n",
      "[==================================================] 166246/166246 pixels   65s /     1s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 80 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 0, 650, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 650, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 650, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 01 mins 27.4 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 650\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 650, 1222, 1300]\n",
      "submit a job to the worker for sub box 1: [1222, 650, 2444, 1300]\n",
      "submit a job to the worker for sub box 2: [2444, 650, 3666, 1300]\n",
      "submit a job to the worker for sub box 3: [3666, 650, 4888, 1300]\n",
      "submit a job to the worker for sub box 4: [4888, 650, 6110, 1300]\n",
      "submit a job to the worker for sub box 5: [6110, 650, 7331, 1300]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 650, 1222, 1300] * 66 ...\n",
      "reading coherence in [6110, 650, 7331, 1300] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 650, 3666, 1300] * 66 ...\n",
      "reading coherence in [1222, 650, 2444, 1300] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 650, 6110, 1300] * 66 ...\n",
      "reading coherence in [3666, 650, 4888, 1300] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [6110, 650, 7331, 1300] * 66 ...\n",
      "reading unwrapPhase in [3666, 650, 4888, 1300] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [0, 650, 1222, 1300] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [2444, 650, 3666, 1300] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [4888, 650, 6110, 1300] * 66 ...\n",
      "reading unwrapPhase in [1222, 650, 2444, 1300] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 737823 out of 794300 (92.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 25525 out of 794300 (3.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 262614 out of 793650 (33.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 287002 out of 794300 (36.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 784183 out of 794300 (98.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 25525/25525 pixels    12s /   402s\n",
      "[===>                     9%                       ] 25800/287002 pixels   12s /   126sconverting LOS phase unit from radian to meter\n",
      "[=>                       3%                       ] 25800/794300 pixels   12s /   405s\n",
      "FUTURE #1 complete. Time used: 28 seconds\n",
      "[==================================================] 262614/262614 pixels  119s /   221s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=================>      36%                       ] 262000/737823 pixels  119s /   212s\n",
      "FUTURE #2 complete. Time used: 135 seconds\n",
      "[==================================================] 287002/287002 pixels  128s /   229s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=================>      36%                       ] 279000/784183 pixels  128s /   229s\n",
      "FUTURE #3 complete. Time used: 144 seconds\n",
      "[==================================================] 737823/737823 pixels  277s /    24s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 91% =================>    ] 714800/784183 pixels  277s /    27s\n",
      "FUTURE #4 complete. Time used: 292 seconds\n",
      "[==================================================] 794300/794300 pixels  293s /     5s\n",
      "[==================================================] 780200/784183 pixelsconverting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #5 complete. Time used: 311 seconds\n",
      "[==================================================] 784183/784183 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 312 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 650, 1300, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [650, 1300, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [650, 1300, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 06 mins 43.8 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 650\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1300, 1222, 1950]\n",
      "submit a job to the worker for sub box 1: [1222, 1300, 2444, 1950]\n",
      "submit a job to the worker for sub box 2: [2444, 1300, 3666, 1950]\n",
      "submit a job to the worker for sub box 3: [3666, 1300, 4888, 1950]\n",
      "submit a job to the worker for sub box 4: [4888, 1300, 6110, 1950]\n",
      "submit a job to the worker for sub box 5: [6110, 1300, 7331, 1950]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 1300, 7331, 1950] * 66 ...\n",
      "reading coherence in [3666, 1300, 4888, 1950] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 1300, 6110, 1950] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 1300, 2444, 1950] * 66 ...\n",
      "reading coherence in [0, 1300, 1222, 1950] * 66 ...\n",
      "reading coherence in [2444, 1300, 3666, 1950] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [0, 1300, 1222, 1950] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1222, 1300, 2444, 1950] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [4888, 1300, 6110, 1950] * 66 ...\n",
      "reading unwrapPhase in [3666, 1300, 4888, 1950] * 66 ...\n",
      "reading unwrapPhase in [2444, 1300, 3666, 1950] * 66 ...\n",
      "reading unwrapPhase in [6110, 1300, 7331, 1950] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 586271 out of 794300 (73.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 352549 out of 793650 (44.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 792040 out of 794300 (99.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 352549/352549 pixels  190s /   242s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=====================>  45%                       ] 358800/794300 pixels  190s /   233s\n",
      "FUTURE #1 complete. Time used: 207 seconds\n",
      "[==================================================] 586271/586271 pixels  291s /   107s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 74% ========>             ] 591200/794300 pixels  291s /   102s\n",
      "FUTURE #2 complete. Time used: 307 seconds\n",
      "[==================================================] 794300/794300 pixels  363s /    11s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 789200/794300 pixels  363s /    11s\n",
      "FUTURE #3 complete. Time used: 379 seconds\n",
      "[==================================================] 792040/792040 pixels  364s /    11s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 770800/794300 pixels  364s /    11s\n",
      "FUTURE #4 complete. Time used: 380 seconds\n",
      "[==================================================] 794300/794300 pixels  364s /    11s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 773000/794300 pixels  364s /    11s\n",
      "FUTURE #5 complete. Time used: 381 seconds\n",
      "[==================================================] 794300/794300 pixels  368s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 388 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 1300, 1950, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [1300, 1950, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [1300, 1950, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 13 mins 16.7 secs.\n",
      "\n",
      "\n",
      "------- processing patch 4 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 650\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1950, 1222, 2600]\n",
      "submit a job to the worker for sub box 1: [1222, 1950, 2444, 2600]\n",
      "submit a job to the worker for sub box 2: [2444, 1950, 3666, 2600]\n",
      "submit a job to the worker for sub box 3: [3666, 1950, 4888, 2600]\n",
      "submit a job to the worker for sub box 4: [4888, 1950, 6110, 2600]\n",
      "submit a job to the worker for sub box 5: [6110, 1950, 7331, 2600]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 1950, 7331, 2600] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 1950, 3666, 2600] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 1950, 6110, 2600] * 66 ...\n",
      "reading coherence in [0, 1950, 1222, 2600] * 66 ...\n",
      "reading coherence in [3666, 1950, 4888, 2600] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 1950, 2444, 2600] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1222, 1950, 2444, 2600] * 66 ...\n",
      "reading unwrapPhase in [0, 1950, 1222, 2600] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [4888, 1950, 6110, 2600] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [2444, 1950, 3666, 2600] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [6110, 1950, 7331, 2600] * 66 ...\n",
      "reading unwrapPhase in [3666, 1950, 4888, 2600] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 432991 out of 793650 (54.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "number of pixels to invert: 532962 out of 794300 (67.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 736577 out of 794300 (92.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 432991/432991 pixels  216s /   184s\n",
      "[======================= 58% >                     ] 430200/736577 pixels  216s /   156sconverting LOS phase unit from radian to meter\n",
      "[======================= 82% ============>         ] 434400/532962 pixels  216s /    47s\n",
      "FUTURE #1 complete. Time used: 233 seconds\n",
      "[==================================================] 532962/532962 pixels  257s /   100s\n",
      "[======================= 67% =====>                ] 531000/794300 pixels  257s /   127sconverting LOS phase unit from radian to meter\n",
      "[======================= 67% =====>                ] 533600/794300 pixels  258s /   127s\n",
      "FUTURE #2 complete. Time used: 274 seconds\n",
      "[==================================================] 736577/736577 pixels  334s /    21s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 94% ==================>   ] 745200/794300 pixels  334s /    21s\n",
      "FUTURE #3 complete. Time used: 351 seconds\n",
      "[==================================================] 794300/794300 pixels  352s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 790000/794300 pixels\n",
      "FUTURE #4 complete. Time used: 368 seconds\n",
      "[==================================================] 794300/794300 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #5 complete. Time used: 370 seconds\n",
      "[==================================================] 794300/794300 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 372 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 1950, 2600, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [1950, 2600, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [1950, 2600, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 19 mins 33.4 secs.\n",
      "\n",
      "\n",
      "------- processing patch 5 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 650\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2600, 1222, 3250]\n",
      "submit a job to the worker for sub box 1: [1222, 2600, 2444, 3250]\n",
      "submit a job to the worker for sub box 2: [2444, 2600, 3666, 3250]\n",
      "submit a job to the worker for sub box 3: [3666, 2600, 4888, 3250]\n",
      "submit a job to the worker for sub box 4: [4888, 2600, 6110, 3250]\n",
      "submit a job to the worker for sub box 5: [6110, 2600, 7331, 3250]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 2600, 6110, 3250] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 2600, 2444, 3250] * 66 ...\n",
      "reading coherence in [2444, 2600, 3666, 3250] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 2600, 7331, 3250] * 66 ...\n",
      "reading coherence in [3666, 2600, 4888, 3250] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 2600, 1222, 3250] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1222, 2600, 2444, 3250] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [3666, 2600, 4888, 3250] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [4888, 2600, 6110, 3250] * 66 ...\n",
      "reading unwrapPhase in [6110, 2600, 7331, 3250] * 66 ...\n",
      "reading unwrapPhase in [0, 2600, 1222, 3250] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [2444, 2600, 3666, 3250] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 514806 out of 793650 (64.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 443840 out of 794300 (55.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 443840/443840 pixels  221s /   174s\n",
      "[======================= 56%                       ] 441800/794300 pixels  221s /   174sconverting LOS phase unit from radian to meter\n",
      "[======================= 56%                       ] 448400/794300 pixels  221s /   174s\n",
      "FUTURE #1 complete. Time used: 237 seconds\n",
      "[==================================================] 514806/514806 pixels  254s /   136s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 65% ===>                  ] 519200/794300 pixels  254s /   136s\n",
      "FUTURE #2 complete. Time used: 269 seconds\n",
      "[==================================================] 794300/794300 pixels  350s /    10s\n",
      "[======================= 98% ====================> ] 782200/794300 pixels  350s /     7sconverting LOS phase unit from radian to meter\n",
      "[======================= 97% ===================>  ] 771000/794300 pixels  350s /    10s\n",
      "FUTURE #3 complete. Time used: 365 seconds\n",
      "[==================================================] 794300/794300 pixels  351s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 774800/794300 pixels  351s /     7s\n",
      "FUTURE #4 complete. Time used: 366 seconds\n",
      "[==================================================] 794300/794300 pixels  353s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 783200/794300 pixels\n",
      "FUTURE #5 complete. Time used: 369 seconds\n",
      "[==================================================] 794300/794300 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 373 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 2600, 3250, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [2600, 3250, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [2600, 3250, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 25 mins 50.6 secs.\n",
      "\n",
      "\n",
      "------- processing patch 6 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 650\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 3250, 1222, 3900]\n",
      "submit a job to the worker for sub box 1: [1222, 3250, 2444, 3900]\n",
      "submit a job to the worker for sub box 2: [2444, 3250, 3666, 3900]\n",
      "submit a job to the worker for sub box 3: [3666, 3250, 4888, 3900]\n",
      "submit a job to the worker for sub box 4: [4888, 3250, 6110, 3900]\n",
      "submit a job to the worker for sub box 5: [6110, 3250, 7331, 3900]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 3250, 6110, 3900] * 66 ...\n",
      "reading coherence in [0, 3250, 1222, 3900] * 66 ...\n",
      "reading coherence in [1222, 3250, 2444, 3900] * 66 ...\n",
      "reading coherence in [2444, 3250, 3666, 3900] * 66 ...\n",
      "reading coherence in [6110, 3250, 7331, 3900] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 3250, 4888, 3900] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [6110, 3250, 7331, 3900] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1222, 3250, 2444, 3900] * 66 ...\n",
      "reading unwrapPhase in [2444, 3250, 3666, 3900] * 66 ...\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [0, 3250, 1222, 3900] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [4888, 3250, 6110, 3900] * 66 ...\n",
      "reading unwrapPhase in [3666, 3250, 4888, 3900] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 355219 out of 794300 (44.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 602874 out of 793650 (76.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794299 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 355219/355219 pixels  177s /   118s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=====================>  44%                       ] 350200/794300 pixels  177s /   226s\n",
      "FUTURE #1 complete. Time used: 194 seconds\n",
      "[==================================================] 602874/602874 pixels  279s /    93s\n",
      "[======================= 74% ========>             ] 590600/794300 pixels  279s /    98sconverting LOS phase unit from radian to meter\n",
      "[======================= 75% =========>            ] 599400/794300 pixels  279s /    93s\n",
      "FUTURE #2 complete. Time used: 295 seconds\n",
      "[==================================================] 794300/794300 pixels  350s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 782400/794300 pixels  350s /     7s\n",
      "FUTURE #3 complete. Time used: 367 seconds\n",
      "[==================================================] 794300/794300 pixels  353s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 788200/794299 pixels\n",
      "FUTURE #4 complete. Time used: 372 seconds\n",
      "[==================================================] 794300/794300 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 792800/794299 pixels\n",
      "FUTURE #5 complete. Time used: 373 seconds\n",
      "[==================================================] 794299/794299 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 373 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 3250, 3900, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [3250, 3900, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [3250, 3900, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 32 mins 8.8 secs.\n",
      "\n",
      "\n",
      "------- processing patch 7 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 650\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 3900, 1222, 4550]\n",
      "submit a job to the worker for sub box 1: [1222, 3900, 2444, 4550]\n",
      "submit a job to the worker for sub box 2: [2444, 3900, 3666, 4550]\n",
      "submit a job to the worker for sub box 3: [3666, 3900, 4888, 4550]\n",
      "submit a job to the worker for sub box 4: [4888, 3900, 6110, 4550]\n",
      "submit a job to the worker for sub box 5: [6110, 3900, 7331, 4550]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 3900, 1222, 4550] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 3900, 6110, 4550] * 66 ...\n",
      "reading coherence in [3666, 3900, 4888, 4550] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 3900, 2444, 4550] * 66 ...\n",
      "reading coherence in [6110, 3900, 7331, 4550] * 66 ...\n",
      "reading coherence in [2444, 3900, 3666, 4550] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [2444, 3900, 3666, 4550] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [4888, 3900, 6110, 4550] * 66 ...\n",
      "reading unwrapPhase in [1222, 3900, 2444, 4550] * 66 ...\n",
      "reading unwrapPhase in [6110, 3900, 7331, 4550] * 66 ...\n",
      "reading unwrapPhase in [0, 3900, 1222, 4550] * 66 ...\n",
      "reading unwrapPhase in [3666, 3900, 4888, 4550] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "number of pixels to invert: 257451 out of 794300 (32.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 678245 out of 793650 (85.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 257451/257451 pixels  128s /   273s\n",
      "converting LOS phase unit from radian to meter\n",
      "[===============>        32%                       ] 254000/794300 pixels  128s /   273s\n",
      "FUTURE #1 complete. Time used: 144 seconds\n",
      "[==================================================] 678245/678245 pixels  310s /    59s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 84% =============>        ] 670400/794300 pixels  310s /    59s\n",
      "FUTURE #2 complete. Time used: 326 seconds\n",
      "[==================================================] 794300/794300 pixels  354s /     7s\n",
      "[==================================================] 792400/794300 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 792600/794300 pixels\n",
      "[==================================================] 792000/794300 pixels\n",
      "[==================================================] 794300/794300 pixels \n",
      "[==================================================] 793600/794300 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 793400/794300 pixels\n",
      "FUTURE #4 complete. Time used: 374 seconds\n",
      "[==================================================] 794300/794300 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 794200/794300 pixels\n",
      "FUTURE #5 complete. Time used: 374 seconds\n",
      "[==================================================] 794300/794300 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 374 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 3900, 4550, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [3900, 4550, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [3900, 4550, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 38 mins 27.9 secs.\n",
      "\n",
      "\n",
      "------- processing patch 8 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 650\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4550, 1222, 5200]\n",
      "submit a job to the worker for sub box 1: [1222, 4550, 2444, 5200]\n",
      "submit a job to the worker for sub box 2: [2444, 4550, 3666, 5200]\n",
      "submit a job to the worker for sub box 3: [3666, 4550, 4888, 5200]\n",
      "submit a job to the worker for sub box 4: [4888, 4550, 6110, 5200]\n",
      "submit a job to the worker for sub box 5: [6110, 4550, 7331, 5200]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 4550, 6110, 5200] * 66 ...\n",
      "reading coherence in [1222, 4550, 2444, 5200] * 66 ...\n",
      "reading coherence in [6110, 4550, 7331, 5200] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 4550, 4888, 5200] * 66 ...\n",
      "reading coherence in [0, 4550, 1222, 5200] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 4550, 3666, 5200] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 1 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 2 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 3 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 4 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 5 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 6 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 7 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [1222, 4550, 2444, 5200] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [2444, 4550, 3666, 5200] * 66 ...\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [6110, 4550, 7331, 5200] * 66 ...\n",
      "reading unwrapPhase in [3666, 4550, 4888, 5200] * 66 ...\n",
      "reading unwrapPhase in [0, 4550, 1222, 5200] * 66 ...\n",
      "reading unwrapPhase in [4888, 4550, 6110, 5200] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 794300 out of 794300 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 234535 out of 794300 (29.5%)\n",
      "number of pixels to invert: 262609 out of 794300 (33.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 187281 out of 794300 (23.6%)\n",
      "number of pixels to invert: 646238 out of 794300 (81.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 65687 out of 793650 (8.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 65687/65687 pixels    32s /   376s\n",
      "[====>                   10%                       ] 64600/646238 pixels   32s /   295sconverting LOS phase unit from radian to meter\n",
      "[===>                     8%                       ] 64800/794300 pixels   32s /   378s\n",
      "FUTURE #1 complete. Time used: 47 seconds\n",
      "[==================================================] 187281/187281 pixels   89s /   220s\n",
      "converting LOS phase unit from radian to meter\n",
      "[===========>            24%                       ] 187800/794300 pixels   90s /   285s\n",
      "FUTURE #2 complete. Time used: 105 seconds\n",
      "[==================================================] 234535/234535 pixels  107s /    11s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=================>      37%                       ] 236200/646238 pixels  107s /   182s\n",
      "FUTURE #3 complete. Time used: 122 seconds\n",
      "[==================================================] 262609/262609 pixels  115s /   165s\n",
      "converting LOS phase unit from radian to meter\n",
      "[===================>    41%                       ] 262600/646238 pixels  115s /   166s\n",
      "FUTURE #4 complete. Time used: 130 seconds\n",
      "[==================================================] 646238/646238 pixels  220s /    48s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 82% ============>         ] 652800/794300 pixels  220s /    48s\n",
      "FUTURE #5 complete. Time used: 235 seconds\n",
      "[==================================================] 794300/794300 pixels  250s /     5s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 268 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 4550, 5200, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4550, 5200, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4550, 5200, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 43 mins 0.3 secs.\n",
      "\n",
      "\n",
      "------- processing patch 9 out of 9 --------------\n",
      "box width:  7331\n",
      "box length: 567\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 5200, 1222, 5767]\n",
      "submit a job to the worker for sub box 1: [1222, 5200, 2444, 5767]\n",
      "submit a job to the worker for sub box 2: [2444, 5200, 3666, 5767]\n",
      "submit a job to the worker for sub box 3: [3666, 5200, 4888, 5767]\n",
      "submit a job to the worker for sub box 4: [4888, 5200, 6110, 5767]\n",
      "submit a job to the worker for sub box 5: [6110, 5200, 7331, 5767]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 5200, 1222, 5767] * 66 ...\n",
      "reading coherence in [2444, 5200, 3666, 5767] * 66 ...\n",
      "reading coherence in [1222, 5200, 2444, 5767] * 66 ...\n",
      "reading coherence in [4888, 5200, 6110, 5767] * 66 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 5200, 4888, 5767] * 66 ...\n",
      "reading coherence in [6110, 5200, 7331, 5767] * 66 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 7 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 7\n",
      "chunk 1 / 7\n",
      "chunk 1 / 7\n",
      "chunk 1 / 7\n",
      "chunk 1 / 7\n",
      "chunk 1 / 7\n",
      "chunk 2 / 7\n",
      "chunk 2 / 7\n",
      "chunk 2 / 7\n",
      "chunk 2 / 7\n",
      "chunk 2 / 7\n",
      "chunk 2 / 7\n",
      "chunk 3 / 7\n",
      "chunk 3 / 7\n",
      "chunk 3 / 7\n",
      "chunk 3 / 7\n",
      "chunk 3 / 7\n",
      "chunk 3 / 7\n",
      "chunk 4 / 7\n",
      "chunk 4 / 7\n",
      "chunk 4 / 7\n",
      "chunk 4 / 7\n",
      "chunk 4 / 7\n",
      "chunk 4 / 7\n",
      "chunk 5 / 7\n",
      "chunk 5 / 7\n",
      "chunk 5 / 7\n",
      "chunk 5 / 7\n",
      "chunk 5 / 7\n",
      "chunk 5 / 7\n",
      "chunk 6 / 7\n",
      "chunk 6 / 7\n",
      "chunk 6 / 7\n",
      "chunk 6 / 7\n",
      "chunk 6 / 7\n",
      "chunk 6 / 7\n",
      "chunk 7 / 7\n",
      "reading unwrapPhase in [0, 5200, 1222, 5767] * 66 ...\n",
      "chunk 7 / 7\n",
      "reading unwrapPhase in [1222, 5200, 2444, 5767] * 66 ...\n",
      "chunk 7 / 7\n",
      "reading unwrapPhase in [2444, 5200, 3666, 5767] * 66 ...\n",
      "chunk 7 / 7\n",
      "chunk 7 / 7\n",
      "reading unwrapPhase in [6110, 5200, 7331, 5767] * 66 ...\n",
      "reading unwrapPhase in [4888, 5200, 6110, 5767] * 66 ...\n",
      "chunk 7 / 7\n",
      "reading unwrapPhase in [3666, 5200, 4888, 5767] * 66 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 261384 out of 692874 (37.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 692307 (0.0%)\n",
      "number of pixels to invert: 21732 out of 692874 (3.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 692874 (0.0%)\n",
      "number of pixels to invert: 66916 out of 692874 (9.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 0 out of 692874 (0.0%)\n",
      "[>                                                 ]\n",
      "FUTURE #1 complete. Time used: 13 seconds\n",
      "[>                        2%                       ] 400/21732 pixels    0s /     9s\n",
      "FUTURE #2 complete. Time used: 13 seconds\n",
      "[>                                                 ]\n",
      "FUTURE #3 complete. Time used: 13 seconds\n",
      "[==================================================] 21732/21732 pixels    7s /    15ss\n",
      "converting LOS phase unit from radian to meter\n",
      "[===============>        33%                       ] 21800/66916 pixels    7s /    14ss\n",
      "FUTURE #4 complete. Time used: 20 seconds\n",
      "[==================================================] 66916/66916 pixels    20s /    57s\n",
      "converting LOS phase unit from radian to meter\n",
      "[============>           26%                       ] 67400/261384 pixels   20s /    57s\n",
      "FUTURE #5 complete. Time used: 33 seconds\n",
      "[==================================================] 261384/261384 pixels   66s /     1s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 80 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 5200, 5767, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [5200, 5767, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [5200, 5767, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 44 mins 24.9 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (3871, 2487)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 66\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 44 mins 24.9 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5767, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/maskTempCoh.h5\n",
      "time used: 00 mins 1.8 secs.\n",
      "number of reliable pixels: 19935391\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (12,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (12,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (12, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 12/12   98s /     8s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 46.9 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (12,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (12,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (12, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (12,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (12,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (12, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 1442]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 1442]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 1442]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 1442]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 1442]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 1442]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 141765 out of 1762124 (8.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 460526 out of 1762124 (26.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1134070 out of 1762124 (64.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 419339 out of 1760682 (23.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 931778 out of 1762124 (52.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1087316 out of 1762124 (61.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 141765/141765    37s /   274s\n",
      "[=======>                15%                       ] 140000/931778   37s /   213s\n",
      "FUTURE #1 complete. Time used: 42 seconds\n",
      "[==================================================] 419339/419339    92s /   145s\n",
      "[===================>    39%                       ] 428000/1087316   93s /   145s\n",
      "FUTURE #2 complete. Time used: 97 seconds\n",
      "[==================================================] 460526/460526    99s /   132s\n",
      "[===================>    41%                       ] 466000/1134070  100s /   144s\n",
      "FUTURE #3 complete. Time used: 104 seconds\n",
      "[==================================================] 931778/931778   167s /    34s\n",
      "[======================= 87% ===============>      ] 944000/1087316  167s /    25s\n",
      "FUTURE #4 complete. Time used: 172 seconds\n",
      "[==================================================] 1087316/1087316  185s /     9s\n",
      "[======================= 95% ===================>  ] 1082000/1134070  185s /     9s\n",
      "FUTURE #5 complete. Time used: 189 seconds\n",
      "[==================================================] 1134070/1134070  189s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 195 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1442, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1442, 1222, 2884]\n",
      "submit a job to the worker for sub box 1: [1222, 1442, 2444, 2884]\n",
      "submit a job to the worker for sub box 2: [2444, 1442, 3666, 2884]\n",
      "submit a job to the worker for sub box 3: [3666, 1442, 4888, 2884]\n",
      "submit a job to the worker for sub box 4: [4888, 1442, 6110, 2884]\n",
      "submit a job to the worker for sub box 5: [6110, 1442, 7331, 2884]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1702141 out of 1762124 (96.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 930660 out of 1760682 (52.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1208084 out of 1762124 (68.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 930660/930660   223s /   205s\n",
      "[======================= 55%                       ] 944000/1702141  223s /   182s\n",
      "FUTURE #1 complete. Time used: 227 seconds\n",
      "[==================================================] 1208084/1208084  272s /   134s\n",
      "[======================= 70% ======>               ] 1200000/1702141  272s /   116s\n",
      "FUTURE #2 complete. Time used: 277 seconds\n",
      "[==================================================] 1702141/1702141  357s /    11s\n",
      "[======================= 97% ===================>  ] 1712000/1762124  357s /    11s\n",
      "FUTURE #3 complete. Time used: 362 seconds\n",
      "[==================================================] 1762124/1762124  366s /    11s\n",
      "[======================= 97% ===================>  ] 1716000/1762124  366s /    11s\n",
      "FUTURE #4 complete. Time used: 370 seconds\n",
      "[==================================================] 1762124/1762124  367s /     7s\n",
      "[======================= 98% ====================> ] 1722000/1762124  367s /     7s\n",
      "FUTURE #5 complete. Time used: 372 seconds\n",
      "[==================================================] 1762124/1762124  369s /     7s\n",
      "\n",
      "FUTURE #6 complete. Time used: 377 seconds\n",
      "close dask client\n",
      "2023-07-10 01:11:36,190 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/worker.py\", line 1237, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/utils_comm.py\", line 413, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/core.py\", line 1365, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/core.py\", line 1124, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 241, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:59212 remote=tcp://127.0.0.1:36887>: Stream is closed\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1442, 2884, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2884, 1222, 4326]\n",
      "submit a job to the worker for sub box 1: [1222, 2884, 2444, 4326]\n",
      "submit a job to the worker for sub box 2: [2444, 2884, 3666, 4326]\n",
      "submit a job to the worker for sub box 3: [3666, 2884, 4888, 4326]\n",
      "submit a job to the worker for sub box 4: [4888, 2884, 6110, 4326]\n",
      "submit a job to the worker for sub box 5: [6110, 2884, 7331, 4326]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 770269 out of 1762124 (43.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762123 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1344369 out of 1760682 (76.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 770269/770269   184s /   234s\n",
      "[=====================>  44%                       ] 770000/1762123  184s /   234s\n",
      "FUTURE #1 complete. Time used: 189 seconds\n",
      "[==================================================] 1344369/1344369  297s /    93s\n",
      "[======================= 76% =========>            ] 1342000/1762124  297s /    93s\n",
      "FUTURE #2 complete. Time used: 302 seconds\n",
      "[==================================================] 1762124/1762124  364s /     7s\n",
      "[==================================================] 1758000/1762123\n",
      "FUTURE #3 complete. Time used: 371 seconds\n",
      "[==================================================] 1762123/1762123 \n",
      "[==================================================] 1754000/1762124\n",
      "FUTURE #4 complete. Time used: 372 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #5 complete. Time used: 373 seconds\n",
      "\n",
      "FUTURE #6 complete. Time used: 373 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2884, 4326, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1441\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4326, 1222, 5767]\n",
      "submit a job to the worker for sub box 1: [1222, 4326, 2444, 5767]\n",
      "submit a job to the worker for sub box 2: [2444, 4326, 3666, 5767]\n",
      "submit a job to the worker for sub box 3: [3666, 4326, 4888, 5767]\n",
      "submit a job to the worker for sub box 4: [4888, 4326, 6110, 5767]\n",
      "submit a job to the worker for sub box 5: [6110, 4326, 7331, 5767]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1329412 out of 1760902 (75.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 335347 out of 1760902 (19.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 302803 out of 1759461 (17.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 508263 out of 1760902 (28.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 941698 out of 1760902 (53.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 536337 out of 1760902 (30.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 302803/302803   71s /    56ss\n",
      "[===========>            23%                       ] 300000/1329412   72s /   241s\n",
      "FUTURE #1 complete. Time used: 76 seconds\n",
      "[==================================================] 335347/335347   78s /   146ss\n",
      "[===========>            25%                       ] 334000/1329412   78s /   236s\n",
      "FUTURE #2 complete. Time used: 83 seconds\n",
      "[==================================================] 508263/508263   109s /   178s\n",
      "[======================= 54%                       ] 510000/941698  109s /    93s\n",
      "FUTURE #3 complete. Time used: 114 seconds\n",
      "[==================================================] 536337/536337  113s /    89ss\n",
      "[===================>    40%                       ] 530000/1329412  113s /   170s\n",
      "FUTURE #4 complete. Time used: 118 seconds\n",
      "[==================================================] 941698/941698   161s /    69s\n",
      "[======================= 70% ======>               ] 928000/1329412  161s /    69s\n",
      "FUTURE #5 complete. Time used: 166 seconds\n",
      "[==================================================] 1329412/1329412  199s /     4s\n",
      "\n",
      "FUTURE #6 complete. Time used: 206 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4326, 5767, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 4326, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 12, 4326, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 19 mins 37.5 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (12,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (12,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (12, 5767, 7331)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 12/12   98s /     8s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 47.4 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 12/12   65s /     5s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20191013 - 0.0055\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0188)\n",
      "None.\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20191013\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 12, 0, 5767, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20191013\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 12, 0, 5767, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20191013\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 12, 0, 5767, 0, 7331)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20191013\n",
      "time used: 00 mins 52.2 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: []\n",
      "--------------------------------------------------\n",
      "dates from input file: 12\n",
      "['20190603', '20190615', '20190627', '20190709', '20190721', '20190802', '20190814', '20190826', '20190907', '20190919', '20191001', '20191013']\n",
      "--------------------------------------------------\n",
      "using all dates to calculate the time function\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5767, 7331)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5\n",
      "split along y dimension (5767) into 3 boxes\n",
      "    with each box up to 1923 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 3 --------------\n",
      "box width:  7331\n",
      "box length: 1923\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 7238419 out of 14097513 (51.3%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 1923, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 1923, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 1923, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 1923, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 1923, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 3 --------------\n",
      "box width:  7331\n",
      "box length: 1923\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 12185267 out of 14097513 (86.4%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [1923, 3846, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [1923, 3846, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [1923, 3846, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [1923, 3846, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [1923, 3846, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "\n",
      "------- processing patch 3 out of 3 --------------\n",
      "box width:  7331\n",
      "box length: 1921\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 6995359 out of 14082851 (49.7%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [3846, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [3846, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [3846, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [3846, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [3846, 5767, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5.\n",
      "time used: 00 mins 24.7 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7331, 5767)\n",
      "subset coverage in y/x: (0, 0, 7331, 5767)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7331/5767\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.25, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 03 mins 39.0 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2019_ERA5\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 101 mins 7.4 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "working on AT137, 2020\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase_ERA5.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/2020_SenAT137.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-07-10 02:16:50.766239--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: 2020_SenAT137\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/2020_SenAT137.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*unw_phase_ERA5_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy 2020_SenAT137.txt    to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg to inputs   directory for backup.\n",
      "copy 2020_SenAT137.txt    to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/2020_SenAT137.txt --project 2020_SenAT137\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*unw_phase_ERA5_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3_app/AT137/2020/S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0/S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3_app/AT137/2020/S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0/S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3_app/AT137/2020/S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0/S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5765, 7329) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5765, 7329) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5765, 7329) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20200609T011055_20200621T011055_VVP012_INT40_G_ueF_BBA0_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5765, 7329) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*unw_phase_ERA5_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3_app/AT137/2020/*/*2020*corr_clipped.tif\n",
      "number of unwrapPhase     : 45\n",
      "number of coherence       : 45\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (45, 5765, 7329) with compression = None\n",
      "[==================================================] 20200925_20201007  273s /     5s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (45, 5765, 7329) with compression = None\n",
      "[==================================================] 20200925_20201007  277s /     5s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (45, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (45,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (45,)\n",
      "add extra metadata: {'PROJECT_NAME': '2020_SenAT137', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 10 mins 25.7 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file 2020_SenAT137.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file 2020_SenAT137.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5765, 7329)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 45/45   54s /     1s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 10\n",
      "number of interferograms: 45\n",
      "shift all perp baseline by -36.851009368896484 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 45\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 227.57 m\n",
      "max temporal      baseline: 120.0 days\n",
      "showing coherence\n",
      "data range: [0.622384, 0.9394732]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 45/45   50s /     1s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5765, 7329)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/maskConnComp.h5\n",
      "time used: 00 mins 53.7 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   40s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5765, 7329)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/avgSpatialCoh.h5\n",
      "time used: 00 mins 49.2 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   41s /     6s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (1696, 4609)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5\n",
      "{'REF_Y': '1696', 'REF_X': '4609', 'REF_LAT': '4819740.0', 'REF_LON': '683420.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   46s /     7s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5765, 7329)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/avgPhaseVelocity.h5\n",
      "time used: 00 mins 57.5 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 45\n",
      "number of triplets: 120\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (250, 7329), 24 blocks in total\n",
      "reference pixel in y/x: (1696, 4609) from dataset: unwrapPhase\n",
      "[==================================================] line 5750 / 5765  148s /     6s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5765, 7329)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/numTriNonzeroIntAmbiguity.png\n",
      "time used: 02 mins 35.5 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (1696, 4609) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 45\n",
      "number of acquisitions  : 10\n",
      "number of lines   : 5765\n",
      "number of columns : 7329\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (10, 5765, 7329)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5765 lines into 6 patches for processing\n",
      "    with each patch up to 970 lines\n",
      "\n",
      "------- processing patch 1 out of 6 --------------\n",
      "box width:  7329\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 970]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 970]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 970]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 970]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 970]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7329, 970]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 0, 1222, 970] * 45 ...\n",
      "reading coherence in [3666, 0, 4888, 970] * 45 ...\n",
      "reading coherence in [1222, 0, 2444, 970] * 45 ...\n",
      "reading coherence in [6110, 0, 7329, 970] * 45 ...\n",
      "reading coherence in [4888, 0, 6110, 970] * 45 ...\n",
      "reading coherence in [2444, 0, 3666, 970] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 0, 4888, 970] * 45 ...\n",
      "reading unwrapPhase in [2444, 0, 3666, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 0, 6110, 970] * 45 ...\n",
      "reading unwrapPhase in [0, 0, 1222, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 0, 2444, 970] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 0, 7329, 970] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "number of pixels to invert: 560878 out of 1185340 (47.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 206272 out of 1182430 (17.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "[>                                                 ]number of pixels to invert: 20483 out of 1185340 (1.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 513405 out of 1185340 (43.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 0 out of 1185340 (0.0%)\n",
      "number of pixels to invert: 357968 out of 1185340 (30.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ] 400/20483 pixels    0s /    11s\n",
      "FUTURE #1 complete. Time used: 16 seconds\n",
      "[==================================================] 20483/20483 pixels     9s /   236s\n",
      "[=>                       4%                       ] 20400/560878 pixels   10s /   247sconverting LOS phase unit from radian to meter\n",
      "[=>                       4%                       ] 20600/560878 pixels   10s /   249s\n",
      "FUTURE #2 complete. Time used: 26 seconds\n",
      "[==================================================] 206272/206272 pixels   76s /   114s\n",
      "[======================= 58% >                     ] 207000/357968 pixels   76s /    55sconverting LOS phase unit from radian to meter\n",
      "[======================= 58% >                     ] 207200/357968 pixels   76s /    55s\n",
      "FUTURE #3 complete. Time used: 92 seconds\n",
      "[==================================================] 357968/357968 pixels  126s /    74s\n",
      "[======================= 63% ===>                  ] 355200/560878 pixels  126s /    74sconverting LOS phase unit from radian to meter\n",
      "[======================= 70% ======>               ] 361000/513405 pixels  126s /    54s\n",
      "FUTURE #4 complete. Time used: 142 seconds\n",
      "[==================================================] 513405/513405 pixels  163s /    18s\n",
      "[======================= 90% ================>     ] 503800/560878 pixels  163s /    18sconverting LOS phase unit from radian to meter\n",
      "[======================= 90% ================>     ] 504000/560878 pixels  163s /    18s\n",
      "FUTURE #5 complete. Time used: 179 seconds\n",
      "[==================================================] 560878/560878 pixels  174s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 192 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 970, 0, 7329]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 970, 0, 7329]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 970, 0, 7329]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 03 mins 18.0 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 6 --------------\n",
      "box width:  7329\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 970, 1222, 1940]\n",
      "submit a job to the worker for sub box 1: [1222, 970, 2444, 1940]\n",
      "submit a job to the worker for sub box 2: [2444, 970, 3666, 1940]\n",
      "submit a job to the worker for sub box 3: [3666, 970, 4888, 1940]\n",
      "submit a job to the worker for sub box 4: [4888, 970, 6110, 1940]\n",
      "submit a job to the worker for sub box 5: [6110, 970, 7329, 1940]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 970, 1222, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 970, 4888, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 970, 3666, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 970, 2444, 1940] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 970, 7329, 1940] * 45 ...\n",
      "reading coherence in [4888, 970, 6110, 1940] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 970, 1222, 1940] * 45 ...\n",
      "reading unwrapPhase in [2444, 970, 3666, 1940] * 45 ...\n",
      "reading unwrapPhase in [3666, 970, 4888, 1940] * 45 ...\n",
      "reading unwrapPhase in [1222, 970, 2444, 1940] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 970, 7329, 1940] * 45 ...\n",
      "reading unwrapPhase in [4888, 970, 6110, 1940] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 605815 out of 1185340 (51.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1051077 out of 1185340 (88.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1183743 out of 1185340 (99.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 489854 out of 1182430 (41.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 1185339 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 1051077/1051077 pixels  436s /    48s\n",
      "[======================= 89% ===============>      ] 1050200/1185340 pixels  436s /    53sconverting LOS phase unit from radian to meter\n",
      "[======================= 89% ===============>      ] 1050400/1185340 pixels  436s /    53s\n",
      "FUTURE #3 complete. Time used: 452 seconds\n",
      "[==================================================] 1185339/1185339 pixels  472s /     9s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1183743/1183743 pixels  472s /     9s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #4 complete. Time used: 489 seconds\n",
      "[======================= 98% ====================> ] 1167400/1185340 pixels  472s /     9s\n",
      "FUTURE #5 complete. Time used: 489 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 493 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 970, 1940, 0, 7329]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [970, 1940, 0, 7329]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [970, 1940, 0, 7329]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 11 mins 35.8 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 6 --------------\n",
      "box width:  7329\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1940, 1222, 2910]\n",
      "submit a job to the worker for sub box 1: [1222, 1940, 2444, 2910]\n",
      "submit a job to the worker for sub box 2: [2444, 1940, 3666, 2910]\n",
      "submit a job to the worker for sub box 3: [3666, 1940, 4888, 2910]\n",
      "submit a job to the worker for sub box 4: [4888, 1940, 6110, 2910]\n",
      "submit a job to the worker for sub box 5: [6110, 1940, 7329, 2910]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 1940, 4888, 2910] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 1940, 3666, 2910] * 45 ...\n",
      "reading coherence in [1222, 1940, 2444, 2910] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 1940, 1222, 2910] * 45 ...\n",
      "reading coherence in [6110, 1940, 7329, 2910] * 45 ...\n",
      "reading coherence in [4888, 1940, 6110, 2910] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "[======================= 56%                       ] 427800/767020 pixels  211s /   166ss"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 767020/767020 pixels   369s /   182s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 67% =====>                ] 792600/1185340 pixels  369s /   182s\n",
      "FUTURE #2 complete. Time used: 386 seconds\n",
      "[==================================================] 1126954/1126954 pixels  485s /    30s\n",
      "[======================= 93% =================>    ] 1103000/1185340 pixels  485s /    36sconverting LOS phase unit from radian to meter\n",
      "[======================= 93% =================>    ] 1103200/1185340 pixels  485s /    36s\n",
      "FUTURE #3 complete. Time used: 501 seconds\n",
      "[==================================================] 1185340/1185340 pixels  506s /    10s\n",
      "[==================================================] 1173600/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1173800/1185340 pixels\n",
      "FUTURE #4 complete. Time used: 523 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "[==================================================] 1179600/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1179800/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 526 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 527 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1940, 2910, 0, 7329]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [1940, 2910, 0, 7329]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [1940, 2910, 0, 7329]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 20 mins 28.2 secs.\n",
      "\n",
      "\n",
      "------- processing patch 4 out of 6 --------------\n",
      "box width:  7329\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2910, 1222, 3880]\n",
      "submit a job to the worker for sub box 1: [1222, 2910, 2444, 3880]\n",
      "submit a job to the worker for sub box 2: [2444, 2910, 3666, 3880]\n",
      "submit a job to the worker for sub box 3: [3666, 2910, 4888, 3880]\n",
      "submit a job to the worker for sub box 4: [4888, 2910, 6110, 3880]\n",
      "submit a job to the worker for sub box 5: [6110, 2910, 7329, 3880]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 2910, 1222, 3880] * 45 ...\n",
      "reading coherence in [3666, 2910, 4888, 3880] * 45 ...\n",
      "reading coherence in [1222, 2910, 2444, 3880] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 2910, 3666, 3880] * 45 ...\n",
      "reading coherence in [4888, 2910, 6110, 3880] * 45 ...\n",
      "reading coherence in [6110, 2910, 7329, 3880] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 2910, 6110, 3880] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 2910, 2444, 3880] * 45 ...\n",
      "reading unwrapPhase in [3666, 2910, 4888, 3880] * 45 ...\n",
      "reading unwrapPhase in [6110, 2910, 7329, 3880] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [2444, 2910, 3666, 3880] * 45 ...\n",
      "reading unwrapPhase in [0, 2910, 1222, 3880] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 569262 out of 1185340 (48.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 862246 out of 1182430 (72.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[=============>          28%                       ] 161200/569262 pixels   78s /   202ss"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 862246/862246 pixels   397s /   146s\n",
      "[======================= 73% =======>              ] 862000/1185340 pixels  397s /   146sconverting LOS phase unit from radian to meter\n",
      "[======================= 73% =======>              ] 867400/1185340 pixels  397s /   147s\n",
      "FUTURE #2 complete. Time used: 413 seconds\n",
      "[==================================================] 1185340/1185340 pixels  502s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1172400/1185340 pixels  502s /    10s\n",
      "FUTURE #3 complete. Time used: 518 seconds\n",
      "[==================================================] 1185340/1185340 pixels  504s /    10s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1171800/1185340 pixels\n",
      "FUTURE #4 complete. Time used: 521 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 1173800/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 522 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 524 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2910, 3880, 0, 7329]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [2910, 3880, 0, 7329]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [2910, 3880, 0, 7329]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 29 mins 17.6 secs.\n",
      "\n",
      "\n",
      "------- processing patch 5 out of 6 --------------\n",
      "box width:  7329\n",
      "box length: 970\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 3880, 1222, 4850]\n",
      "submit a job to the worker for sub box 1: [1222, 3880, 2444, 4850]\n",
      "submit a job to the worker for sub box 2: [2444, 3880, 3666, 4850]\n",
      "submit a job to the worker for sub box 3: [3666, 3880, 4888, 4850]\n",
      "submit a job to the worker for sub box 4: [4888, 3880, 6110, 4850]\n",
      "submit a job to the worker for sub box 5: [6110, 3880, 7329, 4850]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 3880, 1222, 4850] * 45 ...\n",
      "reading coherence in [4888, 3880, 6110, 4850] * 45 ...\n",
      "reading coherence in [3666, 3880, 4888, 4850] * 45 ...\n",
      "reading coherence in [2444, 3880, 3666, 4850] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 3880, 2444, 4850] * 45 ...\n",
      "reading coherence in [6110, 3880, 7329, 4850] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [1222, 3880, 2444, 4850] * 45 ...\n",
      "reading unwrapPhase in [3666, 3880, 4888, 4850] * 45 ...\n",
      "reading unwrapPhase in [2444, 3880, 3666, 4850] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [4888, 3880, 6110, 4850] * 45 ...\n",
      "reading unwrapPhase in [6110, 3880, 7329, 4850] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [0, 3880, 1222, 4850] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1185340 out of 1185340 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 365259 out of 1185340 (30.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 761156 out of 1182430 (64.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1076432 out of 1185340 (90.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1050038 out of 1185340 (88.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 365259/365259 pixels   168s /   375s\n",
      "[===============>        31%                       ] 361800/1185340 pixels  168s /   375sconverting LOS phase unit from radian to meter\n",
      "[===============>        31%                       ] 361800/1185340 pixels  168s /   375s\n",
      "FUTURE #1 complete. Time used: 184 seconds\n",
      "[==================================================] 761156/761156 pixels   324s /   182s\n",
      "[======================= 73% =======>              ] 765000/1050038 pixels  324s /   120sconverting LOS phase unit from radian to meter\n",
      "[======================= 72% =======>              ] 773000/1076432 pixels  324s /   126s\n",
      "FUTURE #2 complete. Time used: 340 seconds\n",
      "[==================================================] 1050038/1050038 pixels  417s /    51s\n",
      "[======================= 98% ====================> ] 1060200/1076432 pixels  417s /     8sconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1060400/1076432 pixels  417s /    51s\n",
      "FUTURE #3 complete. Time used: 433 seconds\n",
      "[==================================================] 1076432/1076432 pixels  422s /    46s\n",
      "[======================= 90% ================>     ] 1066000/1185340 pixels  422s /    46sconverting LOS phase unit from radian to meter\n",
      "[======================= 90% ================>     ] 1066200/1185340 pixels  422s /    46s\n",
      "FUTURE #4 complete. Time used: 438 seconds\n",
      "[==================================================] 1185340/1185340 pixels  446s /     9s\n",
      "[==================================================] 1179400/1185340 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 1179600/1185340 pixels\n",
      "FUTURE #5 complete. Time used: 465 seconds\n",
      "[==================================================] 1185340/1185340 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 466 seconds\n",
      "close dask client\n",
      "2023-07-10 03:11:52,352 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/worker.py\", line 1237, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/utils_comm.py\", line 413, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/core.py\", line 1365, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/core.py\", line 1124, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 241, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39366 remote=tcp://127.0.0.1:43923>: Stream is closed\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 3880, 4850, 0, 7329]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [3880, 4850, 0, 7329]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [3880, 4850, 0, 7329]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 37 mins 8.0 secs.\n",
      "\n",
      "\n",
      "------- processing patch 6 out of 6 --------------\n",
      "box width:  7329\n",
      "box length: 915\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4850, 1222, 5765]\n",
      "submit a job to the worker for sub box 1: [1222, 4850, 2444, 5765]\n",
      "submit a job to the worker for sub box 2: [2444, 4850, 3666, 5765]\n",
      "submit a job to the worker for sub box 3: [3666, 4850, 4888, 5765]\n",
      "submit a job to the worker for sub box 4: [4888, 4850, 6110, 5765]\n",
      "submit a job to the worker for sub box 5: [6110, 4850, 7329, 5765]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 4850, 2444, 5765] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 4850, 6110, 5765] * 45 ...\n",
      "reading coherence in [0, 4850, 1222, 5765] * 45 ...\n",
      "reading coherence in [2444, 4850, 3666, 5765] * 45 ...\n",
      "reading coherence in [6110, 4850, 7329, 5765] * 45 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 4850, 4888, 5765] * 45 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 12 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 1 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 2 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 3 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 4 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 5 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 6 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 7 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 8 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 9 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 10 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "chunk 12 / 12\n",
      "chunk 11 / 12\n",
      "chunk 11 / 12\n",
      "reading unwrapPhase in [4888, 4850, 6110, 5765] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 11 / 12\n",
      "reading unwrapPhase in [0, 4850, 1222, 5765] * 45 ...\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [6110, 4850, 7329, 5765] * 45 ...\n",
      "reading unwrapPhase in [1222, 4850, 2444, 5765] * 45 ...\n",
      "reading unwrapPhase in [2444, 4850, 3666, 5765] * 45 ...\n",
      "chunk 12 / 12\n",
      "reading unwrapPhase in [3666, 4850, 4888, 5765] * 45 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 158810 out of 1118130 (14.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 687145 out of 1118130 (61.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 1689 out of 1118130 (0.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 299304 out of 1118130 (26.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 1115385 (0.0%)\n",
      "number of pixels to invert: 2979 out of 1118130 (0.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]\n",
      "FUTURE #1 complete. Time used: 16 seconds\n",
      "[==================================================] 1689/1689 pixels    0s /     0s\n",
      "[======================= 54%                       ] 1600/2979 pixels    0s /     0sconverting LOS phase unit from radian to meter\n",
      "[>                                                 ]\n",
      "FUTURE #2 complete. Time used: 17 seconds\n",
      "[==================================================] 2979/2979 pixels s    1s /    85s\n",
      "[>                        2%                       ] 3200/158810 pixels    1s /    89sconverting LOS phase unit from radian to meter\n",
      "[>                                                 ]\n",
      "FUTURE #3 complete. Time used: 18 seconds\n",
      "[==================================================] 158810/158810 pixels   48s /   160s\n",
      "[======================= 51%                       ] 152800/299304 pixels   48s /    46sconverting LOS phase unit from radian to meter\n",
      "[===========>            23%                       ] 157800/687145 pixels   48s /   161s\n",
      "FUTURE #4 complete. Time used: 64 seconds\n",
      "[==================================================] 299304/299304 pixels   82s /   105s\n",
      "[=====================>  44%                       ] 303600/687145 pixels   82s /   105sconverting LOS phase unit from radian to meter\n",
      "[=====================>  44%                       ] 303800/687145 pixels   82s /   105s\n",
      "FUTURE #5 complete. Time used: 99 seconds\n",
      "[==================================================] 687145/687145 pixels  156s /     3s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 174 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4850, 5765, 0, 7329]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4850, 5765, 0, 7329]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4850, 5765, 0, 7329]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 40 mins 6.4 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (1696, 4609)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 45\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 40 mins 6.5 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5765, 7329)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/maskTempCoh.h5\n",
      "time used: 00 mins 1.4 secs.\n",
      "number of reliable pixels: 23469311\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5765, 7329)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  59s /     6s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 7.2 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5765, 7329)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5765, 7329)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7329\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 1442]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 1442]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 1442]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 1442]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 1442]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7329, 1442]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 463004 out of 1762124 (26.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 419308 out of 1757798 (23.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 143542 out of 1762124 (8.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 934752 out of 1762124 (53.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1137662 out of 1762124 (64.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1090189 out of 1762124 (61.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 143542/143542    33s /   225s\n",
      "[=======>                15%                       ] 144000/934752   34s /   194ss\n",
      "FUTURE #1 complete. Time used: 38 seconds\n",
      "[==================================================] 419308/419308   84s /     9ss\n",
      "[======================= 91% =================>    ] 420000/463004   84s /     8ss\n",
      "FUTURE #2 complete. Time used: 88 seconds\n",
      "[==================================================] 463004/463004    90s /   124s\n",
      "[====================>   42%                       ] 462000/1090189   90s /   125s\n",
      "FUTURE #3 complete. Time used: 94 seconds\n",
      "[==================================================] 934752/934752   153s /    24s\n",
      "[======================= 87% ===============>      ] 944000/1090189  153s /    22s\n",
      "FUTURE #4 complete. Time used: 157 seconds\n",
      "[==================================================] 1090189/1090189  169s /     7s\n",
      "[======================= 96% ===================>  ] 1096000/1137662  169s /     7s\n",
      "FUTURE #5 complete. Time used: 173 seconds\n",
      "[==================================================] 1137662/1137662  171s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 177 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1442, 0, 7329]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1442, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 0, 1442, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7329\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1442, 1222, 2884]\n",
      "submit a job to the worker for sub box 1: [1222, 1442, 2444, 2884]\n",
      "submit a job to the worker for sub box 2: [2444, 1442, 3666, 2884]\n",
      "submit a job to the worker for sub box 3: [3666, 1442, 4888, 2884]\n",
      "submit a job to the worker for sub box 4: [4888, 1442, 6110, 2884]\n",
      "submit a job to the worker for sub box 5: [6110, 1442, 7329, 2884]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1702141 out of 1762124 (96.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 929507 out of 1757798 (52.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1211250 out of 1762124 (68.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762123 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 929507/929507   202s /    60s\n",
      "[======================= 53%                       ] 934000/1762124  202s /   179s\n",
      "FUTURE #1 complete. Time used: 206 seconds\n",
      "[==================================================] 1211250/1211250  252s /   108s\n",
      "[======================= 69% =====>                ] 1210000/1762124  252s /   113s\n",
      "FUTURE #2 complete. Time used: 257 seconds\n",
      "[==================================================] 1702141/1702141  330s /    10s\n",
      "[======================= 97% ===================>  ] 1716000/1762124  330s /    10s\n",
      "FUTURE #3 complete. Time used: 334 seconds\n",
      "[==================================================] 1762123/1762123  333s /     6s\n",
      "[==================================================] 1754000/1762124\n",
      "FUTURE #4 complete. Time used: 340 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #5 complete. Time used: 341 seconds\n",
      "\n",
      "FUTURE #6 complete. Time used: 342 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1442, 2884, 0, 7329]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1442, 2884, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 1442, 2884, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7329\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2884, 1222, 4326]\n",
      "submit a job to the worker for sub box 1: [1222, 2884, 2444, 4326]\n",
      "submit a job to the worker for sub box 2: [2444, 2884, 3666, 4326]\n",
      "submit a job to the worker for sub box 3: [3666, 2884, 4888, 4326]\n",
      "submit a job to the worker for sub box 4: [4888, 2884, 6110, 4326]\n",
      "submit a job to the worker for sub box 5: [6110, 2884, 7329, 4326]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 773558 out of 1762124 (43.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1343261 out of 1757798 (76.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 773558/773558   169s /   215s\n",
      "[=====================>  44%                       ] 778000/1762124  170s /   216s\n",
      "FUTURE #1 complete. Time used: 174 seconds\n",
      "[==================================================] 1343261/1343261  272s /    86s\n",
      "[======================= 77% =========>            ] 1350000/1762124  272s /    81s\n",
      "FUTURE #2 complete. Time used: 277 seconds\n",
      "[==================================================] 1762124/1762124  334s /     6s\n",
      "[==================================================] 1756000/1762124\n",
      "FUTURE #3 complete. Time used: 340 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1756000/1762124\n",
      "FUTURE #4 complete. Time used: 341 seconds\n",
      "[==================================================] 1758000/1762124\n",
      "FUTURE #5 complete. Time used: 342 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #6 complete. Time used: 342 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2884, 4326, 0, 7329]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2884, 4326, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 2884, 4326, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7329\n",
      "box length: 1439\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4326, 1222, 5765]\n",
      "submit a job to the worker for sub box 1: [1222, 4326, 2444, 5765]\n",
      "submit a job to the worker for sub box 2: [2444, 4326, 3666, 5765]\n",
      "submit a job to the worker for sub box 3: [3666, 4326, 4888, 5765]\n",
      "submit a job to the worker for sub box 4: [4888, 4326, 6110, 5765]\n",
      "submit a job to the worker for sub box 5: [6110, 4326, 7329, 5765]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1327473 out of 1758458 (75.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 337816 out of 1758458 (19.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 506715 out of 1758458 (28.8%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 300543 out of 1754141 (17.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 939632 out of 1758458 (53.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 534399 out of 1758458 (30.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 300543/300543   68s /    45ss\n",
      "[======================= 89% ===============>      ] 300000/337816   68s /     8ss\n",
      "FUTURE #1 complete. Time used: 72 seconds\n",
      "[==================================================] 337816/337816    76s /   216s\n",
      "[=================>      36%                       ] 338000/939632   76s /   135s\n",
      "FUTURE #2 complete. Time used: 80 seconds\n",
      "[==================================================] 506715/506715  100s /    88ss\n",
      "[======================= 54%                       ] 504000/939632  100s /    85ss\n",
      "FUTURE #3 complete. Time used: 104 seconds\n",
      "[==================================================] 534399/534399   105s /   152s\n",
      "[====================>   42%                       ] 552000/1327473  105s /   146s\n",
      "FUTURE #4 complete. Time used: 109 seconds\n",
      "[==================================================] 939632/939632   149s /    60s\n",
      "[======================= 72% =======>              ] 950000/1327473  149s /    58s\n",
      "FUTURE #5 complete. Time used: 153 seconds\n",
      "[==================================================] 1327473/1327473  182s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 188 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4326, 5765, 0, 7329]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4326, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 10, 4326, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 17 mins 52.3 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (10,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (10,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (10, 5765, 7329)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 10/10  71s /     7s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 20.4 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 10/10  43s /     4s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20200820 - 0.0030\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0125)\n",
      "None.\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20200820\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5765, 0, 7329)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries.h5.\n",
      "update \"REF_DATE\" attribute value to 20200820\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5765, 0, 7329)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp.h5.\n",
      "update \"REF_DATE\" attribute value to 20200820\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5\n",
      "reading data ...\n",
      "referencing in time ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5 in r+ mode\n",
      "writing dataset /timeseries                block: (0, 10, 0, 5765, 0, 7329)\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5.\n",
      "update \"REF_DATE\" attribute value to 20200820\n",
      "time used: 00 mins 45.1 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: []\n",
      "--------------------------------------------------\n",
      "dates from input file: 10\n",
      "['20200609', '20200621', '20200715', '20200727', '20200808', '20200820', '20200901', '20200913', '20200925', '20201007']\n",
      "--------------------------------------------------\n",
      "using all dates to calculate the time function\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5765, 7329)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5\n",
      "split along y dimension (5765) into 2 boxes\n",
      "    with each box up to 2883 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 2 --------------\n",
      "box width:  7329\n",
      "box length: 2883\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13311361 out of 21129507 (63.0%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 2883, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 2883, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 2883, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 2883, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 2883, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 2 --------------\n",
      "box width:  7329\n",
      "box length: 2882\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13118258 out of 21122178 (62.1%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [2883, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [2883, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [2883, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [2883, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [2883, 5765, 0, 7329]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5.\n",
      "time used: 00 mins 19.1 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7329, 5765)\n",
      "subset coverage in y/x: (0, 0, 7329, 5765)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7329/5765\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.26, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 02 mins 44.7 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2020_ERA5\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 83 mins 31.4 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "working on AT137, 2021\n",
      "identifying common overlap\n",
      "clipping to common overlap\n",
      "working on _water_mask.tif\n",
      "working on _corr.tif\n",
      "working on _unw_phase_ERA5.tif\n",
      "working on _dem.tif\n",
      "working on _lv_theta.tif\n",
      "working on _lv_phi.tif\n",
      "write configuration to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/2021_SenAT137.txt\n",
      "starting mintpy\n",
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.1, 2023-01-03\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2023-07-10 04:33:59.347431--\n",
      "Current directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: 2021_SenAT137\n",
      "Go to work directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5\n",
      "copy default template file /home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/2021_SenAT137.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.compute.cluster: auto --> local\n",
      "    mintpy.compute.numWorker: auto --> 6\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*unw_phase_ERA5_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*lv_theta_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "    mintpy.deramp: auto --> linear\n",
      "copy 2021_SenAT137.txt    to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg to inputs   directory for backup.\n",
      "copy 2021_SenAT137.txt    to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg to pic      directory for backup.\n",
      "read default template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/2021_SenAT137.txt --project 2021_SenAT137\n",
      "processor : hyp3\n",
      "SAR platform/sensor : Sen\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*unw_phase_ERA5_clipped.tif\"\n",
      "/home/gbrench/sw/miniconda3/envs/mintpy/lib/python3.11/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*corr_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*dem_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /mnt/d/indennt/hyp3_app/AT137/2021/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7_dem_clipped.tif\n",
      "incidenceAngle  : /mnt/d/indennt/hyp3_app/AT137/2021/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7_lv_theta_clipped.tif\n",
      "waterMask       : /mnt/d/indennt/hyp3_app/AT137/2021/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7/S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (5765, 7331) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (5765, 7331) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (5765, 7331) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1BB_20210604T011100_20210616T011101_VVP012_INT40_G_ueF_4BF7_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (5765, 7331) with compression = lzf\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*unw_phase_ERA5_clipped.tif\n",
      "coherence       : /mnt/d/indennt/hyp3_app/AT137/2021/*/*2021*corr_clipped.tif\n",
      "number of unwrapPhase     : 55\n",
      "number of coherence       : 55\n",
      "--------------------------------------------------\n",
      "create HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (55, 5765, 7331) with compression = None\n",
      "[==================================================] 20210920_20211014  339s /     6s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (55, 5765, 7331) with compression = None\n",
      "[==================================================] 20210920_20211014  340s /     6s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (55, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (55,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (55,)\n",
      "add extra metadata: {'PROJECT_NAME': '2021_SenAT137', 'PLATFORM': 'Sen'}\n",
      "Finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 12 mins 37.2 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5\n",
      "Geometry      File : /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file 2021_SenAT137.txt for file: ifgramStack.h5\n",
      "updating metadata based on custom template file 2021_SenAT137.txt for file: geometryGeo.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/waterMask.h5 from /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/waterMask.h5\n",
      "\n",
      "modify_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 55/55   63s /     1s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 11\n",
      "number of interferograms: 55\n",
      "shift all perp baseline by 106.92715454101562 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 55\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 210.00 m\n",
      "max temporal      baseline: 132.0 days\n",
      "showing coherence\n",
      "data range: [0.44810608, 0.909137]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5 --nonzero -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/maskConnComp.h5 --update\n",
      "input ifgramStack file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 55/55   63s /     1s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/maskConnComp.h5\n",
      "time used: 01 mins 6.5 secs.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5 --dataset coherence -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   49s /     6s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/avgSpatialCoh.h5\n",
      "time used: 00 mins 58.2 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/smallbaselineApp.cfg -c /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   52s /     7s \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "y/x: (564, 5296)\n",
      "Add/update ref_x/y attribute to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5\n",
      "{'REF_Y': '564', 'REF_X': '5296', 'REF_LAT': '4865020.0', 'REF_LON': '710820.0'}\n",
      "touch avgSpatialCoh.h5\n",
      "touch maskConnComp.h5\n",
      "\n",
      "\n",
      "******************** step - quick_overview ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "temporal_average.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5 --dataset unwrapPhase -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/avgPhaseVelocity.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/avgPhaseVelocity.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of unwrapPhase in file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 5765/5765   59s /     8s \n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/avgPhaseVelocity.h5 with w mode\n",
      "create dataset /velocity of float32    in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/avgPhaseVelocity.h5\n",
      "time used: 01 mins 9.9 secs\n",
      "\n",
      "\n",
      "unwrap_error_phase_closure.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5 --water-mask /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/waterMask.h5 --action calculate --update\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "number of interferograms: 55\n",
      "number of triplets: 165\n",
      "calculating the number of triplets with non-zero integer ambiguity of closure phase ...\n",
      "    block by block with size up to (190, 7331), 31 blocks in total\n",
      "reference pixel in y/x: (564, 5296) from dataset: unwrapPhase\n",
      "[==================================================] line 5700 / 5765  197s /     6s\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/waterMask.h5\n",
      "mask out pixels with zero in file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/avgSpatialCoh.h5\n",
      "write to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/numTriNonzeroIntAmbiguity.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/numTriNonzeroIntAmbiguity.h5 with w mode\n",
      "create dataset /mask of float32    in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/numTriNonzeroIntAmbiguity.h5\n",
      "plot and save figure to file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/numTriNonzeroIntAmbiguity.png\n",
      "time used: 03 mins 26.5 secs\n",
      "Done.\n",
      "\n",
      "\n",
      "******************** step - correct_unwrap_error ********************\n",
      "phase-unwrapping error correction is OFF.\n",
      "\n",
      "\n",
      "******************** step - invert_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "ifgram_inversion.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/ifgramStack.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/smallbaselineApp.cfg --update\n",
      "read input option from template file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/smallbaselineApp.cfg\n",
      "use dataset \"unwrapPhase\" by default\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) NOT ALL output files found: ['timeseries.h5', 'temporalCoherence.h5', 'numInvIfgram.h5'].\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "reference pixel in y/x: (564, 5296) from dataset: unwrapPhase\n",
      "-------------------------------------------------------------------------------\n",
      "least-squares solution with L2 min-norm on: deformation velocity\n",
      "minimum redundancy: 1.0\n",
      "weight function: var\n",
      "calculate covariance: False \n",
      "mask: no\n",
      "-------------------------------------------------------------------------------\n",
      "number of interferograms: 55\n",
      "number of acquisitions  : 11\n",
      "number of lines   : 5765\n",
      "number of columns : 7331\n",
      "--------------------------------------------------\n",
      "create HDF5 file: timeseries.h5 with w mode\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : bperp      of <class 'numpy.float32'>   in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of <class 'numpy.float32'>   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: timeseries.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: temporalCoherence.h5 with w mode\n",
      "create dataset  : temporalCoherence of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "close  HDF5 file: temporalCoherence.h5\n",
      "--------------------------------------------------\n",
      "create HDF5 file: numInvIfgram.h5 with w mode\n",
      "create dataset  : mask of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "close  HDF5 file: numInvIfgram.h5\n",
      "maximum memory size: 4.0E+00 GB\n",
      "split 5765 lines into 8 patches for processing\n",
      "    with each patch up to 730 lines\n",
      "\n",
      "------- processing patch 1 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 730]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 730]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 730]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 730]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 730]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 730]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 0, 3666, 730] * 55 ...\n",
      "reading coherence in [3666, 0, 4888, 730] * 55 ...\n",
      "reading coherence in [6110, 0, 7331, 730] * 55 ...\n",
      "reading coherence in [1222, 0, 2444, 730] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 0, 1222, 730] * 55 ...\n",
      "reading coherence in [4888, 0, 6110, 730] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [6110, 0, 7331, 730] * 55 ...\n",
      "reading unwrapPhase in [2444, 0, 3666, 730] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [3666, 0, 4888, 730] * 55 ...\n",
      "reading unwrapPhase in [1222, 0, 2444, 730] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [0, 0, 1222, 730] * 55 ...\n",
      "reading unwrapPhase in [4888, 0, 6110, 730] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 116192 out of 891330 (13.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 892060 (0.0%)\n",
      "number of pixels to invert: 0 out of 892060 (0.0%)\n",
      "number of pixels to invert: 220161 out of 892060 (24.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 267375 out of 892060 (30.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 75612 out of 892060 (8.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]\n",
      "FUTURE #1 complete. Time used: 16 seconds\n",
      "[>                                                 ]\n",
      "FUTURE #2 complete. Time used: 16 seconds\n",
      "[==================================================] 75612/75612 pixels    29s /    76s\n",
      "[================>       34%                       ] 73800/220161 pixels   29s /    57sconverting LOS phase unit from radian to meter\n",
      "[======================= 64% ===>                  ] 74000/116192 pixels   29s /    16s\n",
      "FUTURE #3 complete. Time used: 45 seconds\n",
      "[==================================================] 116192/116192 pixels   42s /    53s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 52%                       ] 115400/220161 pixels   42s /    39s\n",
      "FUTURE #4 complete. Time used: 58 seconds\n",
      "[==================================================] 220161/220161 pixels   70s /    13s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 84% =============>        ] 225200/267375 pixels   70s /    13s\n",
      "FUTURE #5 complete. Time used: 86 seconds\n",
      "[==================================================] 267375/267375 pixels   79s /     1s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 96 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 730, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [0, 730, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [0, 730, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 01 mins 42.2 secs.\n",
      "\n",
      "\n",
      "------- processing patch 2 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 730, 1222, 1460]\n",
      "submit a job to the worker for sub box 1: [1222, 730, 2444, 1460]\n",
      "submit a job to the worker for sub box 2: [2444, 730, 3666, 1460]\n",
      "submit a job to the worker for sub box 3: [3666, 730, 4888, 1460]\n",
      "submit a job to the worker for sub box 4: [4888, 730, 6110, 1460]\n",
      "submit a job to the worker for sub box 5: [6110, 730, 7331, 1460]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 730, 2444, 1460] * 55 ...\n",
      "reading coherence in [0, 730, 1222, 1460] * 55 ...\n",
      "reading coherence in [6110, 730, 7331, 1460] * 55 ...\n",
      "reading coherence in [3666, 730, 4888, 1460] * 55 ...\n",
      "reading coherence in [2444, 730, 3666, 1460] * 55 ...\n",
      "reading coherence in [4888, 730, 6110, 1460] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [2444, 730, 3666, 1460] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [1222, 730, 2444, 1460] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [0, 730, 1222, 1460] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [6110, 730, 7331, 1460] * 55 ...\n",
      "reading unwrapPhase in [3666, 730, 4888, 1460] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [4888, 730, 6110, 1460] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 880908 out of 892060 (98.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 313794 out of 891330 (35.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 485123 out of 892060 (54.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 161100 out of 892060 (18.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 161100/161100 pixels   77s /   354s\n",
      "[======================= 52%                       ] 162400/313794 pixels   78s /    72sconverting LOS phase unit from radian to meter\n",
      "[========>               18%                       ] 161000/892060 pixels   77s /   355s\n",
      "FUTURE #1 complete. Time used: 93 seconds\n",
      "[==================================================] 313794/313794 pixels  136s /   242s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=================>      35%                       ] 311800/892060 pixels  136s /   253s\n",
      "FUTURE #2 complete. Time used: 152 seconds\n",
      "[==================================================] 485123/485123 pixels  196s /   154s\n",
      "[======================= 55%                       ] 486800/892060 pixels  196s /   160sconverting LOS phase unit from radian to meter\n",
      "[======================= 56%                       ] 490800/880908 pixels  197s /   154s\n",
      "FUTURE #3 complete. Time used: 212 seconds\n",
      "[==================================================] 880908/880908 pixels  313s /     6s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 875400/892060 pixels  313s /     6s\n",
      "FUTURE #4 complete. Time used: 329 seconds\n",
      "[==================================================] 892060/892060 pixels  315s /     6s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 887200/892060 pixels\n",
      "FUTURE #5 complete. Time used: 334 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 335 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 730, 1460, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [730, 1460, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [730, 1460, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 07 mins 22.0 secs.\n",
      "\n",
      "\n",
      "------- processing patch 3 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1460, 1222, 2190]\n",
      "submit a job to the worker for sub box 1: [1222, 1460, 2444, 2190]\n",
      "submit a job to the worker for sub box 2: [2444, 1460, 3666, 2190]\n",
      "submit a job to the worker for sub box 3: [3666, 1460, 4888, 2190]\n",
      "submit a job to the worker for sub box 4: [4888, 1460, 6110, 2190]\n",
      "submit a job to the worker for sub box 5: [6110, 1460, 7331, 2190]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 1460, 2444, 2190] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 1460, 7331, 2190] * 55 ...\n",
      "reading coherence in [3666, 1460, 4888, 2190] * 55 ...\n",
      "reading coherence in [0, 1460, 1222, 2190] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 1460, 6110, 2190] * 55 ...\n",
      "reading coherence in [2444, 1460, 3666, 2190] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [1222, 1460, 2444, 2190] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [0, 1460, 1222, 2190] * 55 ...\n",
      "reading unwrapPhase in [4888, 1460, 6110, 2190] * 55 ...\n",
      "reading unwrapPhase in [3666, 1460, 4888, 2190] * 55 ...\n",
      "reading unwrapPhase in [2444, 1460, 3666, 2190] * 55 ...\n",
      "reading unwrapPhase in [6110, 1460, 7331, 2190] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 659422 out of 892060 (73.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 853863 out of 892060 (95.7%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 424488 out of 891330 (47.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 424488/424488 pixels  208s /   107s\n",
      "[======================= 49%                       ] 433800/892060 pixels  208s /   216sconverting LOS phase unit from radian to meter\n",
      "[======================= 66% ====>                 ] 433400/659422 pixels  208s /   107s\n",
      "FUTURE #1 complete. Time used: 224 seconds\n",
      "[==================================================] 659422/659422 pixels  300s /   105s\n",
      "[======================= 74% ========>             ] 661600/892060 pixels  300s /   105sconverting LOS phase unit from radian to meter\n",
      "[======================= 74% ========>             ] 662600/892060 pixels  300s /   105s\n",
      "FUTURE #2 complete. Time used: 316 seconds\n",
      "[==================================================] 853863/853863 pixels  362s /    23s\n",
      "[======================= 95% ===================>  ] 844600/892060 pixels  362s /    19sconverting LOS phase unit from radian to meter\n",
      "[======================= 95% ===================>  ] 844800/892060 pixels  362s /    19s\n",
      "FUTURE #3 complete. Time used: 378 seconds\n",
      "[==================================================] 892060/892060 pixels  373s /     7s\n",
      "[==================================================] 887200/892060 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 885400/892060 pixels\n",
      "FUTURE #4 complete. Time used: 390 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "[==================================================] 890200/892060 pixelsconverting LOS phase unit from radian to meter\n",
      "[==================================================] 890400/892060 pixels\n",
      "FUTURE #5 complete. Time used: 392 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 392 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 1460, 2190, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [1460, 2190, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [1460, 2190, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 13 mins 58.7 secs.\n",
      "\n",
      "\n",
      "------- processing patch 4 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2190, 1222, 2920]\n",
      "submit a job to the worker for sub box 1: [1222, 2190, 2444, 2920]\n",
      "submit a job to the worker for sub box 2: [2444, 2190, 3666, 2920]\n",
      "submit a job to the worker for sub box 3: [3666, 2190, 4888, 2920]\n",
      "submit a job to the worker for sub box 4: [4888, 2190, 6110, 2920]\n",
      "submit a job to the worker for sub box 5: [6110, 2190, 7331, 2920]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 2190, 2444, 2920] * 55 ...\n",
      "reading coherence in [4888, 2190, 6110, 2920] * 55 ...\n",
      "reading coherence in [3666, 2190, 4888, 2920] * 55 ...\n",
      "reading coherence in [2444, 2190, 3666, 2920] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 2190, 7331, 2920] * 55 ...\n",
      "reading coherence in [0, 2190, 1222, 2920] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [1222, 2190, 2444, 2920] * 55 ...\n",
      "reading unwrapPhase in [4888, 2190, 6110, 2920] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [6110, 2190, 7331, 2920] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [3666, 2190, 4888, 2920] * 55 ...\n",
      "reading unwrapPhase in [2444, 2190, 3666, 2920] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [0, 2190, 1222, 2920] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 870274 out of 892060 (97.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 555530 out of 892060 (62.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 526293 out of 891330 (59.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 526293/526293 pixels  248s /   172s\n",
      "[======================= 59% =>                    ] 525400/892060 pixels  248s /   172sconverting LOS phase unit from radian to meter\n",
      "[======================= 59% =>                    ] 527200/892060 pixels  248s /   172s\n",
      "FUTURE #1 complete. Time used: 264 seconds\n",
      "[==================================================] 633133/633133 pixels  288s /   117s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 71% =======>              ] 636400/892060 pixels  288s /   117s\n",
      "FUTURE #2 complete. Time used: 303 seconds\n",
      "[==================================================] 892060/892060 pixels  375s /    15s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 890400/892060 pixels  375s /    15s\n",
      "FUTURE #3 complete. Time used: 390 seconds\n",
      "[==================================================] 892060/892060 pixels  376s /     7s\n",
      "[======================= 96% ===================>  ] 854200/892060 pixels  376s /    15sconverting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 875800/892060 pixels  376s /     7s\n",
      "FUTURE #4 complete. Time used: 391 seconds\n",
      "[==================================================] 892060/892060 pixels  381s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 98% ====================> ] 870000/892060 pixels  381s /     7s\n",
      "FUTURE #5 complete. Time used: 396 seconds\n",
      "[==================================================] 892060/892060 pixels  383s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 402 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2920, 3650, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [2920, 3650, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [2920, 3650, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 27 mins 26.6 secs.\n",
      "\n",
      "\n",
      "------- processing patch 6 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 3650, 1222, 4380]\n",
      "submit a job to the worker for sub box 1: [1222, 3650, 2444, 4380]\n",
      "submit a job to the worker for sub box 2: [2444, 3650, 3666, 4380]\n",
      "submit a job to the worker for sub box 3: [3666, 3650, 4888, 4380]\n",
      "submit a job to the worker for sub box 4: [4888, 3650, 6110, 4380]\n",
      "submit a job to the worker for sub box 5: [6110, 3650, 7331, 4380]\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 3650, 3666, 4380] * 55 ...\n",
      "reading coherence in [1222, 3650, 2444, 4380] * 55 ...\n",
      "reading coherence in [6110, 3650, 7331, 4380] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 3650, 6110, 4380] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 3650, 1222, 4380] * 55 ...\n",
      "reading coherence in [3666, 3650, 4888, 4380] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [1222, 3650, 2444, 4380] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [2444, 3650, 3666, 4380] * 55 ...\n",
      "reading unwrapPhase in [4888, 3650, 6110, 4380] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [6110, 3650, 7331, 4380] * 55 ...\n",
      "reading unwrapPhase in [0, 3650, 1222, 4380] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [3666, 3650, 4888, 4380] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "number of pixels to invert: 319789 out of 892060 (35.8%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 743193 out of 891330 (83.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[>                                                 ]number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 319789/319789 pixels  151s /   201s\n",
      "converting LOS phase unit from radian to meter\n",
      "[=================>      36%                       ] 318400/892060 pixels  152s /   270s\n",
      "FUTURE #1 complete. Time used: 167 seconds\n",
      "[==================================================] 743193/743193 pixels  323s /    61s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 84% =============>        ] 751400/892060 pixels  323s /    61s\n",
      "FUTURE #2 complete. Time used: 339 seconds\n",
      "[==================================================] 892060/892060 pixels  371s /     7s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 889800/892060 pixels\n",
      "FUTURE #3 complete. Time used: 386 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "[==================================================] 881200/892060 pixels\n",
      "FUTURE #4 complete. Time used: 387 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "[==================================================] 883400/892060 pixelsconverting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #5 complete. Time used: 388 seconds\n",
      "[==================================================] 892060/892060 pixels \n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 390 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 3650, 4380, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [3650, 4380, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [3650, 4380, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 34 mins 1.5 secs.\n",
      "\n",
      "\n",
      "------- processing patch 7 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 730\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4380, 1222, 5110]\n",
      "submit a job to the worker for sub box 1: [1222, 4380, 2444, 5110]\n",
      "submit a job to the worker for sub box 2: [2444, 4380, 3666, 5110]\n",
      "submit a job to the worker for sub box 3: [3666, 4380, 4888, 5110]\n",
      "submit a job to the worker for sub box 4: [4888, 4380, 6110, 5110]\n",
      "submit a job to the worker for sub box 5: [6110, 4380, 7331, 5110]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 4380, 1222, 5110] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [2444, 4380, 3666, 5110] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 4380, 2444, 5110] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 4380, 7331, 5110] * 55 ...\n",
      "reading coherence in [3666, 4380, 4888, 5110] * 55 ...\n",
      "reading coherence in [4888, 4380, 6110, 5110] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [1222, 4380, 2444, 5110] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [2444, 4380, 3666, 5110] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [0, 4380, 1222, 5110] * 55 ...\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [4888, 4380, 6110, 5110] * 55 ...\n",
      "reading unwrapPhase in [3666, 4380, 4888, 5110] * 55 ...\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [6110, 4380, 7331, 5110] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 892060 out of 892060 (100.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 796168 out of 892060 (89.3%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 227155 out of 892060 (25.5%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 439167 out of 892060 (49.2%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 241415 out of 891330 (27.1%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 467544 out of 892060 (52.4%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "[==================================================] 227155/227155 pixels  111s /   333s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 92% =================>    ] 222600/241415 pixels  111s /     9s\n",
      "FUTURE #1 complete. Time used: 126 seconds\n",
      "[==================================================] 241415/241415 pixels  118s /    97s\n",
      "converting LOS phase unit from radian to meter\n",
      "[===============>        31%                       ] 248200/796168 pixels  118s /   264s\n",
      "FUTURE #2 complete. Time used: 134 seconds\n",
      "[==================================================] 439167/439167 pixels  186s /   146s\n",
      "[======================= 49%                       ] 441400/892060 pixels  186s /   193sconverting LOS phase unit from radian to meter\n",
      "[======================= 56%                       ] 448800/796168 pixels  186s /   146s\n",
      "FUTURE #3 complete. Time used: 201 seconds\n",
      "[==================================================] 467544/467544 pixels  201s /   123s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 55%                       ] 487800/892060 pixels  201s /   164s\n",
      "FUTURE #4 complete. Time used: 217 seconds\n",
      "[==================================================] 796168/796168 pixels  273s /    37s\n",
      "converting LOS phase unit from radian to meter\n",
      "[======================= 88% ===============>      ] 783600/892060 pixels  273s /    37s\n",
      "FUTURE #5 complete. Time used: 289 seconds\n",
      "[==================================================] 892060/892060 pixels  295s /     6s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 313 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4380, 5110, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [4380, 5110, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [4380, 5110, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 39 mins 19.5 secs.\n",
      "\n",
      "\n",
      "------- processing patch 8 out of 8 --------------\n",
      "box width:  7331\n",
      "box length: 655\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 5110, 1222, 5765]\n",
      "submit a job to the worker for sub box 1: [1222, 5110, 2444, 5765]\n",
      "submit a job to the worker for sub box 2: [2444, 5110, 3666, 5765]\n",
      "submit a job to the worker for sub box 3: [3666, 5110, 4888, 5765]\n",
      "submit a job to the worker for sub box 4: [4888, 5110, 6110, 5765]\n",
      "submit a job to the worker for sub box 5: [6110, 5110, 7331, 5765]\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [0, 5110, 1222, 5765] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [4888, 5110, 6110, 5765] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [3666, 5110, 4888, 5765] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [6110, 5110, 7331, 5765] * 55 ...\n",
      "reading coherence in [2444, 5110, 3666, 5765] * 55 ...\n",
      "calculating weight from spatial coherence ...\n",
      "reading coherence in [1222, 5110, 2444, 5765] * 55 ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 8 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight in chunks of 100000 pixels: 9 chunks in total ...\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "convert coherence to weight using inverse of phase variance\n",
      "    with phase PDF for distributed scatterers from Tough et al. (1995)\n",
      "    number of independent looks L=10\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 8\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 1 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 8\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 2 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 3 / 8\n",
      "chunk 3 / 9\n",
      "chunk 3 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 4 / 8\n",
      "chunk 4 / 9\n",
      "chunk 4 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 5 / 8\n",
      "chunk 5 / 9\n",
      "chunk 5 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 6 / 8\n",
      "chunk 6 / 9\n",
      "chunk 6 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 7 / 8\n",
      "chunk 7 / 9\n",
      "chunk 7 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "reading unwrapPhase in [4888, 5110, 6110, 5765] * 55 ...\n",
      "reading unwrapPhase in [2444, 5110, 3666, 5765] * 55 ...\n",
      "reading unwrapPhase in [0, 5110, 1222, 5765] * 55 ...\n",
      "chunk 8 / 9\n",
      "chunk 8 / 9\n",
      "chunk 9 / 9\n",
      "chunk 9 / 9\n",
      "chunk 8 / 8\n",
      "reading unwrapPhase in [3666, 5110, 4888, 5765] * 55 ...\n",
      "reading unwrapPhase in [1222, 5110, 2444, 5765] * 55 ...\n",
      "reading unwrapPhase in [6110, 5110, 7331, 5765] * 55 ...\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "use input reference value\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "convert zero value in unwrapPhase to NaN (no-data value)\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels (on the water) with zero value in file: waterMask.h5\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with unwrapPhase = NaN in all interferograms\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "skip pixels with zero value in file: avgSpatialCoh.h5\n",
      "number of pixels to invert: 86986 out of 800410 (10.9%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 368576 out of 800410 (46.0%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 76721 out of 800410 (9.6%)\n",
      "estimating time-series via WLS pixel-by-pixel ...\n",
      "number of pixels to invert: 0 out of 800410 (0.0%)\n",
      "number of pixels to invert: 0 out of 800410 (0.0%)\n",
      "number of pixels to invert: 0 out of 799755 (0.0%)\n",
      "[>                                                 ]\n",
      "FUTURE #1 complete. Time used: 13 seconds\n",
      "[>                                                 ]\n",
      "FUTURE #2 complete. Time used: 13 seconds\n",
      "[>                                                 ]\n",
      "FUTURE #3 complete. Time used: 13 seconds\n",
      "[==================================================] 76721/76721 pixels    24s /    91s\n",
      "converting LOS phase unit from radian to meter\n",
      "[==========>             22%                       ] 79400/368576 pixels   24s /    86s\n",
      "FUTURE #4 complete. Time used: 37 seconds\n",
      "[==================================================] 86986/86986 pixels    26s /    84s\n",
      "converting LOS phase unit from radian to meter\n",
      "[===========>            24%                       ] 89000/368576 pixels   26s /    85s\n",
      "FUTURE #5 complete. Time used: 40 seconds\n",
      "[==================================================] 368576/368576 pixels   84s /     1s\n",
      "converting LOS phase unit from radian to meter\n",
      "\n",
      "FUTURE #6 complete. Time used: 98 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file timeseries.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 5110, 5765, 0, 7331]\n",
      "close HDF5 file timeseries.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file temporalCoherence.h5 in a mode\n",
      "writing dataset /temporalCoherence         block: [5110, 5765, 0, 7331]\n",
      "close HDF5 file temporalCoherence.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file numInvIfgram.h5 in a mode\n",
      "writing dataset /mask                      block: [5110, 5765, 0, 7331]\n",
      "close HDF5 file numInvIfgram.h5.\n",
      "time used: 41 mins 2.0 secs.\n",
      "\n",
      "--------------------------------------------------\n",
      "update values on the reference pixel: (564, 5296)\n",
      "set temporalCoherence on the reference pixel to 1.\n",
      "set  # of observations on the reference pixel as 55\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 41 mins 2.0 secs.\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/temporalCoherence.h5 -m 0.7 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/maskTempCoh.h5\n",
      "update mode: ON\n",
      "run or skip: run\n",
      "input temporalCoherence file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/temporalCoherence.h5\n",
      "read /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/temporalCoherence.h5\n",
      "create initial mask with the same size as the input file and all = 1\n",
      "all pixels with nan value = 0\n",
      "exclude pixels with value < 0.7\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/maskTempCoh.h5 with w mode\n",
      "create dataset /mask of bool       in size of (5765, 7331)         with compression=None\n",
      "finished writing to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/maskTempCoh.h5\n",
      "time used: 00 mins 1.6 secs.\n",
      "number of reliable pixels: 22493884\n",
      "\n",
      "\n",
      "******************** step - correct_LOD ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No local oscillator drift correction is needed for Sen.\n",
      "\n",
      "\n",
      "******************** step - correct_SET ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No solid Earth tides correction.\n",
      "\n",
      "\n",
      "******************** step - correct_troposphere ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "No tropospheric delay correction.\n",
      "\n",
      "\n",
      "******************** step - deramp ********************\n",
      "Remove for each acquisition a phase ramp: linear\n",
      "\n",
      "remove_ramp.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries.h5 -s linear -m maskTempCoh.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp.h5 NOT found.\n",
      "run or skip: run.\n",
      "remove linear ramp from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries.h5\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 11/11   81s /     8s\n",
      "finished writing to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp.h5\n",
      "add/update the following metadata to file:\n",
      "add/update mintpy.deramp = linear\n",
      "add/update mintpy.deramp.maskFile = maskTempCoh.h5\n",
      "time used: 01 mins 31.2 secs.\n",
      "\n",
      "\n",
      "******************** step - correct_topography ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "dem_error.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5 --update -g /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/inputs/geometryGeo.h5\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5 NOT found.\n",
      "run or skip: run.\n",
      "save the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "set OMP_NUM_THREADS = 1\n",
      "set OPENBLAS_NUM_THREADS = 1\n",
      "set MKL_NUM_THREADS = 1\n",
      "set NUMEXPR_NUM_THREADS = 1\n",
      "set VECLIB_MAXIMUM_THREADS = 1\n",
      "open timeseries file: timeseries_ramp.h5\n",
      "--------------------------------------------------------------------------------\n",
      "correct topographic phase residual (DEM error) (Fattahi & Amelung, 2013, IEEE-TGRS)\n",
      "ordinal least squares (OLS) inversion with L2-norm minimization on: phase\n",
      "temporal deformation model: polynomial order = 2\n",
      "--------------------------------------------------------------------------------\n",
      "add/update the following configuration metadata to file:\n",
      "['polyOrder', 'phaseVelocity', 'stepFuncDate', 'excludeDate']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: demErr.h5 with w mode\n",
      "create dataset  : dem of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "close  HDF5 file: demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5\n",
      "--------------------------------------------------\n",
      "grab dataset structure from ref_file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp.h5\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseriesResidual.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseriesResidual.h5\n",
      "\n",
      "------- processing patch 1 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 0, 1222, 1442]\n",
      "submit a job to the worker for sub box 1: [1222, 0, 2444, 1442]\n",
      "submit a job to the worker for sub box 2: [2444, 0, 3666, 1442]\n",
      "submit a job to the worker for sub box 3: [3666, 0, 4888, 1442]\n",
      "submit a job to the worker for sub box 4: [4888, 0, 6110, 1442]\n",
      "submit a job to the worker for sub box 5: [6110, 0, 7331, 1442]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 463127 out of 1762124 (26.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1137439 out of 1762124 (64.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 143872 out of 1762124 (8.2%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 420779 out of 1760682 (23.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 934524 out of 1762124 (53.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1090225 out of 1762124 (61.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 143872/143872   35s /    75ss\n",
      "[================>       34%                       ] 144000/420779   35s /    68s\n",
      "FUTURE #1 complete. Time used: 39 seconds\n",
      "[==================================================] 420779/420779   87s /     7ss\n",
      "[=====================>  45%                       ] 422000/934524   87s /   107ss\n",
      "FUTURE #2 complete. Time used: 91 seconds\n",
      "[==================================================] 463127/463127    93s /   128s\n",
      "[====================>   42%                       ] 458000/1090225   93s /   129s\n",
      "FUTURE #3 complete. Time used: 97 seconds\n",
      "[==================================================] 934524/934524   160s /    28s\n",
      "[======================= 85% =============>        ] 924000/1090225  160s /    28s\n",
      "FUTURE #4 complete. Time used: 164 seconds\n",
      "[==================================================] 1090225/1090225  179s /     7s\n",
      "[======================= 96% ===================>  ] 1092000/1137439  179s /     7s\n",
      "FUTURE #5 complete. Time used: 183 seconds\n",
      "[==================================================] 1137439/1137439  182s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 188 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [0, 1442, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 0, 1442, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 2 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 1442, 1222, 2884]\n",
      "submit a job to the worker for sub box 1: [1222, 1442, 2444, 2884]\n",
      "submit a job to the worker for sub box 2: [2444, 1442, 3666, 2884]\n",
      "submit a job to the worker for sub box 3: [3666, 1442, 4888, 2884]\n",
      "submit a job to the worker for sub box 4: [4888, 1442, 6110, 2884]\n",
      "submit a job to the worker for sub box 5: [6110, 1442, 7331, 2884]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1702141 out of 1762124 (96.6%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1207332 out of 1762124 (68.5%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 931632 out of 1760682 (52.9%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 931632/931632   214s /    60s\n",
      "[======================= 54%                       ] 950000/1762124  214s /   182s\n",
      "FUTURE #1 complete. Time used: 219 seconds\n",
      "[==================================================] 1207332/1207332  262s /   118s\n",
      "[======================= 70% ======>               ] 1226000/1762124  263s /   112s\n",
      "FUTURE #2 complete. Time used: 267 seconds\n",
      "[==================================================] 1702141/1702141  333s /    21s\n",
      "[======================= 93% =================>    ] 1632000/1762124  333s /    25s\n",
      "FUTURE #3 complete. Time used: 338 seconds\n",
      "[==================================================] 1762124/1762124  346s /     7s\n",
      "[==================================================] 1748000/1762124  346s /     7s\n",
      "FUTURE #4 complete. Time used: 351 seconds\n",
      "[==================================================] 1762124/1762124  347s /     7s\n",
      "\n",
      "FUTURE #5 complete. Time used: 352 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #6 complete. Time used: 355 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [1442, 2884, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 1442, 2884, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 3 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1442\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 2884, 1222, 4326]\n",
      "submit a job to the worker for sub box 1: [1222, 2884, 2444, 4326]\n",
      "submit a job to the worker for sub box 2: [2444, 2884, 3666, 4326]\n",
      "submit a job to the worker for sub box 3: [3666, 2884, 4888, 4326]\n",
      "submit a job to the worker for sub box 4: [4888, 2884, 6110, 4326]\n",
      "submit a job to the worker for sub box 5: [6110, 2884, 7331, 4326]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 769361 out of 1762124 (43.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1346017 out of 1760682 (76.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 1762124 out of 1762124 (100.0%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 769361/769361   170s /   225s\n",
      "[=====================>  43%                       ] 764000/1762124  170s /   226s\n",
      "FUTURE #1 complete. Time used: 175 seconds\n",
      "[==================================================] 1346017/1346017  279s /    83s\n",
      "[======================= 77% =========>            ] 1352000/1762124  279s /    83s\n",
      "FUTURE #2 complete. Time used: 284 seconds\n",
      "[==================================================] 1762124/1762124  342s /     6s\n",
      "[==================================================] 1758000/1762124\n",
      "FUTURE #3 complete. Time used: 349 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1750000/1762124\n",
      "FUTURE #4 complete. Time used: 350 seconds\n",
      "[==================================================] 1762124/1762124 \n",
      "[==================================================] 1762124/1762124 \n",
      "\n",
      "FUTURE #5 complete. Time used: 352 seconds\n",
      "\n",
      "FUTURE #6 complete. Time used: 353 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [2884, 4326, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 2884, 4326, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseriesResidual.h5.\n",
      "\n",
      "------- processing patch 4 out of 4 --------------\n",
      "box width:  7331\n",
      "box length: 1439\n",
      "\n",
      "\n",
      "------- start parallel processing using Dask -------\n",
      "input Dask cluster type: local\n",
      "initiate Dask cluster\n",
      "split patch into 6 sub boxes in x direction for workers to process\n",
      "scale Dask cluster to 6 workers\n",
      "initiate Dask client\n",
      "submit a job to the worker for sub box 0: [0, 4326, 1222, 5765]\n",
      "submit a job to the worker for sub box 1: [1222, 4326, 2444, 5765]\n",
      "submit a job to the worker for sub box 2: [2444, 4326, 3666, 5765]\n",
      "submit a job to the worker for sub box 3: [3666, 4326, 4888, 5765]\n",
      "submit a job to the worker for sub box 4: [4888, 4326, 6110, 5765]\n",
      "submit a job to the worker for sub box 5: [6110, 4326, 7331, 5765]\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "open geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read 2D incidenceAngle, slantRangeDistance from geometry file: geometryGeo.h5\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "read mean bperp from timeseries file\n",
      "skip pixels with ZERO in ALL acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with NaN  in ANY acquisitions\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO temporal coherence\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 334321 out of 1758458 (19.0%)\n",
      "number of pixels to invert: 505155 out of 1758458 (28.7%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 300080 out of 1757019 (17.1%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "estimating DEM error pixel-wisely ...\n",
      "number of pixels to invert: 1326624 out of 1758458 (75.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 938877 out of 1758458 (53.4%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "skip pixels with ZERO / NaN value in incidenceAngle / slantRangeDistance\n",
      "number of pixels to invert: 533532 out of 1758458 (30.3%)\n",
      "estimating DEM error pixel-wisely ...\n",
      "[==================================================] 300080/300080   67s /    50ss\n",
      "[======================= 59% =>                    ] 298000/505155   67s /    46ss\n",
      "FUTURE #1 complete. Time used: 72 seconds\n",
      "[==================================================] 334321/334321   75s /    38ss\n",
      "[=================>      35%                       ] 330000/938877   75s /   140ss\n",
      "FUTURE #2 complete. Time used: 80 seconds\n",
      "[==================================================] 505155/505155   103s /   175s\n",
      "[==================>     38%                       ] 498000/1326624  103s /   168s\n",
      "FUTURE #3 complete. Time used: 108 seconds\n",
      "[==================================================] 533532/533532  106s /    87ss\n",
      "[======================= 55%                       ] 520000/938877  106s /    87ss\n",
      "FUTURE #4 complete. Time used: 111 seconds\n",
      "[==================================================] 938877/938877   156s /    63s\n",
      "[======================= 71% =======>              ] 940000/1326624  156s /    63s\n",
      "FUTURE #5 complete. Time used: 161 seconds\n",
      "[==================================================] 1326624/1326624  195s /     3s\n",
      "\n",
      "FUTURE #6 complete. Time used: 202 seconds\n",
      "close dask client\n",
      "close dask cluster\n",
      "------- finished parallel processing -------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "open  HDF5 file demErr.h5 in a mode\n",
      "writing dataset /dem                       block: [4326, 5765, 0, 7331]\n",
      "close HDF5 file demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4326, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseriesResidual.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 11, 4326, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseriesResidual.h5.\n",
      "roll back to the original settings of ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'NUMEXPR_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']\n",
      "remove env variable OMP_NUM_THREADS\n",
      "remove env variable OPENBLAS_NUM_THREADS\n",
      "remove env variable MKL_NUM_THREADS\n",
      "remove env variable NUMEXPR_NUM_THREADS\n",
      "remove env variable VECLIB_MAXIMUM_THREADS\n",
      "time used: 18 mins 45.2 secs.\n",
      "\n",
      "\n",
      "******************** step - residual_RMS ********************\n",
      "\n",
      "timeseries_rms.py timeseriesResidual.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "remove quadratic ramp from file: timeseriesResidual.h5\n",
      "read mask file: maskTempCoh.h5\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: timeseriesResidual.h5\n",
      "grab dataset structure from ref_file: timeseriesResidual.h5\n",
      "create HDF5 file: timeseriesResidual_ramp.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (11,)                with compression = None\n",
      "create dataset  : date       of |S8                       in size of (11,)                with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (11, 5765, 7331)     with compression = None\n",
      "close  HDF5 file: timeseriesResidual_ramp.h5\n",
      "estimating phase ramp one date at a time ...\n",
      "[==================================================] 11/11   85s /     8s\n",
      "finished writing to file: timeseriesResidual_ramp.h5\n",
      "time used: 01 mins 34.8 secs.\n",
      "\n",
      "calculating residual RMS for each epoch from file: timeseriesResidual_ramp.h5\n",
      "read mask from file: maskTempCoh.h5\n",
      "reading timeseries data from file: timeseriesResidual_ramp.h5 ...\n",
      "[==================================================] 11/11   55s /     5s\n",
      "save timeseries RMS to text file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/rms_timeseriesResidual_ramp.txt\n",
      "read timeseries residual RMS from file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/rms_timeseriesResidual_ramp.txt\n",
      "--------------------------------------------------\n",
      "date with min RMS: 20210604 - 0.0053\n",
      "save date to file: reference_date.txt\n",
      "--------------------------------------------------\n",
      "date(s) with RMS > 3.0 * median RMS (0.0166)\n",
      "20210722 - 0.0173\n",
      "save date(s) to file: exclude_date.txt\n",
      "save figure to file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/rms_timeseriesResidual_ramp.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_date ********************\n",
      "\n",
      "reference_date.py -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/smallbaselineApp.cfg /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp.h5 /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5\n",
      "read reference date from file: reference_date.txt\n",
      "input reference date: 20210604\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries.h5\n",
      "input refDate is the same as the existing REF_DATE.\n",
      "Nothing to be done.\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp.h5\n",
      "input refDate is the same as the existing REF_DATE.\n",
      "Nothing to be done.\n",
      "--------------------------------------------------\n",
      "change reference date for file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5\n",
      "input refDate is the same as the existing REF_DATE.\n",
      "Nothing to be done.\n",
      "time used: 00 mins 3.3 secs.\n",
      "\n",
      "\n",
      "******************** step - velocity ********************\n",
      "\n",
      "timeseries2velocity.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5 -t /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/smallbaselineApp.cfg -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 --update\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "update mode: ON\n",
      "1) output file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 NOT found.\n",
      "run or skip: run.\n",
      "open timeseries file: timeseries_ramp_demErr.h5\n",
      "exclude date: ['20210722']\n",
      "--------------------------------------------------\n",
      "dates from input file: 11\n",
      "['20210604', '20210616', '20210628', '20210710', '20210722', '20210803', '20210815', '20210827', '20210908', '20210920', '20211014']\n",
      "--------------------------------------------------\n",
      "dates used to estimate the time function: 10\n",
      "['20210604', '20210616', '20210628', '20210710', '20210803', '20210815', '20210827', '20210908', '20210920', '20211014']\n",
      "--------------------------------------------------\n",
      "estimate deformation model with the following assumed time functions:\n",
      "    polynomial : 1\n",
      "    periodic   : []\n",
      "    stepDate   : []\n",
      "    exp        : {}\n",
      "    log        : {}\n",
      "add/update the following configuration metadata:\n",
      "['startDate', 'endDate', 'excludeDate', 'polynomial', 'periodic', 'stepDate', 'exp', 'log', 'uncertaintyQuantification', 'timeSeriesCovFile', 'bootstrapCount']\n",
      "--------------------------------------------------\n",
      "create HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 with w mode\n",
      "create dataset  : intercept    of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "create dataset  : interceptStd of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "create dataset  : velocity     of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "create dataset  : velocityStd  of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "create dataset  : residue      of <class 'numpy.float32'>   in size of (5765, 7331)         with compression = None\n",
      "add /intercept    attribute: UNIT = m\n",
      "add /interceptStd attribute: UNIT = m\n",
      "add /velocity     attribute: UNIT = m/year\n",
      "add /velocityStd  attribute: UNIT = m/year\n",
      "add /residue      attribute: UNIT = m\n",
      "close  HDF5 file: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5\n",
      "split along y dimension (5765) into 2 boxes\n",
      "    with each box up to 2883 in y dimension\n",
      "\n",
      "------- processing patch 1 out of 2 --------------\n",
      "box width:  7331\n",
      "box length: 2883\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13311078 out of 21135273 (63.0%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [0, 2883, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [0, 2883, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [0, 2883, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [0, 2883, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [0, 2883, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5.\n",
      "\n",
      "------- processing patch 2 out of 2 --------------\n",
      "box width:  7331\n",
      "box length: 2882\n",
      "reading data from file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/timeseries_ramp_demErr.h5 ...\n",
      "skip pixels with zero/nan value in all acquisitions\n",
      "number of pixels to invert: 13108829 out of 21127942 (62.0%)\n",
      "estimating time functions via linalg.lstsq ...\n",
      "estimating time functions STD from time-series fitting residual ...\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 in a mode\n",
      "writing dataset /intercept                 block: [2883, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 in a mode\n",
      "writing dataset /interceptStd              block: [2883, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocity                  block: [2883, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 in a mode\n",
      "writing dataset /velocityStd               block: [2883, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5.\n",
      "--------------------------------------------------\n",
      "open  HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 in a mode\n",
      "writing dataset /residue                   block: [2883, 5765, 0, 7331]\n",
      "close HDF5 file /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5.\n",
      "time used: 00 mins 22.0 secs.\n",
      "\n",
      "\n",
      "******************** step - geocode ********************\n",
      "dataset is geocoded, skip geocoding and continue.\n",
      "\n",
      "\n",
      "******************** step - google_earth ********************\n",
      "creating Google Earth KMZ file for geocoded velocity file: ...\n",
      "\n",
      "save_kmz.py /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.h5 -o /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.kmz\n",
      "data   coverage in y/x: (0, 0, 7331, 5765)\n",
      "subset coverage in y/x: (0, 0, 7331, 5765)\n",
      "update LENGTH, WIDTH, Y/XMAX\n",
      "update/add SUBSET_XMIN/YMIN/XMAX/YMAX: 0/0/7331/5765\n",
      "update Y/X_FIRST\n",
      "update REF_Y/X\n",
      "read mask from file: maskTempCoh.h5\n",
      "masking out pixels with zero value in file: None\n",
      "colormap: jet\n",
      "plotting data ...\n",
      "figure size : [15.26, 12.00]\n",
      "show reference point\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.png with dpi=600\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity_cbar.png\n",
      "writing /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.kml\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.png\n",
      "remove /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity_cbar.png\n",
      "merged all files to /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5/velocity.kmz\n",
      "\n",
      "\n",
      "******************** step - hdfeos5 ********************\n",
      "save time-series to HDF-EOS5 format is OFF.\n",
      "\n",
      "******************** plot & save to pic ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "parallel processing using 2 cores ...\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 velocity.h5 --dem inputs/geometryGeo.h5 --mask maskTempCoh.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 temporalCoherence.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskTempCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/geometryGeo.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask --wrap -c cmy\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 unwrapPhase- --zero-mask\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 inputs/ifgramStack.h5 coherence- --mask no -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgPhaseVelocity.h5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 avgSpatialCoh.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 maskConnComp.h5 -c gray -v 0 1\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 timeseries_ramp_demErr.h5 --noaxis -u cm --wrap --wrap-range -5 5\n",
      "view.py --dpi 150 --noverbose --nodisplay --update --memory 4.0 numInvIfgram.h5 --mask no\n",
      "copy *.txt files into ./pic directory.\n",
      "move *.png/pdf/kmz files to ./pic directory.\n",
      "time used: 03 mins 9.3 secs.\n",
      "Explore more info & visualization options with the following scripts:\n",
      "        info.py                    #check HDF5 file structure and metadata\n",
      "        view.py                    #2D map view\n",
      "        tsview.py                  #1D point time-series (interactive)\n",
      "        transect.py                #1D profile (interactive)\n",
      "        plot_coherence_matrix.py   #plot coherence matrix for one pixel (interactive)\n",
      "        plot_network.py            #plot network configuration of the dataset\n",
      "        plot_transection.py        #plot 1D profile along a line of a 2D matrix (interactive)\n",
      "        save_kmz.py                #generate Google Earth KMZ file in raster image\n",
      "        save_kmz_timeseries.py     #generate Google Earth KMZ file in points for time-series (interactive)\n",
      "        \n",
      "Go back to directory: /mnt/c/Users/qbren/Desktop/taco/projects/indennt/proc/data/signal_mintpy/AT137/mintpy_2021_ERA5\n",
      "\n",
      "################################################\n",
      "   Normal end of smallbaselineApp processing!\n",
      "################################################\n",
      "Time used: 89 mins 56.9 secs\n",
      "\n",
      "moving outputs to drive\n",
      "removing clipped files\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "mintpy_multiyear(orbit_list, year_list, clip=True, mintpy=True, clean_clip=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mintpy]",
   "language": "python",
   "name": "conda-env-mintpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
